@misc{2014MilnerAward,
  title = {2014 {{Milner Award Lecture}} by {{Professor Bernhard Sch\"olkopf}}},
  urldate = {2021-07-04},
  abstract = {Watch the 2014 Milner Award Lecture by Professor Bernhard Sch\"olkopf on machine learning.},
  howpublished = {https://royalsociety.org/science-events-and-lectures/2014/11/milner-lecture/},
  langid = {british},
  keywords = {ObsCite},
  file = {/Users/lichengk/Zotero/storage/WXAPBFZM/milner-lecture.html}
}

@article{abdarReviewUncertaintyQuantification2021,
  title = {A Review of Uncertainty Quantification in Deep Learning: {{Techniques}}, Applications and Challenges},
  shorttitle = {A Review of Uncertainty Quantification in Deep Learning},
  author = {Abdar, Moloud and Pourpanah, Farhad and Hussain, Sadiq and Rezazadegan, Dana and Liu, Li and Ghavamzadeh, Mohammad and Fieguth, Paul and Cao, Xiaochun and Khosravi, Abbas and Acharya, U. Rajendra and Makarenkov, Vladimir and Nahavandi, Saeid},
  year = {2021},
  month = dec,
  journal = {Information Fusion},
  volume = {76},
  pages = {243--297},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2021.05.008},
  urldate = {2023-01-17},
  abstract = {Uncertainty quantification (UQ) methods play a pivotal role in reducing the impact of uncertainties during both optimization and decision making processes. They have been applied to solve a variety of real-world problems in science and engineering. Bayesian approximation and ensemble learning techniques are two widely-used types of uncertainty quantification (UQ) methods. In this regard, researchers have proposed different UQ methods and examined their performance in a variety of applications such as computer vision (e.g., self-driving cars and object detection), image processing (e.g., image restoration), medical image analysis (e.g., medical image classification and segmentation), natural language processing (e.g., text classification, social media texts and recidivism risk-scoring), bioinformatics, etc. This study reviews recent advances in UQ methods used in deep learning, investigates the application of these methods in reinforcement learning, and highlights fundamental research challenges and directions associated with UQ.},
  langid = {english},
  keywords = {Artificial intelligence,Bayesian statistics,Deep learning,Ensemble learning,Machine learning,Uncertainty quantification},
  file = {/Users/lichengk/Zotero/storage/BLRQ9GV2/Abdar et al. - 2021 - A review of uncertainty quantification in deep lea.pdf;/Users/lichengk/Zotero/storage/HR2MRSZJ/S1566253521001081.html}
}

@inproceedings{acerbiPracticalBayesianOptimization2017,
  title = {Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Acerbi, Luigi and Ma, Wei Ji},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Acerbi_Ma_2017_Practical bayesian optimization for model fitting with bayesian adaptive direct.pdf}
}

@inproceedings{acerbiVariationalBayesianMonte2018,
  title = {Variational Bayesian Monte Carlo},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Acerbi, Luigi},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Acerbi_2018_Variational Bayesian Monte Carlo.pdf}
}

@inproceedings{acerbiVariationalBayesianMonte2020,
  title = {Variational Bayesian Monte Carlo with Noisy Likelihoods},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Acerbi, Luigi},
  editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M. F. and Lin, H.},
  year = {2020},
  volume = {33},
  pages = {8211--8222},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Acerbi_2020_Variational bayesian monte carlo with noisy likelihoods.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Acerbi_2020_Variational bayesian monte carlo with noisy likelihoods2.pdf}
}

@misc{adachiFastBayesianInference2022,
  title = {Fast {{Bayesian Inference}} with {{Batch Bayesian Quadrature}} via {{Kernel Recombination}}},
  author = {Adachi, Masaki and Hayakawa, Satoshi and J{\o}rgensen, Martin and Oberhauser, Harald and Osborne, Michael A.},
  year = {2022},
  month = oct,
  number = {arXiv:2206.04734},
  eprint = {2206.04734},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  urldate = {2022-10-24},
  abstract = {Calculation of Bayesian posteriors and model evidences typically requires numerical integration. Bayesian quadrature (BQ), a surrogate-model-based approach to numerical integration, is capable of superb sample efficiency, but its lack of parallelisation has hindered its practical applications. In this work, we propose a parallelised (batch) BQ method, employing techniques from kernel quadrature, that possesses an empirically exponential convergence rate. Additionally, just as with Nested Sampling, our method permits simultaneous inference of both posteriors and model evidence. Samples from our BQ surrogate model are re-selected to give a sparse set of samples, via a kernel recombination algorithm, requiring negligible additional time to increase the batch size. Empirically, we find that our approach significantly outperforms the sampling efficiency of both state-of-the-art BQ techniques and Nested Sampling in various real-world datasets, including lithium-ion battery analytics.},
  archiveprefix = {arxiv},
  keywords = {{62C10, 62F15},Computer Science - Machine Learning,Mathematics - Numerical Analysis,ObsCite,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Adachi et al_2022_Fast Bayesian Inference with Batch Bayesian Quadrature via Kernel Recombination2.pdf;/Users/lichengk/Zotero/storage/FY8U5KT2/2206.html}
}

@misc{adachiSOBERScalableBatch2023,
  title = {{{SOBER}}: {{Scalable Batch Bayesian Optimization}} and {{Quadrature}} Using {{Recombination Constraints}}},
  shorttitle = {{{SOBER}}},
  author = {Adachi, Masaki and Hayakawa, Satoshi and Hamid, Saad and J{\o}rgensen, Martin and Oberhauser, Harald and Osborne, Micheal A.},
  year = {2023},
  month = jan,
  number = {arXiv:2301.11832},
  eprint = {2301.11832},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  urldate = {2023-02-02},
  abstract = {Batch Bayesian optimisation (BO) has shown to be a sample-efficient method of performing optimisation where expensive-to-evaluate objective functions can be queried in parallel. However, current methods do not scale to large batch sizes -- a frequent desideratum in practice (e.g. drug discovery or simulation-based inference). We present a novel algorithm, SOBER, which permits scalable and diversified batch BO with arbitrary acquisition functions, arbitrary input spaces (e.g. graph), and arbitrary kernels. The key to our approach is to reformulate batch selection for BO as a Bayesian quadrature (BQ) problem, which offers computational advantages. This reformulation is beneficial in solving BQ tasks reciprocally, which introduces the exploitative functionality of BO to BQ. We show that SOBER offers substantive performance gains in synthetic and real-world tasks, including drug discovery and simulation-based inference.},
  archiveprefix = {arxiv},
  keywords = {{62C10, 62F15},Computer Science - Machine Learning,Mathematics - Numerical Analysis,ObsCite,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/TTWGNJEC/Adachi et al. - 2023 - SOBER Scalable Batch Bayesian Optimization and Qu.pdf;/Users/lichengk/Zotero/storage/I4YBRGCC/2301.html}
}

@article{adamDoublySparseVariational2020,
  title = {Doubly {{Sparse Variational Gaussian Processes}}},
  author = {Adam, Vincent and Eleftheriadis, Stefanos and Durrande, Nicolas and Artemev, Artem and Hensman, James},
  year = {2020},
  month = jan,
  journal = {arXiv:2001.05363 [cs, stat]},
  eprint = {2001.05363},
  primaryclass = {cs, stat},
  urldate = {2022-03-09},
  abstract = {The use of Gaussian process models is typically limited to datasets with a few tens of thousands of observations due to their complexity and memory footprint. The two most commonly used methods to overcome this limitation are 1) the variational sparse approximation which relies on inducing points and 2) the state-space equivalent formulation of Gaussian processes which can be seen as exploiting some sparsity in the precision matrix. We propose to take the best of both worlds: we show that the inducing point framework is still valid for state space models and that it can bring further computational and memory savings. Furthermore, we provide the natural gradient formulation for the proposed variational parameterisation. Finally, this work makes it possible to use the state-space formulation inside deep Gaussian process models as illustrated in one of the experiments.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/8KZETCUF/Adam et al. - 2020 - Doubly Sparse Variational Gaussian Processes.pdf;/Users/lichengk/Zotero/storage/YGKXW648/2001.html}
}

@inproceedings{adamDualParameterizationSparse2021,
  title = {Dual {{Parameterization}} of {{Sparse Variational Gaussian Processes}}},
  booktitle = {Thirty-{{Fifth Conference}} on {{Neural Information Processing Systems}}},
  author = {Adam, Vincent and Chang, Paul Edmund and Khan, Mohammad Emtiyaz and Solin, Arno},
  year = {2021},
  month = may,
  urldate = {2021-12-15},
  abstract = {Leveraging dual-parameterization for efficient inference and learning of hyperparameters in sparse variational GP models},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Adam et al_2021_Dual Parameterization of Sparse Variational Gaussian Processes.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Adam et al_2021_Dual Parameterization of Sparse Variational Gaussian Processes2.pdf;/Users/lichengk/Zotero/storage/FBARR434/forum.html}
}

@book{adlerGeometryRandomFields2010,
  title = {The {{Geometry}} of {{Random Fields}}},
  author = {Adler, Robert J},
  year = {2010},
  month = jan,
  series = {Classics in {{Applied Mathematics}}},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9780898718980},
  urldate = {2023-06-07},
  isbn = {978-0-89871-693-1},
  keywords = {Gaussian processes,ObsCite,random fields,random surfaces,stochastic geometry,stochastic processes},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Adler_2010_The Geometry of Random Fields.pdf}
}

@incollection{aggarwalSurprisingBehaviorDistance2001,
  title = {On the {{Surprising Behavior}} of {{Distance Metrics}} in {{High Dimensional Space}}},
  booktitle = {Database {{Theory}} \textemdash{} {{ICDT}} 2001},
  author = {Aggarwal, Charu C. and Hinneburg, Alexander and Keim, Daniel A.},
  editor = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan and Van Den Bussche, Jan and Vianu, Victor},
  year = {2001},
  volume = {1973},
  pages = {420--434},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-44503-X_27},
  urldate = {2023-06-09},
  abstract = {In recent years, the effect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing. In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a efficiency and/or effectiveness perspective. Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful. In this paper, we view the dimensionality curse from the point of view of the distance metrics which are used to measure the similarity between objects. We specifically examine the behavior of the commonly used Lk norm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhattan distance metric (L1 norm) is consistently more preferable than the Euclidean distance metric (L2 norm) for high dimensional data mining applications. Using the intuition derived from our analysis, we introduce and examine a natural extension of the Lk norm to fractional distance metrics. We show that the fractional distance metric provides more meaningful results both from the theoretical and empirical perspective. The results show that fractional distance metrics can significantly improve the effectiveness of standard clustering algorithms such as the k-means algorithm.},
  isbn = {978-3-540-41456-8 978-3-540-44503-6},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/A85LLT3Y/Aggarwal et al. - 2001 - On the Surprising Behavior of Distance Metrics in .pdf}
}

@misc{ahilanSuccinctSummaryReinforcement2023,
  title = {A {{Succinct Summary}} of {{Reinforcement Learning}}},
  author = {Ahilan, Sanjeevan},
  year = {2023},
  month = jan,
  number = {arXiv:2301.01379},
  eprint = {2301.01379},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-01-10},
  abstract = {This document is a concise summary of many key results in single-agent reinforcement learning (RL). The intended audience are those who already have some familiarity with RL and are looking to review, reference and/or remind themselves of important ideas in the field.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Ahilan_2023_A Succinct Summary of Reinforcement Learning.pdf;/Users/lichengk/Zotero/storage/QIMIY4NJ/2301.html}
}

@book{aignerProofsBOOK2018,
  title = {Proofs from {{THE BOOK}}},
  author = {Aigner, Martin and Ziegler, G{\"u}nter M.},
  year = {2018},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-57265-8},
  urldate = {2023-03-07},
  isbn = {978-3-662-57264-1 978-3-662-57265-8},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Aigner_Ziegler_2018_Proofs from THE BOOK.pdf}
}

@article{albergoFlowbasedGenerativeModels2019,
  title = {Flow-Based Generative Models for {{Markov}} Chain {{Monte Carlo}} in Lattice Field Theory},
  author = {Albergo, M. S. and Kanwar, G. and Shanahan, P. E.},
  year = {2019},
  month = aug,
  journal = {Physical Review D},
  volume = {100},
  number = {3},
  pages = {034515},
  issn = {2470-0010, 2470-0029},
  doi = {10.1103/PhysRevD.100.034515},
  urldate = {2022-11-22},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/ZSMSFHYP/Albergo et al. - 2019 - Flow-based generative models for Markov chain Mont.pdf}
}

@phdthesis{alexScalableGaussianProcess2016,
  title = {Scalable {{Gaussian}} Process Inference Using Variational Methods},
  author = {Alex, er Graeme de Garis Matthews},
  year = {2016},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Alex_2016_Scalable Gaussian process inference using variational methods.pdf}
}

@article{alvarezKernelsVectorValuedFunctions2012,
  title = {Kernels for {{Vector-Valued Functions}}: A {{Review}}},
  shorttitle = {Kernels for {{Vector-Valued Functions}}},
  author = {Alvarez, Mauricio A. and Rosasco, Lorenzo and Lawrence, Neil D.},
  year = {2012},
  month = apr,
  journal = {arXiv:1106.6251 [cs, math, stat]},
  eprint = {1106.6251},
  primaryclass = {cs, math, stat},
  urldate = {2022-03-14},
  abstract = {Kernel methods are among the most popular techniques in machine learning. From a frequentist/discriminative perspective they play a central role in regularization theory as they provide a natural choice for the hypotheses space and the regularization functional through the notion of reproducing kernel Hilbert spaces. From a Bayesian/generative perspective they are the key in the context of Gaussian processes, where the kernel function is also known as the covariance function. Traditionally, kernel methods have been used in supervised learning problem with scalar outputs and indeed there has been a considerable amount of work devoted to designing and learning kernels. More recently there has been an increasing interest in methods that deal with multiple outputs, motivated partly by frameworks like multitask learning. In this paper, we review different methods to design or learn valid kernel functions for multiple outputs, paying particular attention to the connection between probabilistic and functional methods.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/KUB8C5K2/Alvarez et al. - 2012 - Kernels for Vector-Valued Functions a Review.pdf;/Users/lichengk/Zotero/storage/T8RFFEK3/1106.html}
}

@article{ambrogioniWassersteinVariationalInference2018,
  title = {Wasserstein {{Variational Inference}}},
  author = {Ambrogioni, Luca and G{\"u}{\c c}l{\"u}, Umut and G{\"u}{\c c}l{\"u}t{\"u}rk, Ya{\u g}mur and Hinne, Max and Maris, Eric and {van Gerven}, Marcel A. J.},
  year = {2018},
  month = jun,
  journal = {arXiv:1805.11284 [cs, stat]},
  eprint = {1805.11284},
  primaryclass = {cs, stat},
  urldate = {2022-04-24},
  abstract = {This paper introduces Wasserstein variational inference, a new form of approximate Bayesian inference based on optimal transport theory. Wasserstein variational inference uses a new family of divergences that includes both f-divergences and the Wasserstein distance as special cases. The gradients of the Wasserstein variational loss are obtained by backpropagating through the Sinkhorn iterations. This technique results in a very stable likelihood-free training method that can be used with implicit distributions and probabilistic programs. Using the Wasserstein variational inference framework, we introduce several new forms of autoencoders and test their robustness and performance against existing variational autoencoding techniques.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/DZ9H6NQ7/Ambrogioni et al. - 2018 - Wasserstein Variational Inference.pdf;/Users/lichengk/Zotero/storage/SFTRQJ8H/1805.html}
}

@article{amosComputationModifiedBessel1974,
  title = {Computation of {{Modified Bessel Functions}} and {{Their Ratios}}},
  author = {Amos, D. E.},
  year = {1974},
  journal = {Mathematics of Computation},
  volume = {28},
  number = {125},
  eprint = {2005830},
  eprinttype = {jstor},
  pages = {239--251},
  publisher = {{American Mathematical Society}},
  issn = {0025-5718},
  doi = {10.2307/2005830},
  urldate = {2021-10-26},
  abstract = {An efficient algorithm for calculating ratios \$r\_\textbackslash nu(x) = I\_\{\textbackslash nu+1\}(x)/I\_\textbackslash nu(x), \textbackslash nu \textbackslash geqq 0, x \textbackslash geqq 0\$, is presented. This algorithm in conjunction with the recursion relation for \$r\_\textbackslash nu(x)\$ gives an alternative to other recursive methods for \$I\_\textbackslash nu(x)\$ when approximations for low-order Bessel functions are available. Sharp bounds on \$r\_\textbackslash nu(x)\$ and \$I\_\textbackslash nu(x)\$ are also established in addition to some monotonicity properties of \$r\_\textbackslash nu(x)\$ and \$r\_\textbackslash nu'(x)\$.},
  keywords = {numerical},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Amos_1974_Computation of Modified Bessel Functions and Their Ratios.pdf}
}

@misc{anastasiouSteinMethodMeets2022,
  title = {Stein's {{Method Meets Computational Statistics}}: {{A Review}} of {{Some Recent Developments}}},
  shorttitle = {Stein's {{Method Meets Computational Statistics}}},
  author = {Anastasiou, Andreas and Barp, Alessandro and Briol, Fran{\c c}ois-Xavier and Ebner, Bruno and Gaunt, Robert E. and Ghaderinezhad, Fatemeh and Gorham, Jackson and Gretton, Arthur and Ley, Christophe and Liu, Qiang and Mackey, Lester and Oates, Chris J. and Reinert, Gesine and Swan, Yvik},
  year = {2022},
  month = jun,
  number = {arXiv:2105.03481},
  eprint = {2105.03481},
  primaryclass = {math, stat},
  publisher = {{arXiv}},
  urldate = {2022-11-07},
  abstract = {Stein's method compares probability distributions through the study of a class of linear operators called Stein operators. While mainly studied in probability and used to underpin theoretical statistics, Stein's method has led to significant advances in computational statistics in recent years. The goal of this survey is to bring together some of these recent developments and, in doing so, to stimulate further research into the successful field of Stein's method and statistics. The topics we discuss include tools to benchmark and compare sampling methods such as approximate Markov chain Monte Carlo, deterministic alternatives to sampling methods, control variate techniques, parameter estimation and goodness-of-fit testing.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Statistics Theory,Statistics - Computation,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Anastasiou et al_2022_Stein's Method Meets Computational Statistics.pdf;/Users/lichengk/Zotero/storage/Z9P5RTU7/2105.html}
}

@book{andrewBayesianDataAnalysis,
  title = {Bayesian {{Data Analysis}}, {{Third Edition}}},
  author = {Andrew, Gelman},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Andrew_Bayesian Data Analysis, Third Edition.pdf}
}

@book{andrewsSpecialFunctions1999,
  title = {Special {{Functions}}},
  author = {Andrews, George E. and Askey, Richard and Roy, Ranjan},
  year = {1999},
  series = {Encyclopedia of {{Mathematics}} and Its {{Applications}}},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9781107325937},
  abstract = {Special functions, natural generalizations of the elementary functions, have been studied for centuries. The greatest mathematicians, among them Euler, Gauss, Legendre, Eisenstein, Riemann, and Ramanujan, have laid the foundations for this beautiful and useful area of mathematics. This treatise presents an overview of special functions, focusing primarily on hypergeometric functions and the associated hypergeometric series, including Bessel functions and classical orthogonal polynomials, using the basic building block of the gamma function.  In addition to relatively new work on gamma and beta functions, such as Selberg's multidimensional integrals, many important but relatively unknown nineteenth century results are included. Other topics include q-extensions of beta integrals and of hypergeometric series, Bailey chains, spherical harmonics, and applications to combinatorial problems. The authors provide organizing ideas, motivation, and historical background for the study and application of some important special functions. This clearly expressed and readable work can serve as a learning tool and lasting reference for students and researchers in special functions, mathematical physics, differential equations, mathematical computing, number theory, and combinatorics.},
  isbn = {978-0-521-62321-6}
}

@article{andrieuIntroductionMCMCMachine,
  title = {An {{Introduction}} to {{MCMC}} for {{Machine Learning}}},
  author = {Andrieu, Christophe and Andrieu, C},
  pages = {39},
  abstract = {This purpose of this introductory paper is threefold. First, it introduces the Monte Carlo method with emphasis on probabilistic machine learning. Second, it reviews the main building blocks of modern Markov chain Monte Carlo simulation, thereby providing and introduction to the remaining papers of this special issue. Lastly, it discusses new interesting research horizons.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/Zotero/storage/398VIHUN/Andrieu and Andrieu - An Introduction to MCMC for Machine Learning.pdf}
}

@misc{angelopoulosGentleIntroductionConformal2022,
  title = {A {{Gentle Introduction}} to {{Conformal Prediction}} and {{Distribution-Free Uncertainty Quantification}}},
  author = {Angelopoulos, Anastasios N. and Bates, Stephen},
  year = {2022},
  month = dec,
  number = {arXiv:2107.07511},
  eprint = {2107.07511},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  urldate = {2023-05-28},
  abstract = {Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions. One can use conformal prediction with any pre-trained model, such as a neural network, to produce sets that are guaranteed to contain the ground truth with a user-specified probability, such as 90\%. It is easy-to-understand, easy-to-use, and general, applying naturally to problems arising in the fields of computer vision, natural language processing, deep reinforcement learning, and so on. This hands-on introduction is aimed to provide the reader a working understanding of conformal prediction and related distribution-free uncertainty quantification techniques with one self-contained document. We lead the reader through practical theory for and examples of conformal prediction and describe its extensions to complex machine learning tasks involving structured outputs, distribution shift, time-series, outliers, models that abstain, and more. Throughout, there are many explanatory illustrations, examples, and code samples in Python. With each code sample comes a Jupyter notebook implementing the method on a real-data example; the notebooks can be accessed and easily run using our codebase.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Angelopoulos_Bates_2022_A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty.pdf;/Users/lichengk/Zotero/storage/E5K6ZAQT/2107.html}
}

@misc{antoranDepthUncertaintyNeural2020,
  title = {Depth {{Uncertainty}} in {{Neural Networks}}},
  author = {Antor{\'a}n, Javier and Allingham, James Urquhart and {Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel},
  year = {2020},
  month = dec,
  number = {arXiv:2006.08437},
  eprint = {2006.08437},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-11-06},
  abstract = {Existing methods for estimating uncertainty in deep learning tend to require multiple forward passes, making them unsuitable for applications where computational resources are limited. To solve this, we perform probabilistic reasoning over the depth of neural networks. Different depths correspond to subnetworks which share weights and whose predictions are combined via marginalisation, yielding model uncertainty. By exploiting the sequential structure of feed-forward networks, we are able to both evaluate our training objective and make predictions with a single forward pass. We validate our approach on real-world regression and image classification tasks. Our approach provides uncertainty calibration, robustness to dataset shift, and accuracies competitive with more computationally expensive baselines.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Antorán et al_2020_Depth Uncertainty in Neural Networks.pdf;/Users/lichengk/Zotero/storage/Z5MU4JL8/2006.html}
}

@article{aoEntropyEstimationNormalizing,
  title = {Entropy Estimation via Normalizing Flow},
  author = {Ao, Ziqiao and Li, Jinglai},
  number = {1},
  pages = {9},
  abstract = {Entropy estimation is an important problem in information theory and statistical science. Many popular entropy estimators suffer from fast growing estimation bias with respect to dimensionality, rendering them unsuitable for high-dimensional problems. In this work we propose a transform-based method for high-dimensional entropy estimation, which consists of the following two main ingredients. First by modifying the kNN based entropy estimator developed in [18], we propose a new estimator which enjoys small estimation bias for samples that are close to a uniform distribution. Second we design a normalizing flow based mapping that pushes samples toward a uniform distribution, and the relation between the entropy of the original samples and the transformed ones is also derived. As a result the entropy of a given set of samples is estimated by first transforming them toward a uniform distribution and then applying the proposed estimator to the transformed samples. Numerical experiments demonstrate the effectiveness of the method for high-dimensional entropy estimation problems.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/2EXEAJSK/Ao and Li - Entropy estimation via normalizing ﬂow.pdf}
}

@inproceedings{arbelAnnealedFlowTransport2021,
  title = {Annealed {{Flow Transport Monte Carlo}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Arbel, Michael and Matthews, Alex and Doucet, Arnaud},
  year = {2021},
  month = jul,
  pages = {318--330},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-12-07},
  abstract = {Annealed Importance Sampling (AIS) and its Sequential Monte Carlo (SMC) extensions are state-of-the-art methods for estimating normalizing constants of probability distributions. We propose here a novel Monte Carlo algorithm, Annealed Flow Transport (AFT), that builds upon AIS and SMC and combines them with normalizing flows (NFs) for improved performance. This method transports a set of particles using not only importance sampling (IS), Markov chain Monte Carlo (MCMC) and resampling steps - as in SMC, but also relies on NFs which are learned sequentially to push particles towards the successive annealed targets. We provide limit theorems for the resulting Monte Carlo estimates of the normalizing constant and expectations with respect to the target distribution. Additionally, we show that a continuous-time scaling limit of the population version of AFT is given by a Feynman\textendash Kac measure which simplifies to the law of a controlled diffusion for expressive NFs. We demonstrate experimentally the benefits and limitations of our methodology on a variety of applications.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Arbel et al_2021_Annealed Flow Transport Monte Carlo.pdf;/Users/lichengk/Zotero/storage/ACPKIBI6/Arbel et al. - 2021 - Annealed Flow Transport Monte Carlo.pdf}
}

@article{artemevTighterBoundsLog2021a,
  title = {Tighter {{Bounds}} on the {{Log Marginal Likelihood}} of {{Gaussian Process Regression Using Conjugate Gradients}}},
  author = {Artemev, Artem and Burt, David R. and {van der Wilk}, Mark},
  year = {2021},
  month = feb,
  journal = {arXiv:2102.08314 [cs, stat]},
  eprint = {2102.08314},
  primaryclass = {cs, stat},
  urldate = {2022-02-17},
  abstract = {We propose a lower bound on the log marginal likelihood of Gaussian process regression models that can be computed without matrix factorisation of the full kernel matrix. We show that approximate maximum likelihood learning of model parameters by maximising our lower bound retains many of the sparse variational approach benefits while reducing the bias introduced into parameter learning. The basis of our bound is a more careful analysis of the log-determinant term appearing in the log marginal likelihood, as well as using the method of conjugate gradients to derive tight lower bounds on the term involving a quadratic form. Our approach is a step forward in unifying methods relying on lower bound maximisation (e.g. variational methods) and iterative approaches based on conjugate gradients for training Gaussian processes. In experiments, we show improved predictive performance with our model for a comparable amount of training time compared to other conjugate gradient based approaches.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Artemev et al_2021_Tighter Bounds on the Log Marginal Likelihood of Gaussian Process Regression.pdf;/Users/lichengk/Zotero/storage/AS49UHS2/2102.html}
}

@article{austinIntroductionPropensityScore2011,
  title = {An {{Introduction}} to {{Propensity Score Methods}} for {{Reducing}} the {{Effects}} of {{Confounding}} in {{Observational Studies}}},
  author = {Austin, Peter C.},
  year = {2011},
  month = may,
  journal = {Multivariate Behavioral Research},
  volume = {46},
  number = {3},
  pages = {399--424},
  issn = {0027-3171},
  doi = {10.1080/00273171.2011.568786},
  urldate = {2021-11-09},
  abstract = {The propensity score is the probability of treatment assignment conditional on observed baseline characteristics. The propensity score allows one to design and analyze an observational (nonrandomized) study so that it mimics some of the particular characteristics of a randomized controlled trial. In particular, the propensity score is a balancing score: conditional on the propensity score, the distribution of observed baseline covariates will be similar between treated and untreated subjects. I describe 4 different propensity score methods: matching on the propensity score, stratification on the propensity score, inverse probability of treatment weighting using the propensity score, and covariate adjustment using the propensity score. I describe balance diagnostics for examining whether the propensity score model has been adequately specified. Furthermore, I discuss differences between regression-based methods and propensity score-based methods for the analysis of observational data. I describe different causal average treatment effects and their relationship with propensity score analyses.},
  pmcid = {PMC3144483},
  pmid = {21818162},
  file = {/Users/lichengk/Zotero/storage/5FMWY6YP/Austin - 2011 - An Introduction to Propensity Score Methods for Re.pdf}
}

@article{bacharoglouAPPROXIMATIONPROBABILITYDISTRIBUTIONS2010,
  title = {{{APPROXIMATION OF PROBABILITY DISTRIBUTIONS BY CONVEX MIXTURES OF GAUSSIAN MEASURES}}},
  author = {BACHAROGLOU, ATHANASSIA G.},
  year = {2010},
  journal = {Proceedings of the American Mathematical Society},
  volume = {138},
  number = {7},
  eprint = {20721762},
  eprinttype = {jstor},
  pages = {2619--2628},
  publisher = {{American Mathematical Society}},
  issn = {0002-9939},
  urldate = {2021-09-21},
  file = {/Users/lichengk/Zotero/storage/M2LF9RUU/BACHAROGLOU - 2010 - APPROXIMATION OF PROBABILITY DISTRIBUTIONS BY CONV.pdf}
}

@article{bachEquivalenceKernelQuadrature,
  title = {On the {{Equivalence}} between {{Kernel Quadrature Rules}} and {{Random Feature Expansions}}},
  author = {Bach, Francis},
  abstract = {We show that kernel-based quadrature rules for computing integrals can be seen as a special case of random feature expansions for positive definite kernels, for a particular decomposition that always exists for such kernels. We provide a theoretical analysis of the number of required samples for a given approximation error, leading to both upper and lower bounds that are based solely on the eigenvalues of the associated integral operator and match up to logarithmic terms. In particular, we show that the upper bound may be obtained from independent and identically distributed samples from a specific non-uniform distribution, while the lower bound if valid for any set of points. Applying our results to kernel-based quadrature, while our results are fairly general, we recover known upper and lower bounds for the special cases of Sobolev spaces. Moreover, our results extend to the more general problem of full function approximations (beyond simply computing an integral), with results in L2- and L{$\infty$}-norm that match known results for special cases. Applying our results to random features, we show an improvement of the number of random features needed to preserve the generalization guarantees for learning with Lipshitz-continuous losses.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/WM3FCS86/Bach - On the Equivalence between Kernel Quadrature Rules.pdf}
}

@article{bachLearningTheoryFirst,
  title = {Learning {{Theory}} from {{First Principles}}},
  author = {Bach, Francis},
  pages = {378},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bach_Learning Theory from First Principles.pdf}
}

@article{bajgiranUncertaintyQuantification4th2021,
  title = {Uncertainty {{Quantification}} of the 4th Kind; Optimal Posterior Accuracy-Uncertainty Tradeoff with the Minimum Enclosing Ball},
  author = {Bajgiran, Hamed Hamze and Franch, Pau Batlle and Owhadi, Houman and Scovel, Clint and Shirdel, Mahdy and Stanley, Michael and Tavallali, Peyman},
  year = {2021},
  month = aug,
  journal = {arXiv:2108.10517 [physics, stat]},
  eprint = {2108.10517},
  primaryclass = {physics, stat},
  urldate = {2021-08-26},
  abstract = {There are essentially three kinds of approaches to Uncertainty Quantification (UQ): (A) robust optimization, (B) Bayesian, (C) decision theory. Although (A) is robust, it is unfavorable with respect to accuracy and data assimilation. (B) requires a prior, it is generally brittle and posterior estimations can be slow. Although (C) leads to the identification of an optimal prior, its approximation suffers from the curse of dimensionality and the notion of risk is one that is averaged with respect to the distribution of the data. We introduce a 4th kind which is a hybrid between (A), (B), (C), and hypothesis testing. It can be summarized as, after observing a sample \$x\$, (1) defining a likelihood region through the relative likelihood and (2) playing a minmax game in that region to define optimal estimators and their risk. The resulting method has several desirable properties (a) an optimal prior is identified after measuring the data, and the notion of risk is a posterior one, (b) the determination of the optimal estimate and its risk can be reduced to computing the minimum enclosing ball of the image of the likelihood region under the quantity of interest map (which is fast and not subject to the curse of dimensionality). The method is characterized by a parameter in \$ [0,1]\$ acting as an assumed lower bound on the rarity of the observed data (the relative likelihood). When that parameter is near \$1\$, the method produces a posterior distribution concentrated around a maximum likelihood estimate with tight but low confidence UQ estimates. When that parameter is near \$0\$, the method produces a maximal risk posterior distribution with high confidence UQ estimates. In addition to navigating the accuracy-uncertainty tradeoff, the proposed method addresses the brittleness of Bayesian inference by navigating the robustness-accuracy tradeoff associated with data assimilation.},
  archiveprefix = {arxiv},
  keywords = {{62C20, 62F03, 62F35, 62F25, 68T37},Computer Science - Machine Learning,{Physics - Data Analysis, Statistics and Probability},Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bajgiran et al_2021_Uncertainty Quantification of the 4th kind\; optimal posterior.pdf;/Users/lichengk/Zotero/storage/VJX6KEH4/2108.html}
}

@article{balandatBoTorchFrameworkEfficient2020,
  title = {{{BoTorch}}: {{A Framework}} for {{Efficient Monte-Carlo Bayesian Optimization}}},
  shorttitle = {{{BoTorch}}},
  author = {Balandat, Maximilian and Karrer, Brian and Jiang, Daniel R. and Daulton, Samuel and Letham, Benjamin and Wilson, Andrew Gordon and Bakshy, Eytan},
  year = {2020},
  month = dec,
  journal = {arXiv:1910.06403 [cs, math, stat]},
  eprint = {1910.06403},
  primaryclass = {cs, math, stat},
  urldate = {2021-05-25},
  abstract = {Bayesian optimization provides sample-efficient global optimization for a broad range of applications, including automatic machine learning, engineering, physics, and experimental design. We introduce BoTorch, a modern programming framework for Bayesian optimization that combines Monte-Carlo (MC) acquisition functions, a novel sample average approximation optimization approach, auto-differentiation, and variance reduction techniques. BoTorch's modular design facilitates flexible specification and optimization of probabilistic models written in PyTorch, simplifying implementation of new acquisition functions. Our approach is backed by novel theoretical convergence results and made practical by a distinctive algorithmic foundation that leverages fast predictive distributions, hardware acceleration, and deterministic optimization. We also propose a novel "one-shot" formulation of the Knowledge Gradient, enabled by a combination of our theoretical and software contributions. In experiments, we demonstrate the improved sample efficiency of BoTorch relative to other popular libraries.},
  archiveprefix = {arxiv},
  keywords = {*3{$\medwhitestar\medwhitestar\medwhitestar$},{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning,done,Mathematics - Optimization and Control,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Balandat et al_2020_BoTorch.pdf;/Users/lichengk/Zotero/storage/2IJRSRU2/1910.html}
}

@unpublished{BanachSpacesHilbert,
  title = {Banach Spaces and {{Hilbert}} Spaces},
  urldate = {2021-09-24},
  file = {/Users/lichengk/Zotero/storage/DEWQ273I/lecture2.pdf}
}

@book{barberBayesianReasoningMachine2011,
  title = {Bayesian {{Reasoning}} and {{Machine Learning}}},
  author = {Barber, David},
  year = {2011},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511804779},
  urldate = {2022-01-13},
  isbn = {978-0-511-80477-9},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Barber_2011_Bayesian Reasoning and Machine Learning.pdf}
}

@article{barnettParallelNonuniformFast2019,
  title = {A Parallel Non-Uniform Fast {{Fourier}} Transform Library Based on an "Exponential of Semicircle" Kernel},
  author = {Barnett, Alex H. and Magland, Jeremy F. and af Klinteberg, Ludvig},
  year = {2019},
  month = apr,
  journal = {arXiv:1808.06736 [cs, math]},
  eprint = {1808.06736},
  primaryclass = {cs, math},
  urldate = {2021-12-05},
  abstract = {The nonuniform fast Fourier transform (NUFFT) generalizes the FFT to off-grid data. Its many applications include image reconstruction, data analysis, and the numerical solution of differential equations. We present FINUFFT, an efficient parallel library for type 1 (nonuiform to uniform), type 2 (uniform to nonuniform), or type 3 (nonuniform to nonuniform) transforms, in dimensions 1, 2, or 3. It uses minimal RAM, requires no precomputation or plan steps, and has a simple interface to several languages. We perform the expensive spreading/interpolation between nonuniform points and the fine grid via a simple new kernel---the `exponential of semicircle' \$e\^\{\textbackslash beta \textbackslash sqrt\{1-x\^2\}\}\$ in \$x\textbackslash in[-1,1]\$---in a cache-aware load-balanced multithreaded implementation. The deconvolution step requires the Fourier transform of the kernel, for which we propose efficient numerical quadrature. For types 1 and 2, rigorous error bounds asymptotic in the kernel width approach the fastest known exponential rate, namely that of the Kaiser--Bessel kernel. We benchmark against several popular CPU-based libraries, showing favorable speed and memory footprint, especially in three dimensions when high accuracy and/or clustered point distributions are desired.},
  archiveprefix = {arxiv},
  keywords = {{65T50, 65T40, 65Y05, 68N01},Computer Science - Mathematical Software,Mathematics - Numerical Analysis},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Barnett et al_2019_A parallel non-uniform fast Fourier transform library based on an exponential.pdf;/Users/lichengk/Zotero/storage/M7AXC7ZI/1808.html}
}

@article{bartlettReproducingKernelHilbert,
  title = {Reproducing {{Kernel Hilbert Spaces}}},
  author = {Bartlett, Peter and Gu, Chunhui},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/VN3LSPZH/Bartlett and Gu - Reproducing Kernel Hilbert Spaces.pdf}
}

@article{bassonVariationalTobitGaussian2023,
  title = {Variational {{Tobit Gaussian Process Regression}}},
  author = {Basson, Marno and Louw, Tobias M. and Smith, Theresa R.},
  year = {2023},
  month = mar,
  journal = {Statistics and Computing},
  volume = {33},
  number = {3},
  pages = {64},
  issn = {1573-1375},
  doi = {10.1007/s11222-023-10225-3},
  urldate = {2023-05-31},
  abstract = {We propose a variational inference-based framework for training a Gaussian process regression model subject to censored observational data. Data censoring is a typical problem encountered during the data gathering procedure and requires specialized techniques to perform inference since the resulting probabilistic models are typically analytically intractable. In this article we exploit the variational sparse Gaussian process inducing variable framework and local variational methods to compute an analytically tractable lower bound on the true log marginal likelihood of the probabilistic model which can be used to perform Bayesian model training and inference. We demonstrate the proposed framework on synthetically-produced, noise-corrupted observational data, as well as on a real-world data set, subject to artificial censoring. The resulting predictions are comparable to existing methods to account for data censoring, but provides a significant reduction in computational cost.},
  langid = {english},
  keywords = {Bayesian statistics,Censored data,Gaussian process regression,Local variational methods,Tobit regression,Variational inference},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Basson et al_2023_Variational Tobit Gaussian Process Regression.pdf}
}

@inproceedings{bauerUnderstandingProbabilisticSparse2016,
  title = {Understanding {{Probabilistic Sparse Gaussian Process Approximations}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bauer, Matthias and {van der Wilk}, Mark and Rasmussen, Carl Edward},
  year = {2016},
  volume = {29},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-02-16},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bauer et al_2016_Understanding Probabilistic Sparse Gaussian Process Approximations.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Bauer et al_2016_Understanding Probabilistic Sparse Gaussian Process Approximations2.pdf}
}

@misc{behrmannUnderstandingMitigatingExploding2021,
  title = {Understanding and {{Mitigating Exploding Inverses}} in {{Invertible Neural Networks}}},
  author = {Behrmann, Jens and Vicol, Paul and Wang, Kuan-Chieh and Grosse, Roger and Jacobsen, J{\"o}rn-Henrik},
  year = {2021},
  month = dec,
  number = {arXiv:2006.09347},
  eprint = {2006.09347},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-19},
  abstract = {Invertible neural networks (INNs) have been used to design generative models, implement memory-saving gradient computation, and solve inverse problems. In this work, we show that commonly-used INN architectures suffer from exploding inverses and are thus prone to becoming numerically non-invertible. Across a wide range of INN use-cases, we reveal failures including the non-applicability of the change-of-variables formula on in- and out-of-distribution (OOD) data, incorrect gradients for memory-saving backprop, and the inability to sample from normalizing flow models. We further derive bi-Lipschitz properties of atomic building blocks of common architectures. These insights into the stability of INNs then provide ways forward to remedy these failures. For tasks where local invertibility is sufficient, like memory-saving backprop, we propose a flexible and efficient regularizer. For problems where global invertibility is necessary, such as applying normalizing flows on OOD data, we show the importance of designing stable INN building blocks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Behrmann et al_2021_Understanding and Mitigating Exploding Inverses in Invertible Neural Networks.pdf;/Users/lichengk/Zotero/storage/MND6JGUH/2006.html}
}

@misc{bellemareCramerDistanceSolution2017,
  title = {The {{Cramer Distance}} as a {{Solution}} to {{Biased Wasserstein Gradients}}},
  author = {Bellemare, Marc G. and Danihelka, Ivo and Dabney, Will and Mohamed, Shakir and Lakshminarayanan, Balaji and Hoyer, Stephan and Munos, R{\'e}mi},
  year = {2017},
  month = may,
  number = {arXiv:1705.10743},
  eprint = {1705.10743},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-19},
  abstract = {The Wasserstein probability metric has received much attention from the machine learning community. Unlike the Kullback-Leibler divergence, which strictly measures change in probability, the Wasserstein metric reflects the underlying geometry between outcomes. The value of being sensitive to this geometry has been demonstrated, among others, in ordinal regression and generative modelling. In this paper we describe three natural properties of probability divergences that reflect requirements from machine learning: sum invariance, scale sensitivity, and unbiased sample gradients. The Wasserstein metric possesses the first two properties but, unlike the Kullback-Leibler divergence, does not possess the third. We provide empirical evidence suggesting that this is a serious issue in practice. Leveraging insights from probabilistic forecasting we propose an alternative to the Wasserstein metric, the Cram\textbackslash 'er distance. We show that the Cram\textbackslash 'er distance possesses all three desired properties, combining the best of the Wasserstein and Kullback-Leibler divergences. To illustrate the relevance of the Cram\textbackslash 'er distance in practice we design a new algorithm, the Cram\textbackslash 'er Generative Adversarial Network (GAN), and show that it performs significantly better than the related Wasserstein GAN.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bellemare et al_2017_The Cramer Distance as a Solution to Biased Wasserstein Gradients.pdf;/Users/lichengk/Zotero/storage/H92MFXA4/1705.html}
}

@article{bellGaussianMeasuresBochner,
  title = {Gaussian Measures and {{Bochner}}'s Theorem},
  author = {Bell, Jordan},
  pages = {10},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bell_Gaussian measures and Bochner’s theorem.pdf}
}

@article{bensimhounNDIMENSIONALCUMULATIVEFUNCTION,
  title = {N-{{DIMENSIONAL CUMULATIVE FUNCTION}}, {{AND OTHER USEFUL FACTS ABOUT GAUSSIANS AND NORMAL DENSITIES}}},
  author = {Bensimhoun, Michael},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/7HAWAM2Q/Bensimhoun - N-DIMENSIONAL CUMULATIVE FUNCTION, AND OTHER USEFU.pdf}
}

@inproceedings{bentonFunctionspaceDistributionsKernels2019,
  title = {Function-Space {{Distributions}} over {{Kernels}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Benton, Greg and Salkey, Jayson and Maddox, Wesley and Albinati, Julio and Wilson, Andrew Gordon},
  year = {2019},
  pages = {8},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Benton et al_2019_Function-space Distributions over Kernels.pdf}
}

@misc{berkenkampNoRegretBayesianOptimization2019,
  title = {No-{{Regret Bayesian Optimization}} with {{Unknown Hyperparameters}}},
  author = {Berkenkamp, Felix and Schoellig, Angela P. and Krause, Andreas},
  year = {2019},
  month = apr,
  number = {arXiv:1901.03357},
  eprint = {1901.03357},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-11-15},
  abstract = {Bayesian optimization (BO) based on Gaussian process models is a powerful paradigm to optimize black-box functions that are expensive to evaluate. While several BO algorithms provably converge to the global optimum of the unknown function, they assume that the hyperparameters of the kernel are known in advance. This is not the case in practice and misspecification often causes these algorithms to converge to poor local optima. In this paper, we present the first BO algorithm that is provably no-regret and converges to the optimum without knowledge of the hyperparameters. During optimization we slowly adapt the hyperparameters of stationary kernels and thereby expand the associated function class over time, so that the BO algorithm considers more complex function candidates. Based on the theoretical insights, we propose several practical algorithms that achieve the empirical sample efficiency of BO with online hyperparameter estimation, but retain theoretical convergence guarantees. We evaluate our method on several benchmark problems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/Zotero/storage/SU6ELNU7/Berkenkamp et al. - 2019 - No-Regret Bayesian Optimization with Unknown Hyper.pdf;/Users/lichengk/Zotero/storage/QAENG8N2/1901.html}
}

@book{berlinetReproducingKernelHilbert2004,
  title = {Reproducing {{Kernel Hilbert Spaces}} in {{Probability}} and {{Statistics}}},
  author = {Berlinet, Alain and {Thomas-Agnan}, Christine},
  year = {2004},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4419-9096-9},
  urldate = {2023-03-31},
  isbn = {978-1-4613-4792-7 978-1-4419-9096-9},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Berlinet_Thomas-Agnan_2004_Reproducing Kernel Hilbert Spaces in Probability and Statistics.pdf}
}

@book{bernardoBayesianTheory2004,
  title = {Bayesian Theory},
  author = {Bernardo, Jos{\'e} M. and Smith, Adrian F. M.},
  year = {2004},
  series = {Wiley Series in Probability and Statistics},
  edition = {Repr},
  publisher = {{Wiley}},
  address = {{Chichester Weinheim}},
  isbn = {978-0-471-49464-5},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bernardo_Smith_2004_Bayesian theory.pdf}
}

@book{bernsteinMatrixMathematicsTheory2009,
  title = {Matrix Mathematics: Theory, Facts, and Formulas},
  shorttitle = {Matrix Mathematics},
  author = {Bernstein, Dennis S.},
  year = {2009},
  edition = {2nd ed},
  publisher = {{Princeton University Press}},
  address = {{Princeton, N.J}},
  isbn = {978-0-691-13287-7 978-0-691-14039-1},
  langid = {english},
  lccn = {QA188 .B475 2009},
  keywords = {Linear systems,Matrices},
  annotation = {OCLC: ocn243960539},
  file = {/Users/lichengk/Zotero/storage/8CUVAM6C/Bernstein - 2009 - Matrix mathematics theory, facts, and formulas.pdf}
}

@article{betancourtConceptualIntroductionHamiltonian2018,
  title = {A {{Conceptual Introduction}} to {{Hamiltonian Monte Carlo}}},
  author = {Betancourt, Michael},
  year = {2018},
  month = jul,
  journal = {arXiv:1701.02434 [stat]},
  eprint = {1701.02434},
  primaryclass = {stat},
  urldate = {2021-08-09},
  abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Betancourt_2018_A Conceptual Introduction to Hamiltonian Monte Carlo.pdf;/Users/lichengk/Zotero/storage/9LR4MZ6F/1701.html}
}

@misc{bhartiOptimallyWeightedEstimatorsMaximum2023,
  title = {Optimally-{{Weighted Estimators}} of the {{Maximum Mean Discrepancy}} for {{Likelihood-Free Inference}}},
  author = {Bharti, Ayush and Naslidnyk, Masha and Key, Oscar and Kaski, Samuel and Briol, Fran{\c c}ois-Xavier},
  year = {2023},
  month = jan,
  number = {arXiv:2301.11674},
  eprint = {2301.11674},
  primaryclass = {stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2301.11674},
  urldate = {2023-02-05},
  abstract = {Likelihood-free inference methods typically make use of a distance between simulated and real data. A common example is the maximum mean discrepancy (MMD), which has previously been used for approximate Bayesian computation, minimum distance estimation, generalised Bayesian inference, and within the nonparametric learning framework. The MMD is commonly estimated at a root-\$m\$ rate, where \$m\$ is the number of simulated samples. This can lead to significant computational challenges since a large \$m\$ is required to obtain an accurate estimate, which is crucial for parameter estimation. In this paper, we propose a novel estimator for the MMD with significantly improved sample complexity. The estimator is particularly well suited for computationally expensive smooth simulators with low- to mid-dimensional inputs. This claim is supported through both theoretical results and an extensive simulation study on benchmark simulators.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bharti et al_2023_Optimally-Weighted Estimators of the Maximum Mean Discrepancy for.pdf;/Users/lichengk/Zotero/storage/LJI2DEH7/2301.html}
}

@article{binoisSurveyHighdimensionalGaussian2022,
  title = {A {{Survey}} on {{High-dimensional Gaussian Process Modeling}} with {{Application}} to {{Bayesian Optimization}}},
  author = {Binois, Micka{\"e}l and Wycoff, Nathan},
  year = {2022},
  month = jun,
  journal = {ACM Transactions on Evolutionary Learning and Optimization},
  volume = {2},
  number = {2},
  pages = {1--26},
  issn = {2688-299X, 2688-3007},
  doi = {10.1145/3545611},
  urldate = {2022-08-26},
  abstract = {Bayesian Optimization, the application of Bayesian function approximation to finding optima of expensive functions, has exploded in popularity in recent years. In particular, much attention has been paid to improving its efficiency on problems with many parameters to optimize. This attention has trickled down to the workhorse of high dimensional BO, high dimensional Gaussian process regression, which is also of independent interest. The great flexibility that the Gaussian process prior implies is a boon when modeling complicated, low dimensional surfaces but simply says too little when dimension grows too large. A variety of structural model assumptions have been tested to tame high dimensions, from variable selection and additive decomposition to low dimensional embeddings and beyond. Most of these approaches in turn require modifications of the acquisition function optimization strategy as well. Here we review the defining structural model assumptions and discuss the benefits and drawbacks of these approaches in practice.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/KUGPQ98H/Binois and Wycoff - 2022 - A Survey on High-dimensional Gaussian Process Mode.pdf}
}

@book{bishopPatternRecognitionMachine2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  year = {2006},
  series = {Information Science and Statistics},
  publisher = {{Springer}},
  address = {{New York}},
  isbn = {978-0-387-31073-2},
  langid = {english},
  lccn = {Q327 .B52 2006},
  keywords = {Machine learning,Pattern perception},
  file = {/Users/lichengk/Zotero/storage/24Q687JB/Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@article{bissiriGeneralFrameworkUpdating2016,
  title = {A General Framework for Updating Belief Distributions},
  author = {Bissiri, P. G. and Holmes, C. C. and Walker, S. G.},
  year = {2016},
  month = nov,
  journal = {Journal of the Royal Statistical Society. Series B, Statistical Methodology},
  volume = {78},
  number = {5},
  pages = {1103--1130},
  issn = {1369-7412},
  doi = {10.1111/rssb.12158},
  urldate = {2021-12-08},
  abstract = {We propose a framework for general Bayesian inference. We argue that a valid update of a prior belief distribution to a posterior can be made for parameters which are connected to observations through a loss function rather than the traditional likelihood function, which is recovered as a special case. Modern application areas make it increasingly challenging for Bayesians to attempt to model the true data-generating mechanism. For instance, when the object of interest is low dimensional, such as a mean or median, it is cumbersome to have to achieve this via a complete model for the whole data distribution. More importantly, there are settings where the parameter of interest does not directly index a family of density functions and thus the Bayesian approach to learning about such parameters is currently regarded as problematic. Our framework uses loss functions to connect information in the data to functionals of interest. The updating of beliefs then follows from a decision theoretic approach involving cumulative loss functions. Importantly, the procedure coincides with Bayesian updating when a true likelihood is known yet provides coherent subjective inference in much more general settings. Connections to other inference frameworks are highlighted.},
  pmcid = {PMC5082587},
  pmid = {27840585},
  keywords = {toread},
  file = {/Users/lichengk/Zotero/storage/4QZATLRD/Bissiri et al. - 2016 - A general framework for updating belief distributi.pdf}
}

@article{bleiVariationalInferenceReview2017,
  title = {Variational {{Inference}}: {{A Review}} for {{Statisticians}}},
  shorttitle = {Variational {{Inference}}},
  author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
  year = {2017},
  month = apr,
  journal = {Journal of the American Statistical Association},
  volume = {112},
  number = {518},
  eprint = {1601.00670},
  pages = {859--877},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2017.1285773},
  urldate = {2021-04-13},
  abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Blei et al_2017_Variational Inference.pdf}
}

@article{blondelEfficientModularImplicit2021,
  title = {Efficient and {{Modular Implicit Differentiation}}},
  author = {Blondel, Mathieu and Berthet, Quentin and Cuturi, Marco and Frostig, Roy and Hoyer, Stephan and {Llinares-L{\'o}pez}, Felipe and Pedregosa, Fabian and Vert, Jean-Philippe},
  year = {2021},
  month = oct,
  journal = {arXiv:2105.15183 [cs, math, stat]},
  eprint = {2105.15183},
  primaryclass = {cs, math, stat},
  urldate = {2022-02-26},
  abstract = {Automatic differentiation (autodiff) has revolutionized machine learning. It allows expressing complex computations by composing elementary ones in creative ways and removes the burden of computing their derivatives by hand. More recently, differentiation of optimization problem solutions has attracted widespread attention with applications such as optimization layers, and in bi-level problems such as hyper-parameter optimization and meta-learning. However, so far, implicit differentiation remained difficult to use for practitioners, as it often required case-by-case tedious mathematical derivations and implementations. In this paper, we propose a unified, efficient and modular approach for implicit differentiation of optimization problems. In our approach, the user defines directly in Python a function \$F\$ capturing the optimality conditions of the problem to be differentiated. Once this is done, we leverage autodiff of \$F\$ and implicit differentiation to automatically differentiate the optimization problem. Our approach thus combines the benefits of implicit differentiation and autodiff. It is efficient as it can be added on top of any state-of-the-art solver and modular as the optimality condition specification is decoupled from the implicit differentiation mechanism. We show that seemingly simple principles allow to recover many exiting implicit differentiation methods and create new ones easily. We demonstrate the ease of formulating and solving bi-level optimization problems using our framework. We also showcase an application to the sensitivity analysis of molecular dynamics.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Blondel et al_2021_Efficient and Modular Implicit Differentiation.pdf;/Users/lichengk/Zotero/storage/PBZ7PXCX/2105.html}
}

@article{blumbergCausalInferenceStatistics2016,
  title = {Causal {{Inference}} for {{Statistics}}, {{Social}}, and {{Biomedical Sciences}}: {{An Introduction}}: {{Book Reviews}}},
  shorttitle = {Causal {{Inference}} for {{Statistics}}, {{Social}}, and {{Biomedical Sciences}}},
  author = {Blumberg, Carol Joyce},
  year = {2016},
  month = apr,
  journal = {International Statistical Review},
  volume = {84},
  number = {1},
  pages = {159--159},
  issn = {03067734},
  doi = {10.1111/insr.12170},
  urldate = {2021-11-08},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Blumberg_2016_Causal Inference for Statistics, Social, and Biomedical Sciences.pdf}
}

@article{bodinModulatingSurrogatesBayesian2020,
  title = {Modulating {{Surrogates}} for {{Bayesian Optimization}}},
  author = {Bodin, Erik and Kaiser, Markus and Kazlauskaite, Ieva and Dai, Zhenwen and Campbell, Neill D. F. and Ek, Carl Henrik},
  year = {2020},
  month = sep,
  journal = {arXiv:1906.11152 [cs, stat]},
  eprint = {1906.11152},
  primaryclass = {cs, stat},
  urldate = {2021-09-14},
  abstract = {Bayesian optimization (BO) methods often rely on the assumption that the objective function is well-behaved, but in practice, this is seldom true for real-world objectives even if noise-free observations can be collected. Common approaches, which try to model the objective as precisely as possible, often fail to make progress by spending too many evaluations modeling irrelevant details. We address this issue by proposing surrogate models that focus on the well-behaved structure in the objective function, which is informative for search, while ignoring detrimental structure that is challenging to model from few observations. First, we demonstrate that surrogate models with appropriate noise distributions can absorb challenging structures in the objective function by treating them as irreducible uncertainty. Secondly, we show that a latent Gaussian process is an excellent surrogate for this purpose, comparing with Gaussian processes with standard noise distributions. We perform numerous experiments on a range of BO benchmarks and find that our approach improves reliability and performance when faced with challenging objective functions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bodin et al_2020_Modulating Surrogates for Bayesian Optimization.pdf;/Users/lichengk/Zotero/storage/U3Y2X63L/1906.html}
}

@inproceedings{bodinModulatingSurrogatesBayesian2020a,
  title = {Modulating {{Surrogates}} for {{Bayesian Optimization}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Bodin, Erik and Kaiser, Markus and Kazlauskaite, Ieva and Dai, Zhenwen and Campbell, Neill and Ek, Carl Henrik},
  year = {2020},
  month = nov,
  pages = {970--979},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-10-06},
  abstract = {Bayesian optimization (BO) methods often rely on the assumption that the objective function is well-behaved, but in practice, this is seldom true for real-world objectives even if noise-free observations can be collected. Common approaches, which try to model the objective as precisely as possible, often fail to make progress by spending too many evaluations modeling irrelevant details. We address this issue by proposing surrogate models that focus on the well-behaved structure in the objective function, which is informative for search, while ignoring detrimental structure that is challenging to model from few observations. First, we demonstrate that surrogate models with appropriate noise distributions can absorb challenging structures in the objective function by treating them as irreducible uncertainty. Secondly, we show that a latent Gaussian process is an excellent surrogate for this purpose, comparing with Gaussian processes with standard noise distributions. We perform numerous experiments on a range of BO benchmarks and find that our approach improves reliability and performance when faced with challenging objective functions.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/L2B4LIEU/Bodin et al. - 2020 - Modulating Surrogates for Bayesian Optimization.pdf;/Users/lichengk/Zotero/storage/PL3Y9MFT/Bodin et al. - 2020 - Modulating Surrogates for Bayesian Optimization.pdf}
}

@article{bonillaGenericInferenceLatent,
  title = {Generic {{Inference}} in {{Latent Gaussian Process Models}}},
  author = {Bonilla, Edwin V and Krauth, Karl and Dezfouli, Amir},
  pages = {63},
  abstract = {We develop an automated variational method for inference in models with Gaussian process (gp) priors and general likelihoods. The method supports multiple outputs and multiple latent functions and does not require detailed knowledge of the conditional likelihood, only needing its evaluation as a black-box function. Using a mixture of Gaussians as the variational distribution, we show that the evidence lower bound and its gradients can be estimated efficiently using samples from univariate Gaussian distributions. Furthermore, the method is scalable to large datasets which is achieved by using an augmented prior via the inducing-variable approach underpinning most sparse gp approximations, along with parallel computation and stochastic optimization. We evaluate our approach quantitatively and qualitatively with experiments on small datasets, medium-scale datasets and large datasets, showing its competitiveness under different likelihood models and sparsity levels. On the large-scale experiments involving prediction of airline delays and classification of handwritten digits, we show that our method is on par with the state-of-the-art hard-coded approaches for scalable gp regression and classification.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/8W4SZ9K8/Bonilla et al. - Generic Inference in Latent Gaussian Process Model.pdf}
}

@incollection{bretthorstFrequencyEstimationGeneralized2003,
  title = {Frequency {{Estimation}} and {{Generalized Lomb-Scargle Periodograms}}},
  booktitle = {Statistical {{Challenges}} in {{Astronomy}}},
  author = {Bretthorst, G. Larry},
  year = {2003},
  pages = {309--329},
  publisher = {{Springer-Verlag}},
  address = {{New York}},
  doi = {10.1007/0-387-21529-8_21},
  urldate = {2021-12-08},
  abstract = {Using Bayesian probability theory we demonstrate that the Lomb-Scargle periodogram may be generalized in a straightforward manner to nonuniformly nonsimultaneously sampled quadrature data when the sinusoid has arbitrary amplitude modulation. This generalized Lomb-Scargle periodogram is the sufficient statistic for single frequency estimation in a wide class of problems ranging from stationary frequency estimation in real uniformly sampled data, to frequency estimation for a single sinusoid having exponential, Gaussian, or arbitrary amplitude modulation. In addition we define the bandwidth of a nonuniformly sampled data set and show that the phenomenon of aliases exists in both uniformly and nonuniformly sampled data and that the phenomenon has the same cause in both types of data. Finally, we show that nonuniform sampling does not affect the accuracy of the frequency estimates; although it may affect the accuracy of the amplitude estimates.},
  isbn = {978-0-387-95546-9},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/J4ETNCGC/Bretthorst - 2003 - Frequency Estimation and Generalized Lomb-Scargle .pdf}
}

@article{briolFrankWolfeBayesianQuadrature2015,
  title = {Frank-{{Wolfe Bayesian Quadrature}}: {{Probabilistic Integration}} with {{Theoretical Guarantees}}},
  shorttitle = {Frank-{{Wolfe Bayesian Quadrature}}},
  author = {Briol, Fran{\c c}ois-Xavier and Oates, Chris J. and Girolami, Mark and Osborne, Michael A.},
  year = {2015},
  month = dec,
  journal = {arXiv:1506.02681 [stat]},
  eprint = {1506.02681},
  primaryclass = {stat},
  urldate = {2021-09-23},
  abstract = {There is renewed interest in formulating integration as an inference problem, motivated by obtaining a full distribution over numerical error that can be propagated through subsequent computation. Current methods, such as Bayesian Quadrature, demonstrate impressive empirical performance but lack theoretical analysis. An important challenge is to reconcile these probabilistic integrators with rigorous convergence guarantees. In this paper, we present the first probabilistic integrator that admits such theoretical treatment, called Frank-Wolfe Bayesian Quadrature (FWBQ). Under FWBQ, convergence to the true value of the integral is shown to be exponential and posterior contraction rates are proven to be superexponential. In simulations, FWBQ is competitive with state-of-the-art methods and out-performs alternatives based on Frank-Wolfe optimisation. Our approach is applied to successfully quantify numerical error in the solution to a challenging model choice problem in cellular biology.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Briol et al_2015_Frank-Wolfe Bayesian Quadrature.pdf;/Users/lichengk/Zotero/storage/M37FRE5R/1506.html}
}

@article{briolProbabilisticIntegrationRole2017,
  title = {Probabilistic {{Integration}}: {{A Role}} in {{Statistical Computation}}?},
  shorttitle = {Probabilistic {{Integration}}},
  author = {Briol, Fran{\c c}ois-Xavier and Oates, Chris J. and Girolami, Mark and Osborne, Michael A. and Sejdinovic, Dino},
  year = {2017},
  month = oct,
  journal = {arXiv:1512.00933 [cs, math, stat]},
  eprint = {1512.00933},
  primaryclass = {cs, math, stat},
  urldate = {2021-09-23},
  abstract = {A research frontier has emerged in scientific computation, wherein numerical error is regarded as a source of epistemic uncertainty that can be modelled. This raises several statistical challenges, including the design of statistical methods that enable the coherent propagation of probabilities through a (possibly deterministic) computational work-flow. This paper examines the case for probabilistic numerical methods in routine statistical computation. Our focus is on numerical integration, where a probabilistic integrator is equipped with a full distribution over its output that reflects the presence of an unknown numerical error. Our main technical contribution is to establish, for the first time, rates of posterior contraction for these methods. These show that probabilistic integrators can in principle enjoy the "best of both worlds", leveraging the sampling efficiency of Monte Carlo methods whilst providing a principled route to assess the impact of numerical error on scientific conclusions. Several substantial applications are provided for illustration and critical evaluation, including examples from statistical modelling, computer graphics and a computer model for an oil reservoir.},
  archiveprefix = {arxiv},
  keywords = {*5{$\medwhitestar\medwhitestar\medwhitestar\medwhitestar\medwhitestar$},Mathematics - Numerical Analysis,Mathematics - Statistics Theory,ObsCite,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Briol et al_2017_Probabilistic Integration.pdf;/Users/lichengk/Zotero/storage/3ZBE6R9N/1512.html}
}

@article{brochuTutorialBayesianOptimization2010,
  title = {A {{Tutorial}} on {{Bayesian Optimization}} of {{Expensive Cost Functions}}, with {{Application}} to {{Active User Modeling}} and {{Hierarchical Reinforcement Learning}}},
  author = {Brochu, Eric and Cora, Vlad M. and {de Freitas}, Nando},
  year = {2010},
  month = dec,
  journal = {arXiv:1012.2599 [cs]},
  eprint = {1012.2599},
  primaryclass = {cs},
  urldate = {2021-10-07},
  abstract = {We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,toread},
  file = {/Users/lichengk/Zotero/storage/BKY7BV2J/Brochu et al. - 2010 - A Tutorial on Bayesian Optimization of Expensive C.pdf;/Users/lichengk/Zotero/storage/UBR3Q9WT/1012.html}
}

@inproceedings{broderickStreamingVariationalBayes2013,
  title = {Streaming {{Variational Bayes}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Broderick, Tamara and Boyd, Nicholas and Wibisono, Andre and Wilson, Ashia C and Jordan, Michael I},
  year = {2013},
  volume = {26},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-08-31},
  abstract = {We present SDA-Bayes, a framework for (S)treaming, (D)istributed, (A)synchronous computation of a Bayesian posterior. The framework makes streaming updates to the estimated posterior according to a user-specified approximation primitive function.  We demonstrate the usefulness of our framework, with variational Bayes (VB) as the primitive, by fitting the latent Dirichlet allocation model to two large-scale document collections.  We demonstrate the advantages of our algorithm over stochastic variational inference (SVI), both in the single-pass setting SVI was designed for and in the streaming setting, to which SVI does not apply.},
  keywords = {online learning},
  file = {/Users/lichengk/Zotero/storage/RYJW2EV8/Broderick et al. - 2013 - Streaming Variational Bayes.pdf}
}

@book{brooksHandbookMarkovChain2011,
  title = {Handbook of Markov Chain Monte Carlo},
  author = {Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
  year = {2011},
  publisher = {{CRC press}},
  file = {/Users/lichengk/Zotero/storage/HFCZ8BT5/books.html}
}

@book{brooksHandbookMarkovChain2011a,
  title = {Handbook for {{Markov}} Chain {{Monte Carlo}}},
  editor = {Brooks, Steve},
  year = {2011},
  publisher = {{Taylor \& Francis}},
  address = {{Boca Raton}},
  isbn = {978-1-4200-7941-8},
  lccn = {QA274.7 .H346 2011},
  keywords = {Markov processes,Monte Carlo method},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Brooks_2011_Handbook for Markov chain Monte Carlo.pdf}
}

@article{bruntonDataDrivenScience2017a,
  title = {Data {{Driven Science}} \& {{Engineering}}},
  author = {Brunton, Steven L and Kutz, J Nathan},
  year = {2017},
  pages = {572},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Brunton_Kutz_2017_Data Driven Science & Engineering.pdf}
}

@article{buiPaperVariationalLearning,
  title = {On the Paper: {{Variational Learning}} of {{Inducing Variables}} in {{Sparse Gaussian Processes}} ({{Titsias}}, 2009)},
  author = {Bui, Thang and Turner, Richard},
  pages = {4},
  abstract = {This summary was prepared for our internal reading club and serves as notes on the sparse GP regression using the variational method (Titsias, 2009). We also discuss why this approximation can be viewed as the corrected version of the Projected Process or Deterministic Training Conditional (DTC) approximation (Seeger, 2003).},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bui_Turner_On the paper.pdf}
}

@inproceedings{buiStreamingSparseGaussian2017,
  title = {Streaming {{Sparse Gaussian Process Approximations}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bui, Thang D and Nguyen, Cuong and Turner, Richard E},
  year = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-05-31},
  abstract = {Sparse pseudo-point approximations for Gaussian process (GP) models provide a suite of methods that support deployment of GPs in the large data regime and enable analytic intractabilities to be sidestepped. However, the field lacks a principled method to handle streaming data in which both the posterior distribution over function values and the hyperparameter estimates are updated in an online fashion. The small number of existing approaches either use suboptimal hand-crafted heuristics for hyperparameter learning, or suffer from catastrophic forgetting or slow updating when new data arrive. This paper develops a new principled framework for deploying Gaussian process probabilistic models in the streaming setting, providing  methods for learning hyperparameters and optimising pseudo-input locations. The proposed framework is assessed using synthetic and real-world datasets.},
  keywords = {online learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bui et al_2017_Streaming Sparse Gaussian Process Approximations2.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Bui et al_2017_Streaming Sparse Gaussian Process Approximations3.pdf}
}

@article{buiUnifyingFrameworkGaussian2017,
  title = {A {{Unifying Framework}} for {{Gaussian Process Pseudo-Point Approximations}} Using {{Power Expectation Propagation}}},
  author = {Bui, Thang D. and Yan, Josiah and Turner, Richard E.},
  year = {2017},
  month = oct,
  journal = {arXiv:1605.07066 [cs, stat]},
  eprint = {1605.07066},
  primaryclass = {cs, stat},
  urldate = {2022-02-10},
  abstract = {Gaussian processes (GPs) are flexible distributions over functions that enable high-level assumptions about unknown functions to be encoded in a parsimonious, flexible and general way. Although elegant, the application of GPs is limited by computational and analytical intractabilities that arise when data are sufficiently numerous or when employing non-Gaussian models. Consequently, a wealth of GP approximation schemes have been developed over the last 15 years to address these key limitations. Many of these schemes employ a small set of pseudo data points to summarise the actual data. In this paper, we develop a new pseudo-point approximation framework using Power Expectation Propagation (Power EP) that unifies a large number of these pseudo-point approximations. Unlike much of the previous venerable work in this area, the new framework is built on standard methods for approximate inference (variational free-energy, EP and Power EP methods) rather than employing approximations to the probabilistic generative model itself. In this way, all of approximation is performed at `inference time' rather than at `modelling time' resolving awkward philosophical and empirical questions that trouble previous approaches. Crucially, we demonstrate that the new framework includes new pseudo-point approximation methods that outperform current approaches on regression and classification tasks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/LN3SVGJY/Bui et al. - 2017 - A Unifying Framework for Gaussian Process Pseudo-P.pdf;/Users/lichengk/Zotero/storage/XBUMY9UD/1605.html}
}

@article{bullConvergenceRatesEfficient2011,
  title = {Convergence Rates of Efficient Global Optimization Algorithms},
  author = {Bull, Adam D.},
  year = {2011},
  month = oct,
  journal = {arXiv:1101.3501 [math, stat]},
  eprint = {1101.3501},
  primaryclass = {math, stat},
  urldate = {2021-10-20},
  abstract = {Efficient global optimization is the problem of minimizing an unknown function f, using as few evaluations f(x) as possible. It can be considered as a continuum-armed bandit problem, with noiseless data and simple regret. Expected improvement is perhaps the most popular method for solving this problem; the algorithm performs well in experiments, but little is known about its theoretical properties. Implementing expected improvement requires a choice of Gaussian process prior, which determines an associated space of functions, its reproducing-kernel Hilbert space (RKHS). When the prior is fixed, expected improvement is known to converge on the minimum of any function in the RKHS. We begin by providing convergence rates for this procedure. The rates are optimal for functions of low smoothness, and we modify the algorithm to attain optimal rates for smoother functions. For practitioners, however, these results are somewhat misleading. Priors are typically not held fixed, but depend on parameters estimated from the data. For standard estimators, we show this procedure may never discover the minimum of f. We then propose alternative estimators, chosen to minimize the constants in the rate of convergence, and show these estimators retain the convergence rates of a fixed prior.},
  archiveprefix = {arxiv},
  keywords = {{90C26 (Primary), 68Q32, 62C10, 62L05 (Secondary)},Mathematics - Optimization and Control,Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Bull_2011_Convergence rates of efficient global optimization algorithms.pdf;/Users/lichengk/Zotero/storage/827JFFH9/1101.html}
}

@misc{bullConvergenceRatesEfficient2011a,
  title = {Convergence Rates of Efficient Global Optimization Algorithms},
  author = {Bull, Adam D.},
  year = {2011},
  month = oct,
  number = {arXiv:1101.3501},
  eprint = {1101.3501},
  primaryclass = {math, stat},
  publisher = {{arXiv}},
  urldate = {2023-05-19},
  abstract = {Efficient global optimization is the problem of minimizing an unknown function f, using as few evaluations f(x) as possible. It can be considered as a continuum-armed bandit problem, with noiseless data and simple regret. Expected improvement is perhaps the most popular method for solving this problem; the algorithm performs well in experiments, but little is known about its theoretical properties. Implementing expected improvement requires a choice of Gaussian process prior, which determines an associated space of functions, its reproducing-kernel Hilbert space (RKHS). When the prior is fixed, expected improvement is known to converge on the minimum of any function in the RKHS. We begin by providing convergence rates for this procedure. The rates are optimal for functions of low smoothness, and we modify the algorithm to attain optimal rates for smoother functions. For practitioners, however, these results are somewhat misleading. Priors are typically not held fixed, but depend on parameters estimated from the data. For standard estimators, we show this procedure may never discover the minimum of f. We then propose alternative estimators, chosen to minimize the constants in the rate of convergence, and show these estimators retain the convergence rates of a fixed prior.},
  archiveprefix = {arxiv},
  keywords = {{90C26 (Primary), 68Q32, 62C10, 62L05 (Secondary)},Mathematics - Optimization and Control,Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/N5ZLLSYE/Bull - 2011 - Convergence rates of efficient global optimization.pdf;/Users/lichengk/Zotero/storage/PVWNE9FH/1101.html}
}

@article{burtBarelyBiasedLearning2021,
  title = {Barely {{Biased Learning}} for {{Gaussian Process Regression}}},
  author = {Burt, David R. and Artemev, Artem and {van der Wilk}, Mark},
  year = {2021},
  month = sep,
  journal = {arXiv:2109.09417 [cs, stat]},
  eprint = {2109.09417},
  primaryclass = {cs, stat},
  urldate = {2021-10-18},
  abstract = {Recent work in scalable approximate Gaussian process regression has discussed a bias-variance-computation trade-off when estimating the log marginal likelihood. We suggest a method that adaptively selects the amount of computation to use when estimating the log marginal likelihood so that the bias of the objective function is guaranteed to be small. While simple in principle, our current implementation of the method is not competitive computationally with existing approximations.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/D8T8Y6BV/Burt et al. - 2021 - Barely Biased Learning for Gaussian Process Regres.pdf;/Users/lichengk/Zotero/storage/KBIDKVPX/2109.html}
}

@article{burtConvergenceSparseVariational,
  title = {Convergence of {{Sparse Variational Inference}} in {{Gaussian Processes Regression}}},
  author = {Burt, David R and Rasmussen, Carl Edward},
  pages = {63},
  abstract = {Gaussian processes are distributions over functions that are versatile and mathematically convenient priors in Bayesian modelling. However, their use is often impeded for data with large numbers of observations, N , due to the cubic (in N ) cost of matrix operations used in exact inference. Many solutions have been proposed that rely on M N inducing variables to form an approximation at a cost of O(N M 2). While the computational cost appears linear in N , the true complexity depends on how M must scale with N to ensure a certain quality of the approximation. In this work, we investigate upper and lower bounds on how M needs to grow with N to ensure high quality approximations. We show that we can make the KL-divergence between the approximate model and the exact posterior arbitrarily small for a Gaussian-noise regression model with M N . Specifically, for the popular squared exponential kernel and D-dimensional Gaussian distributed covariates, M = O((log N )D) suffice and a method with an overall computational cost of O N (log N )2D(log log N )2 can be used to perform inference.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Burt_Rasmussen_Convergence of Sparse Variational Inference in Gaussian Processes Regression.pdf}
}

@inproceedings{burtRatesConvergenceSparse2019,
  title = {Rates of {{Convergence}} for {{Sparse Variational Gaussian Process Regression}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Burt, David and Rasmussen, Carl Edward and Wilk, Mark Van Der},
  year = {2019},
  month = may,
  pages = {862--871},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-08-16},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Burt et al_2019_Rates of Convergence for Sparse Variational Gaussian Process Regression.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Burt et al_2019_Rates of Convergence for Sparse Variational Gaussian Process Regression2.pdf}
}

@misc{burtRatesConvergenceSparse2019a,
  title = {Rates of {{Convergence}} for {{Sparse Variational Gaussian Process Regression}}},
  author = {Burt, David R. and Rasmussen, Carl E. and {van der Wilk}, Mark},
  year = {2019},
  month = sep,
  number = {arXiv:1903.03571},
  eprint = {1903.03571},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-08-26},
  abstract = {Excellent variational approximations to Gaussian process posteriors have been developed which avoid the \$\textbackslash mathcal\{O\}\textbackslash left(N\^3\textbackslash right)\$ scaling with dataset size \$N\$. They reduce the computational cost to \$\textbackslash mathcal\{O\}\textbackslash left(NM\^2\textbackslash right)\$, with \$M\textbackslash ll N\$ being the number of inducing variables, which summarise the process. While the computational cost seems to be linear in \$N\$, the true complexity of the algorithm depends on how \$M\$ must increase to ensure a certain quality of approximation. We address this by characterising the behavior of an upper bound on the KL divergence to the posterior. We show that with high probability the KL divergence can be made arbitrarily small by growing \$M\$ more slowly than \$N\$. A particular case of interest is that for regression with normally distributed inputs in D-dimensions with the popular Squared Exponential kernel, \$M=\textbackslash mathcal\{O\}(\textbackslash log\^D N)\$ is sufficient. Our results show that as datasets grow, Gaussian process posteriors can truly be approximated cheaply, and provide a concrete rule for how to increase \$M\$ in continual learning scenarios.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/Zotero/storage/4GK4DNDM/Burt et al. - 2019 - Rates of Convergence for Sparse Variational Gaussi.pdf;/Users/lichengk/Zotero/storage/EXN2ETEP/1903.html}
}

@phdthesis{burtSpectralMethodsGaussian2018,
  title = {Spectral {{Methods}} in {{Gaussian Process Approximations}}},
  author = {Burt, David R},
  year = {2018},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Burt_2018_Spectral Methods in Gaussian Process Approximations.pdf}
}

@article{burtVariationalOrthogonalFeatures2020,
  title = {Variational {{Orthogonal Features}}},
  author = {Burt, David R. and Rasmussen, Carl Edward and {van der Wilk}, Mark},
  year = {2020},
  month = jun,
  journal = {arXiv:2006.13170 [cs, stat]},
  eprint = {2006.13170},
  primaryclass = {cs, stat},
  urldate = {2021-12-01},
  abstract = {Sparse stochastic variational inference allows Gaussian process models to be applied to large datasets. The per iteration computational cost of inference with this method is \$\textbackslash mathcal\{O\}(\textbackslash tilde\{N\}M\^2+M\^3),\$ where \$\textbackslash tilde\{N\}\$ is the number of points in a minibatch and \$M\$ is the number of `inducing features', which determine the expressiveness of the variational family. Several recent works have shown that for certain priors, features can be defined that remove the \$\textbackslash mathcal\{O\}(M\^3)\$ cost of computing a minibatch estimate of an evidence lower bound (ELBO). This represents a significant computational savings when \$M\textbackslash gg \textbackslash tilde\{N\}\$. We present a construction of features for any stationary prior kernel that allow for computation of an unbiased estimator to the ELBO using \$T\$ Monte Carlo samples in \$\textbackslash mathcal\{O\}(\textbackslash tilde\{N\}T+M\^2T)\$ and in \$\textbackslash mathcal\{O\}(\textbackslash tilde\{N\}T+MT)\$ with an additional approximation. We analyze the impact of this additional approximation on inference quality.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/LHBRXWS2/Burt et al. - 2020 - Variational Orthogonal Features.pdf;/Users/lichengk/Zotero/storage/9H9JYT5I/2006.html}
}

@article{byrdLIMITEDMEMORYALGORITHM,
  title = {A {{LIMITED MEMORY ALGORITHM FOR BOUND CONSTRAINED OPTIMIZATION}}},
  author = {Byrd, Richard H and Lu, Peihuang and Nocedal, Jorge and Zhu, Ciyou},
  pages = {25},
  abstract = {An algorithm for solving large nonlinear optimization problems with simple bounds is described. It is based on the gradient projection method and uses a limited memory BFGS matrix to approximate the Hessian of the objective function. It is shown how to take advantage of the form of the limited memory approximation to implement the algorithm e ciently. The results of numerical tests on a set of large problems are reported.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/SKSRRBHA/Byrd et al. - A LIMITED MEMORY ALGORITHM FOR BOUND CONSTRAINED O.pdf}
}

@article{caflischMonteCarloQuasiMonte,
  title = {Monte {{Carlo}} and Quasi-{{Monte Carlo}} Methods},
  author = {Caflisch, Russel E},
  journal = {MONTE CARLO},
  pages = {49},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Caflisch_Monte Carlo and quasi-Monte Carlo methods.pdf}
}

@inproceedings{caiFiniteMixtureModels2021,
  title = {Finite Mixture Models Do Not Reliably Learn the Number of Components},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Cai, Diana and Campbell, Trevor and Broderick, Tamara},
  year = {2021},
  month = jul,
  pages = {1158--1169},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-09-22},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Cai et al_2021_Finite mixture models do not reliably learn the number of components.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Cai et al_2021_Finite mixture models do not reliably learn the number of components2.pdf}
}

@article{caliendoPRACTICALGUIDANCEIMPLEMENTATION2008,
  title = {{{SOME PRACTICAL GUIDANCE FOR THE IMPLEMENTATION OF PROPENSITY SCORE MATCHING}}},
  author = {Caliendo, Marco and Kopeinig, Sabine},
  year = {2008},
  month = feb,
  journal = {Journal of Economic Surveys},
  volume = {22},
  number = {1},
  pages = {31--72},
  issn = {0950-0804, 1467-6419},
  doi = {10.1111/j.1467-6419.2007.00527.x},
  urldate = {2021-11-08},
  abstract = {Propensity Score Matching (PSM) has become a popular approach to estimate causal treatment effects. It is widely applied when evaluating labour market policies, but empirical examples can be found in very diverse fields of study. Once the researcher has decided to use PSM, he is confronted with a lot of questions regarding its implementation. To begin with, a first decision has to be made concerning the estimation of the propensity score. Following that one has to decide which matching algorithm to choose and determine the region of common support. Subsequently, the matching quality has to be assessed and treatment effects and their standard errors have to be estimated. Furthermore, questions like `what to do if there is choice-based sampling?' or `when to measure effects?' can be important in empirical studies. Finally, one might also want to test the sensitivity of estimated treatment effects with respect to unobserved heterogeneity or failure of the common support condition. Each implementation step involves a lot of decisions and different approaches can be thought of. The aim of this paper is to discuss these implementation issues and give some guidance to researchers who want to use PSM for evaluation purposes.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Caliendo_Kopeinig_2008_SOME PRACTICAL GUIDANCE FOR THE IMPLEMENTATION OF PROPENSITY SCORE MATCHING.pdf}
}

@misc{campbellAutomatedScalableBayesian2019,
  title = {Automated {{Scalable Bayesian Inference}} via {{Hilbert Coresets}}},
  author = {Campbell, Trevor and Broderick, Tamara},
  year = {2019},
  month = feb,
  number = {arXiv:1710.05053},
  eprint = {1710.05053},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-10-24},
  abstract = {The automation of posterior inference in Bayesian data analysis has enabled experts and nonexperts alike to use more sophisticated models, engage in faster exploratory modeling and analysis, and ensure experimental reproducibility. However, standard automated posterior inference algorithms are not tractable at the scale of massive modern datasets, and modifications to make them so are typically model-specific, require expert tuning, and can break theoretical guarantees on inferential quality. Building on the Bayesian coresets framework, this work instead takes advantage of data redundancy to shrink the dataset itself as a preprocessing step, providing fully-automated, scalable Bayesian inference with theoretical guarantees. We begin with an intuitive reformulation of Bayesian coreset construction as sparse vector sum approximation, and demonstrate that its automation and performance-based shortcomings arise from the use of the supremum norm. To address these shortcomings we develop Hilbert coresets, i.e., Bayesian coresets constructed under a norm induced by an inner-product on the log-likelihood function space. We propose two Hilbert coreset construction algorithms---one based on importance sampling, and one based on the Frank-Wolfe algorithm---along with theoretical guarantees on approximation quality as a function of coreset size. Since the exact computation of the proposed inner-products is model-specific, we automate the construction with a random finite-dimensional projection of the log-likelihood functions. The resulting automated coreset construction algorithm is simple to implement, and experiments on a variety of models with real and synthetic datasets show that it provides high-quality posterior approximations and a significant reduction in the computational cost of inference.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Campbell_Broderick_2019_Automated Scalable Bayesian Inference via Hilbert Coresets.pdf;/Users/lichengk/Zotero/storage/DAX4BHHT/1710.html}
}

@misc{canonneShortNoteInequality2022,
  title = {A Short Note on an Inequality between {{KL}} and {{TV}}},
  author = {Canonne, Cl{\'e}ment L.},
  year = {2022},
  month = feb,
  number = {arXiv:2202.07198},
  eprint = {2202.07198},
  primaryclass = {math, stat},
  publisher = {{arXiv}},
  urldate = {2022-08-31},
  abstract = {The goal of this short note is to discuss the relation between Kullback--Leibler divergence and total variation distance, starting with the celebrated Pinsker's inequality relating the two, before switching to a simple, yet (arguably) more useful inequality, apparently not as well known, due to Bretagnolle and Huber. We also discuss applications of this bound for minimax testing lower bounds.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Canonne_2022_A short note on an inequality between KL and TV.pdf;/Users/lichengk/Zotero/storage/LVMEIFKF/2202.html}
}

@article{chaiAutomatedModelSelection2019,
  title = {Automated {{Model Selection}} with {{Bayesian Quadrature}}},
  author = {Chai, Henry and Ton, Jean-Francois and Garnett, Roman and Osborne, Michael A.},
  year = {2019},
  month = mar,
  journal = {arXiv:1902.09724 [cs, stat]},
  eprint = {1902.09724},
  primaryclass = {cs, stat},
  urldate = {2021-08-08},
  abstract = {We present a novel technique for tailoring Bayesian quadrature (BQ) to model selection. The state-of-the-art for comparing the evidence of multiple models relies on Monte Carlo methods, which converge slowly and are unreliable for computationally expensive models. Previous research has shown that BQ offers sample efficiency superior to Monte Carlo in computing the evidence of an individual model. However, applying BQ directly to model comparison may waste computation producing an overly-accurate estimate for the evidence of a clearly poor model. We propose an automated and efficient algorithm for computing the most-relevant quantity for model selection: the posterior probability of a model. Our technique maximizes the mutual information between this quantity and observations of the models' likelihoods, yielding efficient acquisition of samples across disparate model spaces when likelihood observations are limited. Our method produces more-accurate model posterior estimates using fewer model likelihood evaluations than standard Bayesian quadrature and Monte Carlo estimators, as we demonstrate on synthetic and real-world examples.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Chai et al_2019_Automated Model Selection with Bayesian Quadrature.pdf;/Users/lichengk/Zotero/storage/L43LITSP/1902.html}
}

@inproceedings{chaiImprovingQuadratureConstrained2019,
  title = {Improving {{Quadrature}} for {{Constrained Integrands}}},
  booktitle = {Proceedings of the {{Twenty-Second International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Chai, Henry R. and Garnett, Roman},
  year = {2019},
  month = apr,
  pages = {2751--2759},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-10-24},
  abstract = {We present an improved Bayesian framework for performing inference of affine transformations of constrained functions. We focus on quadrature with nonnegative functions, a common task in Bayesian inference.  We consider constraints on the range of the function of interest, such as nonnegativity or boundedness. Although our framework is general, we derive explicit approximation schemes for these constraints, and argue for the use of a log transformation for functions with high dynamic range such as likelihood surfaces. We propose a novel method for optimizing hyperparameters in this framework: we optimize the marginal likelihood in the original space, as opposed to in the transformed space. The result is a model that better explains the actual data. Experiments on synthetic and real-world data demonstrate our framework achieves superior estimates using less wall-clock time than existing Bayesian quadrature procedures.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Chai_Garnett_2019_Improving Quadrature for Constrained Integrands.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Chai_Garnett_2019_Improving Quadrature for Constrained Integrands2.pdf}
}

@misc{chandraGradientDescentUltimate2022,
  title = {Gradient {{Descent}}: {{The Ultimate Optimizer}}},
  shorttitle = {Gradient {{Descent}}},
  author = {Chandra, Kartik and Xie, Audrey and {Ragan-Kelley}, Jonathan and Meijer, Erik},
  year = {2022},
  month = oct,
  number = {arXiv:1909.13371},
  eprint = {1909.13371},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-11-30},
  abstract = {Working with any gradient-based machine learning algorithm involves the tedious task of tuning the optimizer's hyperparameters, such as its step size. Recent work has shown how the step size can itself be optimized alongside the model parameters by manually deriving expressions for "hypergradients" ahead of time. We show how to automatically compute hypergradients with a simple and elegant modification to backpropagation. This allows us to easily apply the method to other optimizers and hyperparameters (e.g. momentum coefficients). We can even recursively apply the method to its own hyper-hyperparameters, and so on ad infinitum. As these towers of optimizers grow taller, they become less sensitive to the initial choice of hyperparameters. We present experiments validating this for MLPs, CNNs, and RNNs. Finally, we provide a simple PyTorch implementation of this algorithm (see people.csail.mit.edu/kach/gradient-descent-the-ultimate-optimizer).},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/TSLC5YU5/Chandra et al. - 2022 - Gradient Descent The Ultimate Optimizer.pdf;/Users/lichengk/Zotero/storage/4RCHI4YP/1909.html}
}

@article{chenBayesianOptimizationAlphaGo2018,
  title = {Bayesian {{Optimization}} in {{AlphaGo}}},
  author = {Chen, Yutian and Huang, Aja and Wang, Ziyu and Antonoglou, Ioannis and Schrittwieser, Julian and Silver, David and {de Freitas}, Nando},
  year = {2018},
  month = dec,
  journal = {arXiv:1812.06855 [cs, stat]},
  eprint = {1812.06855},
  primaryclass = {cs, stat},
  urldate = {2021-06-03},
  abstract = {During the development of AlphaGo, its many hyper-parameters were tuned with Bayesian optimization multiple times. This automatic tuning process resulted in substantial improvements in playing strength. For example, prior to the match with Lee Sedol, we tuned the latest AlphaGo agent and this improved its win-rate from 50\% to 66.5\% in self-play games. This tuned version was deployed in the final match. Of course, since we tuned AlphaGo many times during its development cycle, the compounded contribution was even higher than this percentage. It is our hope that this brief case study will be of interest to Go fans, and also provide Bayesian optimization practitioners with some insights and inspiration.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Chen et al_2018_Bayesian Optimization in AlphaGo.pdf;/Users/lichengk/Zotero/storage/UJMAITLG/1812.html}
}

@inproceedings{chenFastGreedyMAP2018,
  title = {Fast {{Greedy MAP Inference}} for {{Determinantal Point Process}} to {{Improve Recommendation Diversity}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Chen, Laming and Zhang, Guoxin and Zhou, Eric},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-09-01},
  abstract = {The determinantal point process (DPP) is an elegant probabilistic model of repulsion with applications in various machine learning tasks including summarization and search. However, the maximum a posteriori (MAP) inference for DPP which plays an important role in many applications is NP-hard, and even the popular greedy algorithm can still be too computationally expensive to be used in large-scale real-time scenarios. To overcome the computational challenge, in this paper, we propose a novel algorithm to greatly accelerate the greedy MAP inference for DPP. In addition, our algorithm also adapts to scenarios where the repulsion is only required among nearby few items in the result sequence. We apply the proposed algorithm to generate relevant and diverse recommendations. Experimental results show that our proposed algorithm is significantly faster than state-of-the-art competitors, and provides a better relevance-diversity trade-off on several public datasets, which is also confirmed in an online A/B test.},
  file = {/Users/lichengk/Zotero/storage/K2JLVNHR/Chen et al. - 2018 - Fast Greedy MAP Inference for Determinantal Point .pdf}
}

@article{chenHowPriorsInitial2018,
  title = {How Priors of Initial Hyperparameters Affect {{Gaussian}} Process Regression Models},
  author = {Chen, Zexun and Wang, Bo},
  year = {2018},
  month = jan,
  journal = {Neurocomputing},
  volume = {275},
  eprint = {1605.07906},
  pages = {1702--1710},
  issn = {09252312},
  doi = {10.1016/j.neucom.2017.10.028},
  urldate = {2021-11-11},
  abstract = {The hyperparameters in Gaussian process regression (GPR) model with a specified kernel are often estimated from the data via the maximum marginal likelihood. Due to the non-convexity of marginal likelihood with respect to the hyperparameters, the optimization may not converge to the global maxima. A common approach to tackle this issue is to use multiple starting points randomly selected from a specific prior distribution. As a result the choice of prior distribution may play a vital role in the predictability of this approach. However, there exists little research in the literature to study the impact of the prior distributions on the hyperparameter estimation and the performance of GPR. In this paper, we provide the first empirical study on this problem using simulated and real data experiments. We consider different types of priors for the initial values of hyperparameters for some commonly used kernels and investigate the influence of the priors on the predictability of GPR models. The results reveal that, once a kernel is chosen, different priors for the initial hyperparameters have no significant impact on the performance of GPR prediction, despite that the estimates of the hyperparameters are very different to the true values in some cases.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Machine Learning,toread},
  file = {/Users/lichengk/Zotero/storage/2X9LYGIX/Chen and Wang - 2018 - How priors of initial hyperparameters affect Gauss.pdf;/Users/lichengk/Zotero/storage/EIU7GLYS/1605.html}
}

@article{chenNovelCompressibleAdaptive2021,
  title = {Novel {{Compressible Adaptive Spectral Mixture Kernels}} for {{Gaussian Processes}} with {{Sparse Time}} and {{Phase Delay Structures}}},
  author = {Chen, Kai and Dai, Yijue and Yin, Feng and Marchiori, Elena and Theodoridis, Sergios},
  year = {2021},
  month = aug,
  journal = {arXiv:1808.00560 [cs, stat]},
  eprint = {1808.00560},
  primaryclass = {cs, stat},
  urldate = {2021-08-11},
  abstract = {Spectral mixture (SM) kernels comprise a powerful class of kernels for Gaussian processes (GPs) capable of discovering structurally complex patterns and modeling negative covariances. Being a linear superposition of quasi-periodical kernel components, the state-of-the-art SM kernel does not consider component compression and dependency structures between components. In this paper, we investigate the benefits of component compression and modeling of both time and phase delay structures between basis components in the SM kernel. By verifying the presence of dependencies between function components using Gaussian conditionals and posterior covariance, we first propose a new SM kernel variant with a time and phase delay dependency structure (SMD) and then provide a structure adaptation (SA) algorithm for the SMD. The SMD kernel is constructed in two steps: first, time delay and phase delay are incorporated into each basis component; next, cross-convolution between a basis component and the reversed complex conjugate of another basis component is performed, which yields a complex-valued and positive definite kernel incorporating dependency structures between basis components. The model compression and dependency sparsity of the SMD kernel can be obtained by using automatic pruning in SA. We perform a thorough comparative experimental analysis of the SMD on both synthetic and real-life datasets. The results corroborate the efficacy of the dependency structure and SA in the SMD.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/26N7FBHW/1808.html}
}

@inproceedings{chenStochasticGradientDescent2020,
  title = {Stochastic {{Gradient Descent}} in {{Correlated Settings}}: {{A Study}} on {{Gaussian Processes}}},
  shorttitle = {Stochastic {{Gradient Descent}} in {{Correlated Settings}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Chen, Hao and Zheng, Lili and AL Kontar, Raed and Raskutti, Garvesh},
  year = {2020},
  volume = {33},
  pages = {2722--2733},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2021-09-14},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Chen et al_2020_Stochastic Gradient Descent in Correlated Settings.pdf}
}

@inproceedings{chenStochasticGradientDescent2020a,
  title = {Stochastic {{Gradient Descent}} in {{Correlated Settings}}: {{A Study}} on {{Gaussian Processes}}},
  shorttitle = {Stochastic {{Gradient Descent}} in {{Correlated Settings}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Chen, Hao and Zheng, Lili and AL Kontar, Raed and Raskutti, Garvesh},
  year = {2020},
  volume = {33},
  pages = {2722--2733},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-04-20},
  file = {/Users/lichengk/Zotero/storage/UI3L6VBB/Chen et al. - 2020 - Stochastic Gradient Descent in Correlated Settings.pdf}
}

@misc{claiciWassersteinMeasureCoresets2020,
  title = {Wasserstein {{Measure Coresets}}},
  author = {Claici, Sebastian and Genevay, Aude and Solomon, Justin},
  year = {2020},
  month = mar,
  number = {arXiv:1805.07412},
  eprint = {1805.07412},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-02-28},
  abstract = {The proliferation of large data sets and Bayesian inference techniques motivates demand for better data sparsification. Coresets provide a principled way of summarizing a large dataset via a smaller one that is guaranteed to match the performance of the full data set on specific problems. Classical coresets, however, neglect the underlying data distribution, which is often continuous. We address this oversight by introducing Wasserstein measure coresets, an extension of coresets which by definition takes into account generalization. Our formulation of the problem, which essentially consists in minimizing the Wasserstein distance, is solvable via stochastic gradient descent. This yields an algorithm which simply requires sample access to the data distribution and is able to handle large data streams in an online manner. We validate our construction for inference and clustering.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Claici et al_2020_Wasserstein Measure Coresets.pdf;/Users/lichengk/Zotero/storage/3D6NNSX5/1805.html}
}

@misc{clarkeCheatSheetBayesian2023,
  title = {A {{Cheat Sheet}} for {{Bayesian Prediction}}},
  author = {Clarke, Bertrand and Yao, Yuling},
  year = {2023},
  month = apr,
  number = {arXiv:2304.12218},
  eprint = {2304.12218},
  primaryclass = {stat},
  publisher = {{arXiv}},
  urldate = {2023-05-28},
  abstract = {This paper reviews the growing field of Bayesian prediction. Bayes point and interval prediction are defined and exemplified and situated in statistical prediction more generally. Then, four general approaches to Bayes prediction are defined and we turn to predictor selection. This can be done predictively or non-predictively and predictors can be based on single models or multiple models. We call these latter cases unitary predictors and model average predictors, respectively. Then we turn to the most recent aspect of prediction to emerge, namely prediction in the context of large observational data sets and discuss three further classes of techniques. We conclude with a summary and statement of several current open problems.},
  archiveprefix = {arxiv},
  keywords = {62-02,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Clarke_Yao_2023_A Cheat Sheet for Bayesian Prediction.pdf;/Users/lichengk/Zotero/storage/HU6RZGCY/2304.html}
}

@article{clarkReliabilitybasedLayoutOptimization2021,
  title = {Reliability-Based Layout Optimization in Offshore Wind Energy Systems},
  author = {Clark, Caitlyn E. and Barter, Garrett and Shaler, Kelsey and DuPont, Bryony},
  year = {2021},
  journal = {Wind Energy},
  publisher = {{Wiley Online Library}},
  file = {/Users/lichengk/Zotero/storage/3LIC5CI4/we.html}
}

@article{cockayneBayesianProbabilisticNumerical2019a,
  title = {Bayesian {{Probabilistic Numerical Methods}}},
  author = {Cockayne, Jon and Oates, Chris and Sullivan, Tim and Girolami, Mark},
  year = {2019},
  month = jan,
  journal = {SIAM Review},
  volume = {61},
  number = {3},
  eprint = {1702.03673},
  pages = {756--789},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/17M1139357},
  urldate = {2021-09-23},
  abstract = {The emergent field of probabilistic numerics has thus far lacked clear statistical principals. This paper establishes Bayesian probabilistic numerical methods as those which can be cast as solutions to certain inverse problems within the Bayesian framework. This allows us to establish general conditions under which Bayesian probabilistic numerical methods are well-defined, encompassing both non-linear and non-Gaussian models. For general computation, a numerical approximation scheme is proposed and its asymptotic convergence established. The theoretical development is then extended to pipelines of computation, wherein probabilistic numerical methods are composed to solve more challenging numerical tasks. The contribution highlights an important research frontier at the interface of numerical analysis and uncertainty quantification, with a challenging industrial application presented.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Numerical Analysis,Mathematics - Statistics Theory,Statistics - Computation,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Cockayne et al_2019_Bayesian Probabilistic Numerical Methods3.pdf;/Users/lichengk/Zotero/storage/9QCLRZ63/1702.html}
}

@phdthesis{cohenEquivariantConvolutionalNetworks2021,
  title = {Equivariant Convolutional Networks},
  author = {Cohen, T. S.},
  year = {2021},
  urldate = {2021-05-28},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Cohen_2021_Equivariant convolutional networks.pdf;/Users/lichengk/Zotero/storage/TI652Y3N/search.html}
}

@misc{CommentsMLStatistics,
  title = {Comments on {{ML}} "versus" Statistics},
  urldate = {2021-06-11},
  howpublished = {https://sgfin.github.io/2020/01/31/Comments-ML-Statistics/},
  file = {/Users/lichengk/Zotero/storage/JTWHA4YM/Comments-ML-Statistics.html}
}

@misc{cornishRelaxingBijectivityConstraints2021,
  title = {Relaxing {{Bijectivity Constraints}} with {{Continuously Indexed Normalising Flows}}},
  author = {Cornish, Rob and Caterini, Anthony L. and Deligiannidis, George and Doucet, Arnaud},
  year = {2021},
  month = apr,
  number = {arXiv:1909.13833},
  eprint = {1909.13833},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-18},
  abstract = {We show that normalising flows become pathological when used to model targets whose supports have complicated topologies. In this scenario, we prove that a flow must become arbitrarily numerically noninvertible in order to approximate the target closely. This result has implications for all flow-based models, and especially Residual Flows (ResFlows), which explicitly control the Lipschitz constant of the bijection used. To address this, we propose Continuously Indexed Flows (CIFs), which replace the single bijection used by normalising flows with a continuously indexed family of bijections, and which can intuitively "clean up" mass that would otherwise be misplaced by a single bijection. We show theoretically that CIFs are not subject to the same topological limitations as normalising flows, and obtain better empirical performance on a variety of models and benchmarks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Cornish et al_2021_Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows.pdf;/Users/lichengk/Zotero/storage/Z8JEW8FM/1909.html}
}

@inproceedings{cortesImpactKernelApproximation2010,
  title = {On the {{Impact}} of {{Kernel Approximation}} on {{Learning Accuracy}}},
  booktitle = {Proceedings of the {{Thirteenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Cortes, Corinna and Mohri, Mehryar and Talwalkar, Ameet},
  year = {2010},
  month = mar,
  pages = {113--120},
  publisher = {{JMLR Workshop and Conference Proceedings}},
  issn = {1938-7228},
  urldate = {2021-08-16},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Cortes et al_2010_On the Impact of Kernel Approximation on Learning Accuracy.pdf}
}

@misc{CourseMAST32004Advanced,
  title = {Course: {{MAST32004}}, {{Advanced Bayesian Inference}}, 2022},
  urldate = {2022-04-09},
  howpublished = {https://moodle.helsinki.fi/course/view.php?id=51243},
  file = {/Users/lichengk/Zotero/storage/F3VAT7Y9/view.html}
}

@article{crameriMisuseColourScience2020,
  title = {The Misuse of Colour in Science Communication},
  author = {Crameri, Fabio and Shephard, Grace E. and Heron, Philip J.},
  year = {2020},
  month = oct,
  journal = {Nature Communications},
  volume = {11},
  number = {1},
  pages = {5444},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-19160-7},
  urldate = {2023-02-16},
  abstract = {The accurate representation of data is essential in science communication. However, colour maps that visually distort data through uneven colour gradients or are unreadable to those with colour-vision deficiency remain prevalent in science. These include, but are not limited to, rainbow-like and red\textendash green colour maps. Here, we present a simple guide for the scientific use of colour. We show how scientifically derived colour maps report true data variations, reduce complexity, and are accessible for people with colour-vision deficiencies. We highlight ways for the scientific community to identify and prevent the misuse of colour in science, and call for a proactive step away from colour misuse among the community, publishers, and the press.},
  copyright = {2020 The Author(s)},
  langid = {english},
  keywords = {Scientific community,Software},
  file = {/Users/lichengk/Zotero/storage/E33NJK3N/Crameri et al. - 2020 - The misuse of colour in science communication.pdf}
}

@article{cranmerFrontierSimulationbasedInference2020,
  title = {The Frontier of Simulation-Based Inference},
  author = {Cranmer, Kyle and Brehmer, Johann and Louppe, Gilles},
  year = {2020},
  month = dec,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {117},
  number = {48},
  eprint = {1911.01429},
  primaryclass = {cs, stat},
  pages = {30055--30062},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1912789117},
  urldate = {2023-05-24},
  abstract = {Many domains of science have developed complex simulations to describe phenomena of interest. While these simulations provide high-fidelity models, they are poorly suited for inference and lead to challenging inverse problems. We review the rapidly developing field of simulation-based inference and identify the forces giving new momentum to the field. Finally, we describe how the frontier is expanding so that a broad audience can appreciate the profound change these developments may have on science.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Cranmer et al_2020_The frontier of simulation-based inference.pdf;/Users/lichengk/Zotero/storage/29RVWNS9/1911.html}
}

@article{cunninghamSTATG8325,
  title = {{{STAT G8325}}},
  author = {Cunningham, John P.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Cunningham_STAT G8325.pdf}
}

@article{czolbeLossFunctionGenerative2020,
  title = {A {{Loss Function}} for {{Generative Neural Networks Based}} on {{Watson}}'s {{Perceptual Model}}},
  author = {Czolbe, Steffen and Krause, Oswin and Cox, Ingemar and Igel, Christian},
  year = {2020},
  journal = {arXiv preprint arXiv:2006.15057},
  eprint = {2006.15057},
  archiveprefix = {arxiv},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Czolbe et al_2020_A Loss Function for Generative Neural Networks Based on Watson's Perceptual.pdf;/Users/lichengk/Zotero/storage/DCZ2AWTF/2006.html}
}

@misc{dagumOptimalAlgorithmMonte1995,
  title = {An {{Optimal Algorithm}} for {{Monte Carlo Estimation}}},
  author = {Dagum, Paul and Karp, Richard and Luby, Michael and Ross, Sheldon},
  year = {1995},
  abstract = {A typical approach to estimate an unknown quantity  is to design an experiment that produces a random variable Z distributed in [0; 1] with E[Z] = , run this experiment independently a number of times and use the average of the outcomes as the estimate. In this paper, we consider the case when no a priori information about Z is known except that is distributed in [0; 1]. We describe an approximation algorithm AA which, given ffl and ffi, when running independent experiments with respect to any Z, produces an estimate that is within a factor 1 + ffl of  with probability at least 1 \textbackslash Gamma ffi. We prove that the expected number of experiments run by AA (which depends on Z) is optimal to within a constant factor for every Z.  An announcement of these results appears in P. Dagum, D. Karp, M. Luby, S. Ross, "An optimal algorithm for Monte-Carlo Estimation (extended abstract)", Proceedings of the Thirtysixth IEEE Symposium on Foundations of Computer Science,  1995, pp. 142-149 [3].   Section ...},
  file = {/Users/lichengk/Zotero/storage/WKXR7DZQ/Dagum et al. - 1995 - An Optimal Algorithm for Monte Carlo Estimation.pdf;/Users/lichengk/Zotero/storage/SBCYIJ5I/download.html}
}

@article{daiTranslationRotationEquivariant2022,
  title = {Translation and Rotation Equivariant Normalizing Flow ({{TRENF}}) for Optimal Cosmological Analysis},
  author = {Dai, Biwei and Seljak, Uro{\v s}},
  year = {2022},
  month = oct,
  journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {516},
  number = {2},
  pages = {2363--2373},
  issn = {0035-8711},
  doi = {10.1093/mnras/stac2010},
  urldate = {2022-12-13},
  abstract = {Our Universe is homogeneous and isotropic, and its perturbations obey translation and rotation symmetry. In this work, we develop translation and rotation equivariant normalizing flow (TRENF), a generative normalizing flow (NF) model which explicitly incorporates these symmetries, defining the data likelihood via a sequence of Fourier space-based convolutions and pixel-wise non-linear transforms. TRENF gives direct access to the high dimensional data likelihood p(x|y) as a function of the labels y, such as cosmological parameters. In contrast to traditional analyses based on summary statistics, the NF approach has no loss of information since it preserves the full dimensionality of the data. On Gaussian random fields, the TRENF likelihood agrees well with the analytical expression and saturates the Fisher information content in the labels y. On non-linear cosmological overdensity fields from N-body simulations, TRENF leads to significant improvements in constraining power over the standard power spectrum summary statistic. TRENF is also a generative model of the data, and we show that TRENF samples agree well with the N-body simulations it trained on, and that the inverse mapping of the data agrees well with a Gaussian white noise both visually and on various summary statistics: when this is perfectly achieved the resulting p(x|y) likelihood analysis becomes optimal. Finally, we develop a generalization of this model that can handle effects that break the symmetry of the data, such as the survey mask, which enables likelihood analysis on data without periodic boundaries.},
  file = {/Users/lichengk/Zotero/storage/SZUGZZ6I/Dai and Seljak - 2022 - Translation and rotation equivariant normalizing f.pdf;/Users/lichengk/Zotero/storage/APV4BXLG/6649319.html}
}

@article{dalalApproximatingPriorsMixtures1983,
  title = {Approximating {{Priors}} by {{Mixtures}} of {{Natural Conjugate Priors}}},
  author = {Dalal, S. R. and Hall, W. J.},
  year = {1983},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {45},
  number = {2},
  eprint = {2345533},
  eprinttype = {jstor},
  pages = {278--286},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0035-9246},
  urldate = {2021-09-21},
  abstract = {The purpose of this paper is twofold: First, to show that a natural enlargement of the class of natural conjugate priors--namely, mixtures of natural conjugate priors--also leads to mathematically tractable solutions. Secondly, to show that this enlargement is "adequate" in that any prior may be arbitrarily closely approximated by a suitable member of this class. Specifically, a general method for approximating an arbitrary prior density is first given with approximation (convergence) defined pointwise or in the L\textsubscript{1} or total variation senses. Corresponding posterior densities are shown to provide approximations in corresponding senses, whether or not the approximating priors are those given herein. Then formulas are given for posterior densities when the prior is a mixture of natural conjugate priors, and it is shown that an arbitrary prior density and its posterior density may be approximated by such a mixture and its posterior. In these senses, Bayesians may find it satisfactory to confine attention to mixtures of natural conjugate priors. The results are illustrated by several exponential family examples.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Dalal_Hall_1983_Approximating Priors by Mixtures of Natural Conjugate Priors.pdf}
}

@inproceedings{damianouDeepGaussianProcesses2013,
  title = {Deep Gaussian Processes},
  booktitle = {Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics, {{AISTATS}} 2013, Scottsdale, {{AZ}}, {{USA}}, April 29 - May 1, 2013},
  author = {Damianou, Andreas C. and Lawrence, Neil D.},
  year = {2013},
  series = {{{JMLR}} Workshop and Conference Proceedings},
  volume = {31},
  pages = {207--215},
  publisher = {{JMLR.org}},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/aistats/DamianouL13.bib},
  timestamp = {Wed, 29 May 2019 08:41:44 +0200},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Damianou_Lawrence_2013_Deep gaussian processes.pdf}
}

@misc{daxbergerLaplaceReduxEffortless2022,
  title = {Laplace {{Redux}} -- {{Effortless Bayesian Deep Learning}}},
  author = {Daxberger, Erik and Kristiadi, Agustinus and Immer, Alexander and Eschenhagen, Runa and Bauer, Matthias and Hennig, Philipp},
  year = {2022},
  month = mar,
  number = {arXiv:2106.14806},
  eprint = {2106.14806},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2106.14806},
  urldate = {2023-03-22},
  abstract = {Bayesian formulations of deep learning have been shown to have compelling theoretical properties and offer practical functional benefits, such as improved predictive uncertainty quantification and model selection. The Laplace approximation (LA) is a classic, and arguably the simplest family of approximations for the intractable posteriors of deep neural networks. Yet, despite its simplicity, the LA is not as popular as alternatives like variational Bayes or deep ensembles. This may be due to assumptions that the LA is expensive due to the involved Hessian computation, that it is difficult to implement, or that it yields inferior results. In this work we show that these are misconceptions: we (i) review the range of variants of the LA including versions with minimal cost overhead; (ii) introduce "laplace", an easy-to-use software library for PyTorch offering user-friendly access to all major flavors of the LA; and (iii) demonstrate through extensive experiments that the LA is competitive with more popular alternatives in terms of performance, while excelling in terms of computational cost. We hope that this work will serve as a catalyst to a wider adoption of the LA in practical deep learning, including in domains where Bayesian approaches are not typically considered at the moment.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Daxberger et al_2022_Laplace Redux -- Effortless Bayesian Deep Learning.pdf;/Users/lichengk/Zotero/storage/RFYKINLC/2106.html}
}

@misc{daxNeuralImportanceSampling2022,
  title = {Neural {{Importance Sampling}} for {{Rapid}} and {{Reliable Gravitational-Wave Inference}}},
  author = {Dax, Maximilian and Green, Stephen R. and Gair, Jonathan and P{\"u}rrer, Michael and Wildberger, Jonas and Macke, Jakob H. and Buonanno, Alessandra and Sch{\"o}lkopf, Bernhard},
  year = {2022},
  month = oct,
  number = {arXiv:2210.05686},
  eprint = {2210.05686},
  primaryclass = {astro-ph, physics:gr-qc},
  publisher = {{arXiv}},
  urldate = {2022-11-22},
  abstract = {We combine amortized neural posterior estimation with importance sampling for fast and accurate gravitational-wave inference. We first generate a rapid proposal for the Bayesian posterior using neural networks, and then attach importance weights based on the underlying likelihood and prior. This provides (1) a corrected posterior free from network inaccuracies, (2) a performance diagnostic (the sample efficiency) for assessing the proposal and identifying failure cases, and (3) an unbiased estimate of the Bayesian evidence. By establishing this independent verification and correction mechanism we address some of the most frequent criticisms against deep learning for scientific inference. We carry out a large study analyzing 42 binary black hole mergers observed by LIGO and Virgo with the SEOBNRv4PHM and IMRPhenomXPHM waveform models. This shows a median sample efficiency of \$\textbackslash approx 10\textbackslash\%\$ (two orders-of-magnitude better than standard samplers) as well as a ten-fold reduction in the statistical uncertainty in the log evidence. Given these advantages, we expect a significant impact on gravitational-wave inference, and for this approach to serve as a paradigm for harnessing deep learning methods in scientific applications.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics,Computer Science - Machine Learning,General Relativity and Quantum Cosmology},
  file = {/Users/lichengk/Zotero/storage/BTQCN2N7/Dax et al. - 2022 - Neural Importance Sampling for Rapid and Reliable .pdf;/Users/lichengk/Zotero/storage/R432QK3Q/2210.html}
}

@book{debnathIntegralTransformsTheir2014,
  title = {Integral {{Transforms}} and {{Their Applications}}},
  author = {Debnath, Lokenath and Bhatta, Dambaru},
  year = {2014},
  month = nov,
  edition = {Zeroth},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/b17670},
  urldate = {2021-09-12},
  isbn = {978-0-429-16263-3},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Debnath_Bhatta_2014_Integral Transforms and Their Applications.pdf}
}

@book{deisenrothMathematicsMachineLearning2020,
  title = {Mathematics for Machine Learning},
  author = {Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng Soon},
  year = {2020},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge ; New York, NY}},
  abstract = {"The fundamental mathematical tools needed to understand machine learning include linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability, and statistics. These topics are traditionally taught in disparate courses, making it hard for data science or computer science students, or professionals, to efficiently learn the mathematics. This self-contained textbook bridges the gap between mathematical and machine learning texts, introducing the mathematical concepts with a minimum of prerequisites. It uses these concepts to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models, and support vector machines. For students and others with a mathematical background, these derivations provide a starting point to machine learning texts. For those learning the mathematics for the first time, the methods help build intuition and practical experience with applying mathematical concepts"--},
  isbn = {978-1-108-47004-9 978-1-108-45514-5},
  lccn = {Q325.5 .D45 2020},
  keywords = {Machine learning,Mathematics},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Deisenroth et al_Mathematics for Machine Learning.pdf}
}

@misc{dellaportaRobustBayesianInference2022,
  title = {Robust {{Bayesian Inference}} for {{Simulator-based Models}} via the {{MMD Posterior Bootstrap}}},
  author = {Dellaporta, Charita and Knoblauch, Jeremias and Damoulas, Theodoros and Briol, Fran{\c c}ois-Xavier},
  year = {2022},
  month = dec,
  number = {arXiv:2202.04744},
  eprint = {2202.04744},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2202.04744},
  urldate = {2023-02-02},
  abstract = {Simulator-based models are models for which the likelihood is intractable but simulation of synthetic data is possible. They are often used to describe complex real-world phenomena, and as such can often be misspecified in practice. Unfortunately, existing Bayesian approaches for simulators are known to perform poorly in those cases. In this paper, we propose a novel algorithm based on the posterior bootstrap and maximum mean discrepancy estimators. This leads to a highly-parallelisable Bayesian inference algorithm with strong robustness properties. This is demonstrated through an in-depth theoretical study which includes generalisation bounds and proofs of frequentist consistency and robustness of our posterior. The approach is then assessed on a range of examples including a g-and-k distribution and a toggle-switch model.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/Zotero/storage/RYN6YANS/Dellaporta et al. - 2022 - Robust Bayesian Inference for Simulator-based Mode.pdf;/Users/lichengk/Zotero/storage/AV276SNX/2202.html}
}

@misc{DenoisingDiffusionbasedGenerative,
  title = {Denoising {{Diffusion-based Generative Modeling}}: {{Foundations}} and {{Applications}}},
  shorttitle = {Denoising {{Diffusion-based Generative Modeling}}},
  journal = {Denoising Diffusion-based Generative Modeling: Foundations and Applications},
  urldate = {2022-06-20},
  abstract = {Tutorial in Conjunction with CVPR 2022},
  howpublished = {https://cvpr2022-tutorial-diffusion-models.github.io},
  file = {/Users/lichengk/Zotero/storage/PE66WMR6/cvpr2022-tutorial-diffusion-models.github.io.html}
}

@misc{DerivingInformationEntropy,
  title = {Deriving the Information Entropy of the Multivariate Gaussian},
  urldate = {2021-06-11},
  howpublished = {https://sgfin.github.io/2017/03/11/Deriving-the-information-entropy-of-the-multivariate-gaussian/},
  file = {/Users/lichengk/Zotero/storage/X9B79ZKA/Deriving-the-information-entropy-of-the-multivariate-gaussian.html}
}

@article{diaconisBayesianNumericalAnalysis1988,
  title = {Bayesian {{Numerical Analysis}}},
  author = {Diaconis, P.},
  year = {1988},
  journal = {undefined},
  urldate = {2021-05-26},
  abstract = {Semantic Scholar extracted view of \&quot;Bayesian Numerical Analysis\&quot; by P. Diaconis},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Diaconis_1988_Bayesian Numerical Analysis.pdf;/Users/lichengk/Zotero/storage/QK4VL6CH/bed94ff3851ea67c44da91968cf04acb6fe50f2a.html}
}

@article{dickHighdimensionalIntegrationQuasiMonte2013,
  title = {High-Dimensional Integration: {{The}} Quasi-{{Monte Carlo}} Way},
  shorttitle = {High-Dimensional Integration},
  author = {Dick, Josef and Kuo, Frances Y. and Sloan, Ian H.},
  year = {2013},
  month = may,
  journal = {Acta Numerica},
  volume = {22},
  pages = {133--288},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492913000044},
  urldate = {2023-02-28},
  abstract = {This paper is a contemporary review of QMC (`quasi-Monte Carlo') methods, that is, equal-weight rules for the approximate evaluation of high-dimensional integrals over the unit cube [0,1]                                s                              , where               s               may be large, or even infinite. After a general introduction, the paper surveys recent developments in lattice methods, digital nets, and related themes. Among those recent developments are methods of construction of both lattices and digital nets, to yield QMC rules that have a prescribed rate of convergence for sufficiently smooth functions, and ideally also guaranteed slow growth (or no growth) of the worst-case error as s increases. A crucial role is played by parameters called `weights', since a careful use of the weight parameters is needed to ensure that the worst-case errors in an appropriately weighted function space are bounded, or grow only slowly, as the dimension s increases. Important tools for the analysis are weighted function spaces, reproducing kernel Hilbert spaces, and discrepancy, all of which are discussed with an appropriate level of detail.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/LW5EZD3F/Dick et al. - 2013 - High-dimensional integration The quasi-Monte Carl.pdf}
}

@inproceedings{domkeImportanceWeightingVariational2018a,
  title = {Importance {{Weighting}} and {{Variational Inference}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Domke, Justin and Sheldon, Daniel R},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-03-24},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Domke_Sheldon_2018_Importance Weighting and Variational Inference.pdf}
}

@misc{doucetScoreBasedDiffusionMeets2022,
  title = {Score-{{Based Diffusion}} Meets {{Annealed Importance Sampling}}},
  author = {Doucet, Arnaud and Grathwohl, Will and Matthews, Alexander G. D. G. and Strathmann, Heiko},
  year = {2022},
  month = oct,
  number = {arXiv:2208.07698},
  eprint = {2208.07698},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-12-06},
  abstract = {More than twenty years after its introduction, Annealed Importance Sampling (AIS) remains one of the most effective methods for marginal likelihood estimation. It relies on a sequence of distributions interpolating between a tractable initial distribution and the target distribution of interest which we simulate from approximately using a non-homogeneous Markov chain. To obtain an importance sampling estimate of the marginal likelihood, AIS introduces an extended target distribution to reweight the Markov chain proposal. While much effort has been devoted to improving the proposal distribution used by AIS, an underappreciated issue is that AIS uses a convenient but suboptimal extended target distribution. We here leverage recent progress in score-based generative modeling (SGM) to approximate the optimal extended target distribution minimizing the variance of the marginal likelihood estimate for AIS proposals corresponding to the discretization of Langevin and Hamiltonian dynamics. We demonstrate these novel, differentiable, AIS procedures on a number of synthetic benchmark distributions and variational auto-encoders.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Doucet et al_2022_Score-Based Diffusion meets Annealed Importance Sampling.pdf;/Users/lichengk/Zotero/storage/TJ6E4SUN/2208.html}
}

@book{doucetSequentialMonteCarlo2001,
  title = {Sequential {{Monte Carlo Methods}} in {{Practice}}},
  editor = {Doucet, Arnaud and Freitas, Nando and Gordon, Neil},
  year = {2001},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4757-3437-9},
  urldate = {2022-12-05},
  isbn = {978-1-4419-2887-0 978-1-4757-3437-9},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Doucet et al_2001_Sequential Monte Carlo Methods in Practice.pdf}
}

@inproceedings{durkanContrastiveLearningLikelihoodfree2020,
  title = {On {{Contrastive Learning}} for {{Likelihood-free Inference}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Durkan, Conor and Murray, Iain and Papamakarios, George},
  year = {2020},
  month = nov,
  pages = {2771--2781},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-10-27},
  abstract = {Likelihood-free methods perform parameter inference in stochastic simulator models where evaluating the likelihood is intractable but sampling synthetic data is possible. One class of methods for this likelihood-free problem uses a classifier to distinguish between pairs of parameter-observation samples generated using the simulator and pairs sampled from some reference distribution, which implicitly learns a density ratio proportional to the likelihood. Another popular class of methods fits a conditional distribution to the parameter posterior directly, and a particular recent variant allows for the use of flexible neural density estimators for this task. In this work, we show that both of these approaches can be unified under a general contrastive learning scheme, and clarify how they should be run and compared.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Durkan et al_2020_On Contrastive Learning for Likelihood-free Inference.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Durkan et al_2020_On Contrastive Learning for Likelihood-free Inference2.pdf}
}

@misc{durkanNeuralSplineFlows2019,
  title = {Neural {{Spline Flows}}},
  author = {Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
  year = {2019},
  month = dec,
  number = {arXiv:1906.04032},
  eprint = {1906.04032},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-16},
  abstract = {A normalizing flow models a complex probability density as an invertible transformation of a simple base density. Flows based on either coupling or autoregressive transforms both offer exact density evaluation and sampling, but rely on the parameterization of an easily invertible elementwise transformation, whose choice determines the flexibility of these models. Building upon recent work, we propose a fully-differentiable module based on monotonic rational-quadratic splines, which enhances the flexibility of both coupling and autoregressive transforms while retaining analytic invertibility. We demonstrate that neural spline flows improve density estimation, variational inference, and generative modeling of images.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/FQLPERMU/Durkan et al. - 2019 - Neural Spline Flows.pdf;/Users/lichengk/Zotero/storage/HGVDQG4H/1906.html}
}

@misc{dutordoirNeuralDiffusionProcesses2022,
  title = {Neural {{Diffusion Processes}}},
  author = {Dutordoir, Vincent and Saul, Alan and Ghahramani, Zoubin and Simpson, Fergus},
  year = {2022},
  month = jun,
  number = {arXiv:2206.03992},
  eprint = {2206.03992},
  primaryclass = {cs, stat},
  institution = {{arXiv}},
  urldate = {2022-06-15},
  abstract = {Gaussian processes provide an elegant framework for specifying prior and posterior distributions over functions. They are, however, also computationally expensive, and limited by the expressivity of their covariance function. We propose Neural Diffusion Processes (NDPs), a novel approach based upon diffusion models, that learn to sample from distributions over functions. Using a novel attention block, we can incorporate properties of stochastic processes, such as exchangeability, directly into the NDP's architecture. We empirically show that NDPs are able to capture functional distributions that are close to the true Bayesian posterior of a Gaussian process. This enables a variety of downstream tasks, including hyperparameter marginalisation and Bayesian optimisation.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/N3RG6QSV/Dutordoir et al. - 2022 - Neural Diffusion Processes.pdf;/Users/lichengk/Zotero/storage/Z2A5BGZG/2206.html}
}

@article{dutordoirSparseGaussianProcesses2020,
  title = {Sparse {{Gaussian Processes}} with {{Spherical Harmonic Features}}},
  author = {Dutordoir, Vincent and Durrande, Nicolas and Hensman, James},
  year = {2020},
  month = jun,
  journal = {arXiv:2006.16649 [cs, stat]},
  eprint = {2006.16649},
  primaryclass = {cs, stat},
  urldate = {2022-03-21},
  abstract = {We introduce a new class of inter-domain variational Gaussian processes (GP) where data is mapped onto the unit hypersphere in order to use spherical harmonic representations. Our inference scheme is comparable to variational Fourier features, but it does not suffer from the curse of dimensionality, and leads to diagonal covariance matrices between inducing variables. This enables a speed-up in inference, because it bypasses the need to invert large covariance matrices. Our experiments show that our model is able to fit a regression model for a dataset with 6 million entries two orders of magnitude faster compared to standard sparse GPs, while retaining state of the art accuracy. We also demonstrate competitive performance on classification with non-conjugate likelihoods.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Dutordoir et al_2020_Sparse Gaussian Processes with Spherical Harmonic Features.pdf;/Users/lichengk/Zotero/storage/MV7SGPTP/2006.html}
}

@inproceedings{duvenaudAvoidingPathologiesVery2014,
  title = {Avoiding Pathologies in Very Deep Networks},
  booktitle = {Proceedings of the {{Seventeenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Duvenaud, David and Rippel, Oren and Adams, Ryan and Ghahramani, Zoubin},
  year = {2014},
  month = apr,
  pages = {202--210},
  publisher = {{PMLR}},
  issn = {1938-7228},
  urldate = {2023-06-07},
  abstract = {Choosing appropriate architectures and regularization strategies of deep networks is crucial to good predictive performance.  To shed light on this problem, we analyze the analogous problem of constructing useful priors on compositions of functions.  Specifically, we study the deep Gaussian process, a type of infinitely-wide, deep neural network.  We show that in standard architectures, the representational capacity of the network tends to capture fewer degrees of freedom as the number of layers increases, retaining only a single degree of freedom in the limit.  We propose an alternate network architecture which does not suffer from this pathology.  We also examine deep covariance functions, obtained by composing infinitely many feature transforms.  Lastly, we characterize the class of models obtained by performing dropout on Gaussian processes.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Duvenaud et al_2014_Avoiding pathologies in very deep networks.pdf}
}

@misc{duvenaudBayesianQuadratureModelbased2012,
  title = {Bayesian {{Quadrature}}: {{Model-based Approximate Integration}}},
  author = {Duvenaud, David},
  year = {2012},
  urldate = {2021-05-17},
  annotation = {not clear},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Duvenaud_2012_Bayesian Quadrature.pdf}
}

@article{duvenaudStructureDiscoveryNonparametric2013,
  title = {Structure {{Discovery}} in {{Nonparametric Regression}} through {{Compositional Kernel Search}}},
  author = {Duvenaud, David and Lloyd, James Robert and Grosse, Roger and Tenenbaum, Joshua B. and Ghahramani, Zoubin},
  year = {2013},
  month = may,
  journal = {arXiv:1302.4922 [cs, stat]},
  eprint = {1302.4922},
  primaryclass = {cs, stat},
  urldate = {2021-12-04},
  abstract = {Despite its importance, choosing the structural form of the kernel in nonparametric regression remains a black art. We define a space of kernel structures which are built compositionally by adding and multiplying a small number of base kernels. We present a method for searching over this space of structures which mirrors the scientific discovery process. The learned structures can often decompose functions into interpretable components and enable long-range extrapolation on time-series datasets. Our structure search method outperforms many widely used kernels and kernel combination methods on a variety of prediction tasks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,G.3,I.2.6,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/Zotero/storage/W88NX7YB/Duvenaud et al. - 2013 - Structure Discovery in Nonparametric Regression th.pdf;/Users/lichengk/Zotero/storage/APZXAQYY/1302.html}
}

@misc{dwivediKernelThinning2022,
  title = {Kernel {{Thinning}}},
  author = {Dwivedi, Raaz and Mackey, Lester},
  year = {2022},
  month = jul,
  number = {arXiv:2105.05842},
  eprint = {2105.05842},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2105.05842},
  urldate = {2023-03-06},
  abstract = {We introduce kernel thinning, a new procedure for compressing a distribution \$\textbackslash mathbb\{P\}\$ more effectively than i.i.d. sampling or standard thinning. Given a suitable reproducing kernel \$\textbackslash mathbf\{k\}\$ and \$\textbackslash mathcal\{O\}(n\^2)\$ time, kernel thinning compresses an \$n\$-point approximation to \$\textbackslash mathbb\{P\}\$ into a \$\textbackslash sqrt\{n\}\$-point approximation with comparable worst-case integration error across the associated reproducing kernel Hilbert space. With high probability, the maximum discrepancy in integration error is \$\textbackslash mathcal\{O\}\_d(n\^\{-1/2\}\textbackslash sqrt\{\textbackslash log n\})\$ for compactly supported \$\textbackslash mathbb\{P\}\$ and \$\textbackslash mathcal\{O\}\_d(n\^\{-\textbackslash frac\{1\}\{2\}\} (\textbackslash log n)\^\{(d+1)/2\}\textbackslash sqrt\{\textbackslash log\textbackslash log n\})\$ for sub-exponential \$\textbackslash mathbb\{P\}\$ on \$\textbackslash mathbb\{R\}\^d\$. In contrast, an equal-sized i.i.d. sample from \$\textbackslash mathbb\{P\}\$ suffers \$\textbackslash Omega(n\^\{-1/4\})\$ integration error. Our sub-exponential guarantees resemble the classical quasi-Monte Carlo error rates for uniform \$\textbackslash mathbb\{P\}\$ on \$[0,1]\^d\$ but apply to general distributions on \$\textbackslash mathbb\{R\}\^d\$ and a wide range of common kernels. We use our results to derive explicit non-asymptotic maximum mean discrepancy bounds for Gaussian, Mat\textbackslash 'ern, and B-spline kernels and present two vignettes illustrating the practical benefits of kernel thinning over i.i.d. sampling and standard Markov chain Monte Carlo thinning, in dimensions \$d=2\$ through \$100\$.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/Zotero/storage/TJEATI6N/Dwivedi and Mackey - 2022 - Kernel Thinning.pdf;/Users/lichengk/Zotero/storage/CDZ45BRH/2105.html}
}

@misc{eduardoBayesianOptimizationInformative2022,
  title = {Bayesian {{Optimization}} with {{Informative Covariance}}},
  author = {Eduardo, Afonso and Gutmann, Michael U.},
  year = {2022},
  month = aug,
  number = {arXiv:2208.02704},
  eprint = {2208.02704},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-08-09},
  abstract = {Bayesian Optimization is a methodology for global optimization of unknown and expensive objectives. It combines a surrogate Bayesian regression model with an acquisition function to decide where to evaluate the objective. Typical regression models are Gaussian processes with stationary covariance functions, which, however, are unable to express prior input-dependent information, in particular information about possible locations of the optimum. The ubiquity of stationary models has led to the common practice of exploiting prior information via informative mean functions. In this paper, we highlight that these models can lead to poor performance, especially in high dimensions. We propose novel informative covariance functions that leverage nonstationarity to encode preferences for certain regions of the search space and adaptively promote local exploration during the optimization. We demonstrate that they can increase the sample efficiency of the optimization in high dimensions, even under weak prior information.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Eduardo_Gutmann_2022_Bayesian Optimization with Informative Covariance.pdf;/Users/lichengk/Zotero/storage/W3CHR8XN/2208.html}
}

@inproceedings{eggenspergerEfficientBenchmarkingHyperparameter2015,
  title = {Efficient Benchmarking of Hyperparameter Optimizers via Surrogates},
  booktitle = {Proceedings of the {{Twenty-Ninth AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Eggensperger, Katharina and Hutter, Frank and Hoos, Holger H. and {Leyton-Brown}, Kevin},
  year = {2015},
  month = jan,
  series = {{{AAAI}}'15},
  pages = {1114--1120},
  publisher = {{AAAI Press}},
  address = {{Austin, Texas}},
  urldate = {2021-10-25},
  abstract = {Hyperparameter optimization is crucial for achieving peak performance with many machine learning algorithms; however, the evaluation of new optimization techniques on real-world hyperparameter optimization problems can be very expensive. Therefore, experiments are often performed using cheap synthetic test functions with characteristics rather different from those of real benchmarks of interest. In this work, we introduce another option: cheap-to-evaluate surrogates of real hyperparameter optimization benchmarks that share the same hyperparameter spaces and feature similar response surfaces. Specifically, we train regression models on data describing a machine learning algorithm's performance depending on its hyperparameter setting, and then cheaply evaluate hyperparameter optimization methods using the model's performance predictions in lieu of running the real algorithm. We evaluated a wide range of regression techniques, both in terms of how well they predict the performance of new hyperparameter settings and in terms of the quality of surrogate benchmarks obtained. We found that tree-based models capture the performance of several machine learning algorithms well and yield surrogate benchmarks that closely resemble real-world benchmarks, while being much easier to use and orders of magnitude cheaper to evaluate.},
  isbn = {978-0-262-51129-2},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Eggensperger et al_2015_Efficient benchmarking of hyperparameter optimizers via surrogates.pdf}
}

@inproceedings{erikssonScalableConstrainedBayesian2021,
  title = {Scalable {{Constrained Bayesian Optimization}}},
  booktitle = {Proceedings of {{The}} 24th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Eriksson, David and Poloczek, Matthias},
  year = {2021},
  month = mar,
  pages = {730--738},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-12-07},
  abstract = {The global optimization of a high-dimensional black-box function under black-box constraints is a pervasive task in machine learning, control, and engineering. These problems are challenging since the feasible set is typically non-convex and hard to find, in addition to the curses of dimensionality and the heterogeneity of the underlying functions. In particular, these characteristics dramatically impact the performance of Bayesian optimization methods, that otherwise have become the defacto standard for sample-efficient optimization in unconstrained settings, leaving practitioners with evolutionary strategies or heuristics. We propose the scalable constrained Bayesian optimization (SCBO) algorithm that overcomes the above challenges and pushes the applicability of Bayesian optimization far beyond the state-of-the-art. A comprehensive experimental evaluation demonstrates that SCBO achieves excellent results on a variety of benchmarks. To this end, we propose two new control problems that we expect to be of independent value for the scientific community.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Eriksson_Poloczek_2021_Scalable Constrained Bayesian Optimization.pdf;/Users/lichengk/Zotero/storage/ZHHHZYQD/Eriksson and Poloczek - 2021 - Scalable Constrained Bayesian Optimization.pdf}
}

@inproceedings{erikssonScalingGaussianProcess2018,
  title = {Scaling {{Gaussian Process Regression}} with {{Derivatives}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Eriksson, David and Dong, Kun and Lee, Eric and Bindel, David and Wilson, Andrew G},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2021-12-10},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Eriksson et al_2018_Scaling Gaussian Process Regression with Derivatives.pdf}
}

@article{eskenazisGaussianMixturesEntropy2018,
  title = {Gaussian Mixtures: Entropy and Geometric Inequalities},
  shorttitle = {Gaussian Mixtures},
  author = {Eskenazis, Alexandros and Nayar, Piotr and Tkocz, Tomasz},
  year = {2018},
  month = sep,
  journal = {The Annals of Probability},
  volume = {46},
  number = {5},
  eprint = {1611.04921},
  issn = {0091-1798},
  doi = {10.1214/17-AOP1242},
  urldate = {2021-06-21},
  abstract = {A symmetric random variable is called a Gaussian mixture if it has the same distribution as the product of two independent random variables, one being positive and the other a standard Gaussian random variable. Examples of Gaussian mixtures include random variables with densities proportional to \$e\^\{-|t|\^p\}\$ and symmetric \$p\$-stable random variables, where \$p\textbackslash in(0,2]\$. We obtain various sharp moment and entropy comparison estimates for weighted sums of independent Gaussian mixtures and investigate extensions of the B-inequality and the Gaussian correlation inequality in the context of Gaussian mixtures. We also obtain a correlation inequality for symmetric geodesically convex sets in the unit sphere equipped with the normalized surface area measure. We then apply these results to derive sharp constants in Khintchine inequalities for vectors uniformly distributed on the unit balls with respect to \$p\$-norms and provide short proofs to new and old comparison estimates for geometric parameters of sections and projections of such balls.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Information Theory,Mathematics - Functional Analysis,Mathematics - Metric Geometry,Mathematics - Probability},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Eskenazis et al_2018_Gaussian mixtures.pdf;/Users/lichengk/Zotero/storage/25LBIV2R/1611.html}
}

@unpublished{ExponentialFamilyBasics,
  title = {The Exponential Family {{Basics}}},
  urldate = {2022-02-11},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/The exponential family Basics.pdf}
}

@article{fergusonBayesianAnalysisNonparametric1973,
  title = {A {{Bayesian Analysis}} of {{Some Nonparametric Problems}}},
  author = {Ferguson, Thomas S.},
  year = {1973},
  month = mar,
  journal = {The Annals of Statistics},
  volume = {1},
  number = {2},
  pages = {209--230},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1176342360},
  urldate = {2023-01-24},
  abstract = {The Bayesian approach to statistical problems, though fruitful in many ways, has been rather unsuccessful in treating nonparametric problems. This is due primarily to the difficulty in finding workable prior distributions on the parameter space, which in nonparametric ploblems is taken to be a set of probability distributions on a given sample space. There are two desirable properties of a prior distribution for nonparametric problems. (I) The support of the prior distribution should be large--with respect to some suitable topology on the space of probability distributions on the sample space. (II) Posterior distributions given a sample of observations from the true probability distribution should be manageable analytically. These properties are antagonistic in the sense that one may be obtained at the expense of the other. This paper presents a class of prior distributions, called Dirichlet process priors, broad in the sense of (I), for which (II) is realized, and for which treatment of many nonparametric statistical problems may be carried out, yielding results that are comparable to the classical theory. In Section 2, we review the properties of the Dirichlet distribution needed for the description of the Dirichlet process given in Section 3. Briefly, this process may be described as follows. Let \$\textbackslash mathscr\{X\}\$ be a space and \$\textbackslash mathscr\{A\}\$ a \$\textbackslash sigma\$-field of subsets, and let \$\textbackslash alpha\$ be a finite non-null measure on \$(\textbackslash mathscr\{X\}, \textbackslash mathscr\{A\})\$. Then a stochastic process \$P\$ indexed by elements \$A\$ of \$\textbackslash mathscr\{A\}\$, is said to be a Dirichlet process on \$(\textbackslash mathscr\{X\}, \textbackslash mathscr\{A\})\$ with parameter \$\textbackslash alpha\$ if for any measurable partition \$(A\_1, \textbackslash cdots, A\_k)\$ of \$\textbackslash mathscr\{X\}\$, the random vector \$(P(A\_1), \textbackslash cdots, P(A\_k))\$ has a Dirichlet distribution with parameter \$(\textbackslash alpha(A\_1), \textbackslash cdots, \textbackslash alpha(A\_k)). P\$ may be considered a random probability measure on \$(\textbackslash mathscr\{X\}, \textbackslash mathscr\{A\})\$, The main theorem states that if \$P\$ is a Dirichlet process on \$(\textbackslash mathscr\{X\}, \textbackslash mathscr\{A\})\$ with parameter \$\textbackslash alpha\$, and if \$X\_1, \textbackslash cdots, X\_n\$ is a sample from \$P\$, then the posterior distribution of \$P\$ given \$X\_1, \textbackslash cdots, X\_n\$ is also a Dirichlet process on \$(\textbackslash mathscr\{X\}, \textbackslash mathscr\{A\})\$ with a parameter \$\textbackslash alpha + \textbackslash sum\^n\_1 \textbackslash delta\_\{x\_i\}\$, where \$\textbackslash delta\_x\$ denotes the measure giving mass one to the point \$x\$. In Section 4, an alternative definition of the Dirichlet process is given. This definition exhibits a version of the Dirichlet process that gives probability one to the set of discrete probability measures on \$(\textbackslash mathscr\{X\}, \textbackslash mathscr\{A\})\$. This is in contrast to Dubins and Freedman [2], whose methods for choosing a distribution function on the interval [0, 1] lead with probability one to singular continuous distributions. Methods of choosing a distribution function on [0, 1] that with probability one is absolutely continuous have been described by Kraft [7]. The general method of choosing a distribution function on [0, 1], described in Section 2 of Kraft and van Eeden [10], can of course be used to define the Dirichlet process on [0, 1]. Special mention must be made of the papers of Freedman and Fabius. Freedman [5] defines a notion of tailfree for a distribution on the set of all probability measures on a countable space \$\textbackslash mathscr\{X\}\$. For a tailfree prior, posterior distribution given a sample from the true probability measure may be fairly easily computed. Fabius [3] extends the notion of tailfree to the case where \$\textbackslash mathscr\{X\}\$ is the unit interval [0, 1], but it is clear his extension may be made to cover quite general \$\textbackslash mathscr\{X\}\$. With such an extension, the Dirichlet process would be a special case of a tailfree distribution for which the posterior distribution has a particularly simple form. There are disadvantages to the fact that \$P\$ chosen by a Dirichlet process is discrete with probability one. These appear mainly because in sampling from a \$P\$ chosen by a Dirichlet process, we expect eventually to see one observation exactly equal to another. For example, consider the goodness-of-fit problem of testing the hypothesis \$H\_0\$ that a distribution on the interval [0, 1] is uniform. If on the alternative hypothesis we place a Dirichlet process prior with parameter \$\textbackslash alpha\$ itself a uniform measure on [0, 1], and if we are given a sample of size \$n \textbackslash geqq 2\$, the only nontrivial nonrandomized Bayes rule is to reject \$H\_0\$ if and only if two or more of the observations are exactly equal. This is really a test of the hypothesis that a distribution is continuous against the hypothesis that it is discrete. Thus, there is still a need for a prior that chooses a continuous distribution with probability one and yet satisfies properties (I) and (II). Some applications in which the possible doubling up of the values of the observations plays no essential role are presented in Section 5. These include the estimation of a distribution function, of a mean, of quantiles, of a variance and of a covariance. A two-sample problem is considered in which the Mann-Whitney statistic, equivalent to the rank-sum statistic, appears naturally. A decision theoretic upper tolerance limit for a quantile is also treated. Finally, a hypothesis testing problem concerning a quantile is shown to yield the sign test. In each of these problems, useful ways of combining prior information with the statistical observations appear. Other applications exist. In his Ph. D. dissertation [1], Charles Antoniak finds a need to consider mixtures of Dirichlet processes. He treats several problems, including the estimation of a mixing distribution, bio-assay, empirical Bayes problems, and discrimination problems.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Ferguson_1973_A Bayesian Analysis of Some Nonparametric Problems.pdf}
}

@article{fernandezAdaptiveQuadratureSchemes2020,
  title = {Adaptive Quadrature Schemes for {{Bayesian}} Inference via Active Learning},
  author = {Fern{\'a}ndez, Fernando Llorente and Martino, Luca and Elvira, Victor and Delgado, David and {L{\'o}pez-Santiago}, Javier},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {208462--208483},
  publisher = {{IEEE}},
  file = {/Users/lichengk/Zotero/storage/RY464PDK/9260147.html}
}

@inproceedings{fernandezGaussianProcessesSurvival2016,
  title = {Gaussian {{Processes}} for {{Survival Analysis}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Fernandez, Tamara and Rivera, Nicolas and Teh, Yee Whye},
  year = {2016},
  volume = {29},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-02-08},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Fernandez et al_2016_Gaussian Processes for Survival Analysis.pdf}
}

@article{figurnovImplicitReparameterizationGradients2019,
  title = {Implicit {{Reparameterization Gradients}}},
  author = {Figurnov, Michael and Mohamed, Shakir and Mnih, Andriy},
  year = {2019},
  month = jan,
  journal = {arXiv:1805.08498 [cs, stat]},
  eprint = {1805.08498},
  primaryclass = {cs, stat},
  urldate = {2022-02-21},
  abstract = {By providing a simple and efficient way of computing low-variance gradients of continuous random variables, the reparameterization trick has become the technique of choice for training a variety of latent variable models. However, it is not applicable to a number of important continuous distributions. We introduce an alternative approach to computing reparameterization gradients based on implicit differentiation and demonstrate its broader applicability by applying it to Gamma, Beta, Dirichlet, and von Mises distributions, which cannot be used with the classic reparameterization trick. Our experiments show that the proposed approach is faster and more accurate than the existing gradient estimators for these distributions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Figurnov et al_2019_Implicit Reparameterization Gradients.pdf;/Users/lichengk/Zotero/storage/F3IHKMPD/1805.html}
}

@unpublished{FinettiTheorem01,
  title = {De {{Finetti}}'s Theorem 0-1 Proof},
  urldate = {2023-05-26},
  keywords = {ObsCite},
  file = {/Users/lichengk/Zotero/storage/CXA6T3A3/DeFinetti.pdf}
}

@misc{FirstOccurrenceCommon,
  title = {First (?) {{Occurrence}} of {{Common Terms}} in {{Probability}} and {{Statistics}}\textemdash{{A Second List}}, with {{Corrections}}},
  shorttitle = {First (?},
  issn = {0003-1305},
  urldate = {2023-04-27},
  howpublished = {https://www.tandfonline.com/doi/epdf/10.1080/00031305.1998.10480535?needAccess=true\&role=button},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/35U7QXEI/00031305.1998.html}
}

@inproceedings{fisherLocallyAdaptiveBayesian2020,
  title = {A {{Locally Adaptive Bayesian Cubature Method}}},
  booktitle = {Proceedings of the {{Twenty Third International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Fisher, Matthew and Oates, Chris and Powell, Catherine and Teckentrup, Aretha},
  year = {2020},
  month = jun,
  pages = {1265--1275},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-02-10},
  abstract = {Bayesian cubature (BC) is a popular inferential perspective on the cubature of expensive integrands, wherein the integrand is emulated using a stochastic process model. Several approaches have been put forward to encode sequential adaptation (i.e. dependence on previous integrand evaluations) into this framework. However, these proposals have been limited to either estimating the parameters of a stationary covariance model or focusing computational resources on regions where large values are taken by the integrand. In contrast, many classical adaptive cubature methods are locally adaptive in the sense that they focus computational resources on spatial regions in which local error estimates are largest. The main contributions of this work are twofold; first we establish that existing BC methods do not possess local adaptivity in the sense of many classical adaptive methods and secondly, we developed a novel BC method whose behaviour, demonstrated empirically, is analogous to such methods. Finally we present evidence that the novel method provides improved cubature performance, relative to standard BC, in a detailed empirical assessment.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Fisher et al_2020_A Locally Adaptive Bayesian Cubature Method.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Fisher et al_2020_A Locally Adaptive Bayesian Cubature Method2.pdf}
}

@phdthesis{fisterOptimizedExtensionsArbitrary2021,
  title = {Optimized Extensions of Arbitrary Cubatures},
  author = {Fister, Matthew W.},
  year = {2021},
  school = {The University of Alabama},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Fister_2021_Optimized extensions of arbitrary cubatures.pdf;/Users/lichengk/Zotero/storage/DMLGUMKH/1.html}
}

@article{flaxmanFastHierarchicalGaussian,
  title = {Fast Hierarchical {{Gaussian}} Processes},
  author = {Flaxman, Seth and Gelman, Andrew and Neill, Daniel and Smola, Alex and Vehtari, Aki and Wilson, Andrew Gordon},
  pages = {18},
  abstract = {While the framework of Gaussian process priors for functions is very flexible and has a number of advantages, its use within a fully Bayesian hierarchical modeling framework has been limited due to computational constraints. Most often, simple models are fit, with hyperparameters learned by maximum likelihood. But this approach understates the posterior uncertainty in inference. We consider priors over kernel hyperparameters, thus inducing a very flexible Bayesian hierarchical modeling framework in which we perform inference using MCMC not just for the posterior function but also for the posterior over the kernel hyperparameters. We address the central challenge of computational efficiency with MCMC by exploiting separable structure in the covariance matrix corresponding to the kernel, yielding significant gains in time and memory efficiency. Our method can be conveniently implemented in a probabilistic programming language (Stan), is widely applicable to any setting involving structured kernels, and immediately enables a number of useful features, including kernel learning through novel prior specifications, learning nonparametric priors over categorical variables, clustering through a factor analysis approach, and missing observations. We demonstrate our methods on real and synthetic spatiotemporal datasets.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/T8Y2T33W/Flaxman et al. - Fast hierarchical Gaussian processes.pdf}
}

@article{fongMarginalLikelihoodCrossvalidation2019,
  title = {On the Marginal Likelihood and Cross-Validation},
  author = {Fong, Edwin and Holmes, Chris},
  year = {2019},
  month = sep,
  journal = {arXiv:1905.08737 [stat]},
  eprint = {1905.08737},
  primaryclass = {stat},
  urldate = {2022-03-02},
  abstract = {In Bayesian statistics, the marginal likelihood, also known as the evidence, is used to evaluate model fit as it quantifies the joint probability of the data under the prior. In contrast, non-Bayesian models are typically compared using cross-validation on held-out data, either through \$k\$-fold partitioning or leave-\$p\$-out subsampling. We show that the marginal likelihood is formally equivalent to exhaustive leave-\$p\$-out cross-validation averaged over all values of \$p\$ and all held-out test sets when using the log posterior predictive probability as the scoring rule. Moreover, the log posterior predictive is the only coherent scoring rule under data exchangeability. This offers new insight into the marginal likelihood and cross-validation and highlights the potential sensitivity of the marginal likelihood to the choice of the prior. We suggest an alternative approach using cumulative cross-validation following a preparatory training phase. Our work has connections to prequential analysis and intrinsic Bayes factors but is motivated through a different course.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/Zotero/storage/Z4LAS3VT/Fong and Holmes - 2019 - On the marginal likelihood and cross-validation.pdf;/Users/lichengk/Zotero/storage/C7VZFIDC/1905.html}
}

@article{fortuinPriorsBayesianDeep2021,
  title = {Priors in {{Bayesian Deep Learning}}: {{A Review}}},
  shorttitle = {Priors in {{Bayesian Deep Learning}}},
  author = {Fortuin, Vincent},
  year = {2021},
  month = may,
  journal = {arXiv:2105.06868 [cs, stat]},
  eprint = {2105.06868},
  primaryclass = {cs, stat},
  urldate = {2021-05-25},
  abstract = {While the choice of prior is one of the most critical parts of the Bayesian inference workflow, recent Bayesian deep learning models have often fallen back on uninformative priors, such as standard Gaussians. In this review, we highlight the importance of prior choices for Bayesian deep learning and present an overview of different priors that have been proposed for (deep) Gaussian processes, variational autoencoders, and Bayesian neural networks. We also outline different methods of learning priors for these models from data. We hope to motivate practitioners in Bayesian deep learning to think more carefully about the prior specification for their models and to provide them with some inspiration in this regard.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Fortuin_2021_Priors in Bayesian Deep Learning.pdf;/Users/lichengk/Zotero/storage/3NZFGVP5/2105.html}
}

@article{fortuinPriorsBayesianDeep2022,
  title = {Priors in {{Bayesian Deep Learning}}: {{A Review}}},
  shorttitle = {Priors in {{Bayesian Deep Learning}}},
  author = {Fortuin, Vincent},
  year = {2022},
  journal = {International Statistical Review},
  volume = {90},
  number = {3},
  pages = {563--591},
  issn = {1751-5823},
  doi = {10.1111/insr.12502},
  urldate = {2022-12-12},
  abstract = {While the choice of prior is one of the most critical parts of the Bayesian inference workflow, recent Bayesian deep learning models have often fallen back on vague priors, such as standard Gaussians. In this review, we highlight the importance of prior choices for Bayesian deep learning and present an overview of different priors that have been proposed for (deep) Gaussian processes, variational autoencoders and Bayesian neural networks. We also outline different methods of learning priors for these models from data. We hope to motivate practitioners in Bayesian deep learning to think more carefully about the prior specification for their models and to provide them with some inspiration in this regard.},
  langid = {english},
  keywords = {Bayesian deep learning,Bayesian learning,deep learning,priors},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Fortuin_2022_Priors in Bayesian Deep Learning.pdf}
}

@article{frazierTutorialBayesianOptimization2018,
  title = {A {{Tutorial}} on {{Bayesian Optimization}}},
  author = {Frazier, Peter I.},
  year = {2018},
  month = jul,
  journal = {arXiv:1807.02811 [cs, math, stat]},
  eprint = {1807.02811},
  primaryclass = {cs, math, stat},
  urldate = {2021-05-26},
  abstract = {Bayesian optimization is an approach to optimizing objective functions that take a long time (minutes or hours) to evaluate. It is best-suited for optimization over continuous domains of less than 20 dimensions, and tolerates stochastic noise in function evaluations. It builds a surrogate for the objective and quantifies the uncertainty in that surrogate using a Bayesian machine learning technique, Gaussian process regression, and then uses an acquisition function defined from this surrogate to decide where to sample. In this tutorial, we describe how Bayesian optimization works, including Gaussian process regression and three common acquisition functions: expected improvement, entropy search, and knowledge gradient. We then discuss more advanced techniques, including running multiple function evaluations in parallel, multi-fidelity and multi-information source optimization, expensive-to-evaluate constraints, random environmental conditions, multi-task Bayesian optimization, and the inclusion of derivative information. We conclude with a discussion of Bayesian optimization software and future research directions in the field. Within our tutorial material we provide a generalization of expected improvement to noisy evaluations, beyond the noise-free setting where it is more commonly applied. This generalization is justified by a formal decision-theoretic argument, standing in contrast to previous ad hoc modifications.},
  archiveprefix = {arxiv},
  keywords = {*5{$\medwhitestar\medwhitestar\medwhitestar\medwhitestar\medwhitestar$},Computer Science - Machine Learning,done,Mathematics - Optimization and Control,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Frazier_2018_A Tutorial on Bayesian Optimization.pdf;/Users/lichengk/Zotero/storage/PFBCY2EE/1807.html}
}

@article{frohlichBayesianQuadratureRiemannian2021,
  title = {Bayesian {{Quadrature}} on {{Riemannian Data Manifolds}}},
  author = {Fr{\"o}hlich, Christian and Gessner, Alexandra and Hennig, Philipp and Sch{\"o}lkopf, Bernhard and Arvanitidis, Georgios},
  year = {2021},
  journal = {arXiv preprint arXiv:2102.06645},
  eprint = {2102.06645},
  archiveprefix = {arxiv},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Fröhlich et al_2021_Bayesian Quadrature on Riemannian Data Manifolds.pdf;/Users/lichengk/Zotero/storage/Q5DWZ97N/2102.html}
}

@misc{FullyBayesianInference,
  title = {Fully {{Bayesian}} Inference for Generalized {{GP}} Models with {{HMC}} \textemdash{} {{GPflow}} 1.0.0 Documentation},
  urldate = {2022-02-28},
  howpublished = {https://gpflow.readthedocs.io/en/awav-documentation/notebooks/mcmc.html},
  file = {/Users/lichengk/Zotero/storage/Q7XY3EMG/mcmc.html}
}

@article{gabrieAdaptiveMonteCarlo2022,
  title = {Adaptive {{Monte Carlo}} Augmented with Normalizing Flows},
  author = {Gabri{\'e}, Marylou and Rotskoff, Grant M. and {Vanden-Eijnden}, Eric},
  year = {2022},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {10},
  pages = {e2109420119},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2109420119},
  urldate = {2022-12-13},
  abstract = {Many problems in the physical sciences, machine learning, and statistical inference necessitate sampling from a high-dimensional, multimodal probability distribution. Markov Chain Monte Carlo (MCMC) algorithms, the ubiquitous tool for this task, typically rely on random local updates to propagate configurations of a given system in a way that ensures that generated configurations will be distributed according to a target probability distribution asymptotically. In high-dimensional settings with multiple relevant metastable basins, local approaches require either immense computational effort or intricately designed importance sampling strategies to capture information about, for example, the relative populations of such basins. Here, we analyze an adaptive MCMC, which augments MCMC sampling with nonlocal transition kernels parameterized with generative models known as normalizing flows. We focus on a setting where there are no preexisting data, as is commonly the case for problems in which MCMC is used. Our method uses 1) an MCMC strategy that blends local moves obtained from any standard transition kernel with those from a generative model to accelerate the sampling and 2) the data generated this way to adapt the generative model and improve its efficacy in the MCMC algorithm. We provide a theoretical analysis of the convergence properties of this algorithm and investigate numerically its efficiency, in particular in terms of its propensity to equilibrate fast between metastable modes whose rough location is known a priori but respective probability weight is not. We show that our algorithm can sample effectively across large free energy barriers, providing dramatic accelerations relative to traditional MCMC algorithms.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gabrié et al_2022_Adaptive Monte Carlo augmented with normalizing flows.pdf}
}

@misc{gabrieEfficientBayesianSampling2021,
  title = {Efficient {{Bayesian Sampling Using Normalizing Flows}} to {{Assist Markov Chain Monte Carlo Methods}}},
  author = {Gabri{\'e}, Marylou and Rotskoff, Grant M. and {Vanden-Eijnden}, Eric},
  year = {2021},
  month = jul,
  number = {arXiv:2107.08001},
  eprint = {2107.08001},
  primaryclass = {physics, stat},
  publisher = {{arXiv}},
  urldate = {2022-11-25},
  abstract = {Normalizing flows can generate complex target distributions and thus show promise in many applications in Bayesian statistics as an alternative or complement to MCMC for sampling posteriors. Since no data set from the target posterior distribution is available beforehand, the flow is typically trained using the reverse Kullback-Leibler (KL) divergence that only requires samples from a base distribution. This strategy may perform poorly when the posterior is complicated and hard to sample with an untrained normalizing flow. Here we explore a distinct training strategy, using the direct KL divergence as loss, in which samples from the posterior are generated by (i) assisting a local MCMC algorithm on the posterior with a normalizing flow to accelerate its mixing rate and (ii) using the data generated this way to train the flow. The method only requires a limited amount of \textbackslash textit\{a\textasciitilde priori\} input about the posterior, and can be used to estimate the evidence required for model validation, as we illustrate on examples.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,{Physics - Data Analysis, Statistics and Probability},Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gabrié et al_2021_Efficient Bayesian Sampling Using Normalizing Flows to Assist Markov Chain.pdf;/Users/lichengk/Zotero/storage/KHRNVI7A/2107.html}
}

@article{galImprovingGaussianProcess,
  title = {Improving the {{Gaussian Process Sparse Spectrum Approximation}} by {{Representing Uncertainty}} in {{Frequency Inputs}}},
  author = {Gal, Yarin and Turner, Richard},
  pages = {10},
  abstract = {Standard sparse pseudo-input approximations to the Gaussian process (GP) cannot handle complex functions well. Sparse spectrum alternatives attempt to answer this but are known to over-fit. We suggest the use of variational inference for the sparse spectrum approximation to avoid both issues. We model the covariance function with a finite Fourier series approximation and treat it as a random variable. The random covariance function has a posterior, on which a variational distribution is placed. The variational distribution transforms the random covariance function to fit the data. We study the properties of our approximate inference, compare it to alternative ones, and extend it to the distributed and stochastic domains. Our approximation captures complex functions better than standard approaches and avoids over-fitting.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/Y5Z8Q98Z/Gal and Turner - Improving the Gaussian Process Sparse Spectrum App.pdf}
}

@article{galModernDeepLearning,
  title = {On {{Modern Deep Learning}} and {{Variational Inference}}},
  author = {Gal, Yarin and Ghahramani, Zoubin},
  pages = {9},
  abstract = {Bayesian modelling and variational inference are rooted in Bayesian statistics, and easily benefit from the vast literature in the field. In contrast, deep learning lacks a solid mathematical grounding. Instead, empirical developments in deep learning are often justified by metaphors, evading the unexplained principles at play. It is perhaps astonishing then that most modern deep learning models can be cast as performing approximate variational inference in a Bayesian setting. This mathematically grounded result, studied in Gal and Ghahramani [1] for deep neural networks (NNs), is extended here to arbitrary deep learning models. The implications of this statement are profound: we can use the rich Bayesian statistics literature with deep learning models, explain away many of the curiosities with these, combine results from deep learning into Bayesian modelling, and much more. We demonstrate the practical impact of the framework with image classification by combining Bayesian and deep learning techniques, obtaining new state-of-the-art results, and survey open problems to research. These stand at the forefront of a new and exciting field combining modern deep learning and Bayesian techniques.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/AU839BGF/Gal and Ghahramani - On Modern Deep Learning and Variational Inference.pdf}
}

@misc{galy-fajouAdaptiveInducingPoints2021,
  title = {Adaptive {{Inducing Points Selection For Gaussian Processes}}},
  author = {{Galy-Fajou}, Th{\'e}o and Opper, Manfred},
  year = {2021},
  month = jul,
  number = {arXiv:2107.10066},
  eprint = {2107.10066},
  primaryclass = {cs, stat},
  institution = {{arXiv}},
  urldate = {2022-05-31},
  abstract = {Gaussian Processes (\textbackslash textbf\{GPs\}) are flexible non-parametric models with strong probabilistic interpretation. While being a standard choice for performing inference on time series, GPs have few techniques to work in a streaming setting. \textbackslash cite\{bui2017streaming\} developed an efficient variational approach to train online GPs by using sparsity techniques: The whole set of observations is approximated by a smaller set of inducing points (\textbackslash textbf\{IPs\}) and moved around with new data. Both the number and the locations of the IPs will affect greatly the performance of the algorithm. In addition to optimizing their locations, we propose to adaptively add new points, based on the properties of the GP and the structure of the data.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/IW2Q8LWD/Galy-Fajou and Opper - 2021 - Adaptive Inducing Points Selection For Gaussian Pr.pdf;/Users/lichengk/Zotero/storage/BGWERK9B/2107.html}
}

@article{galy-fajouAutomatedAugmentedConjugate2020,
  title = {Automated {{Augmented Conjugate Inference}} for {{Non-conjugate Gaussian Process Models}}},
  author = {{Galy-Fajou}, Th{\'e}o and Wenzel, Florian and Opper, Manfred},
  year = {2020},
  month = feb,
  journal = {arXiv:2002.11451 [cs, stat]},
  eprint = {2002.11451},
  primaryclass = {cs, stat},
  urldate = {2021-09-01},
  abstract = {We propose automated augmented conjugate inference, a new inference method for non-conjugate Gaussian processes (GP) models. Our method automatically constructs an auxiliary variable augmentation that renders the GP model conditionally conjugate. Building on the conjugate structure of the augmented model, we develop two inference methods. First, a fast and scalable stochastic variational inference method that uses efficient block coordinate ascent updates, which are computed in closed form. Second, an asymptotically correct Gibbs sampler that is useful for small datasets. Our experiments show that our method are up two orders of magnitude faster and more robust than existing state-of-the-art black-box methods.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Galy-Fajou et al_2020_Automated Augmented Conjugate Inference for Non-conjugate Gaussian Process.pdf;/Users/lichengk/Zotero/storage/YPX65CMD/2002.html}
}

@misc{gammalFastRobustBayesian2022,
  title = {Fast and Robust {{Bayesian Inference}} Using {{Gaussian Processes}} with {{GPry}}},
  author = {Gammal, Jonas El and Sch{\"o}neberg, Nils and Torrado, Jes{\'u}s and Fidler, Christian},
  year = {2022},
  month = nov,
  number = {arXiv:2211.02045},
  eprint = {2211.02045},
  primaryclass = {astro-ph, stat},
  publisher = {{arXiv}},
  urldate = {2022-11-08},
  abstract = {We present the GPry algorithm for fast Bayesian inference of general (non-Gaussian) posteriors with a moderate number of parameters. GPry does not need any pre-training, special hardware such as GPUs, and is intended as a drop-in replacement for traditional Monte Carlo methods for Bayesian inference. Our algorithm is based on generating a Gaussian Process surrogate model of the log-posterior, aided by a Support Vector Machine classifier that excludes extreme or non-finite values. An active learning scheme allows us to reduce the number of required posterior evaluations by two orders of magnitude compared to traditional Monte Carlo inference. Our algorithm allows for parallel evaluations of the posterior at optimal locations, further reducing wall-clock times. We significantly improve performance using properties of the posterior in our active learning scheme and for the definition of the GP prior. In particular we account for the expected dynamical range of the posterior in different dimensionalities. We test our model against a number of synthetic and cosmological examples. GPry outperforms traditional Monte Carlo methods when the evaluation time of the likelihood (or the calculation of theoretical observables) is of the order of seconds; for evaluation times of over a minute it can perform inference in days that would take months using traditional methods. GPry is distributed as an open source Python package (pip install gpry) and can also be found at https://github.com/jonaselgammal/GPry.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gammal et al_2022_Fast and robust Bayesian Inference using Gaussian Processes with GPry.pdf;/Users/lichengk/Zotero/storage/AIKLCYQK/2211.html}
}

@article{gammelliEstimatingLatentDemand2020,
  title = {Estimating Latent Demand of Shared Mobility through Censored {{Gaussian Processes}}},
  author = {Gammelli, Daniele and Peled, Inon and Rodrigues, Filipe and Pacino, Dario and Kurtaran, Haci A. and Pereira, Francisco C.},
  year = {2020},
  month = nov,
  journal = {Transportation Research Part C: Emerging Technologies},
  volume = {120},
  pages = {102775},
  issn = {0968-090X},
  doi = {10.1016/j.trc.2020.102775},
  urldate = {2022-02-08},
  abstract = {Transport demand is highly dependent on supply, especially for shared transport services where availability is often limited. As observed demand cannot be higher than available supply, historical transport data typically represents a biased, or censored, version of the true underlying demand pattern. Without explicitly accounting for this inherent distinction, predictive models of demand would necessarily represent a biased version of true demand, thus less effectively predicting the needs of service users. To counter this problem, we propose a general method for censorship-aware demand modeling, for which we derive a censored likelihood function capable of handling time-varying supply. We apply this method to the task of shared mobility demand prediction by incorporating the censored likelihood within a Gaussian Process model, which can flexibly approximate arbitrary functional forms. Experiments on artificial and real-world datasets show how taking into account the limiting effect of supply on demand is essential in the process of obtaining an unbiased predictive model of user demand behavior.},
  langid = {english},
  keywords = {Bayesian inference,Censoring,Demand modeling,Gaussian Processes,Shared mobility},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gammelli et al_2020_Estimating latent demand of shared mobility through censored Gaussian Processes.pdf;/Users/lichengk/Zotero/storage/NX9VTTER/S0968090X20306859.html}
}

@article{gardnerGPyTorchBlackboxMatrixMatrix2021,
  title = {{{GPyTorch}}: {{Blackbox Matrix-Matrix Gaussian Process Inference}} with {{GPU Acceleration}}},
  shorttitle = {{{GPyTorch}}},
  author = {Gardner, Jacob R. and Pleiss, Geoff and Bindel, David and Weinberger, Kilian Q. and Wilson, Andrew Gordon},
  year = {2021},
  month = jun,
  journal = {arXiv:1809.11165 [cs, stat]},
  eprint = {1809.11165},
  primaryclass = {cs, stat},
  urldate = {2021-11-10},
  abstract = {Despite advances in scalable models, the inference tools used for Gaussian processes (GPs) have yet to fully capitalize on developments in computing hardware. We present an efficient and general approach to GP inference based on Blackbox Matrix-Matrix multiplication (BBMM). BBMM inference uses a modified batched version of the conjugate gradients algorithm to derive all terms for training and inference in a single call. BBMM reduces the asymptotic complexity of exact GP inference from \$O(n\^3)\$ to \$O(n\^2)\$. Adapting this algorithm to scalable approximations and complex GP models simply requires a routine for efficient matrix-matrix multiplication with the kernel and its derivative. In addition, BBMM uses a specialized preconditioner to substantially speed up convergence. In experiments we show that BBMM effectively uses GPU hardware to dramatically accelerate both exact GP inference and scalable approximations. Additionally, we provide GPyTorch, a software platform for scalable GP inference via BBMM, built on PyTorch.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/FNJWVDN8/Gardner et al. - 2021 - GPyTorch Blackbox Matrix-Matrix Gaussian Process .pdf;/Users/lichengk/Zotero/storage/J7YSDU9P/1809.html}
}

@misc{garneloNeuralProcesses2018,
  title = {Neural {{Processes}}},
  author = {Garnelo, Marta and Schwarz, Jonathan and Rosenbaum, Dan and Viola, Fabio and Rezende, Danilo J. and Eslami, S. M. Ali and Teh, Yee Whye},
  year = {2018},
  month = jul,
  number = {arXiv:1807.01622},
  eprint = {1807.01622},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-06-09},
  abstract = {A neural network (NN) is a parameterised function that can be tuned via gradient descent to approximate a labelled collection of data with high precision. A Gaussian process (GP), on the other hand, is a probabilistic model that defines a distribution over possible functions, and is updated in light of data via the rules of probabilistic inference. GPs are probabilistic, data-efficient and flexible, however they are also computationally intensive and thus limited in their applicability. We introduce a class of neural latent variable models which we call Neural Processes (NPs), combining the best of both worlds. Like GPs, NPs define distributions over functions, are capable of rapid adaptation to new observations, and can estimate the uncertainty in their predictions. Like NNs, NPs are computationally efficient during training and evaluation but also learn to adapt their priors to data. We demonstrate the performance of NPs on a range of learning tasks, including regression and optimisation, and compare and contrast with related models in the literature.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Garnelo et al_2018_Neural Processes.pdf;/Users/lichengk/Zotero/storage/M7QJ3UNE/1807.html}
}

@book{garnettBayesianOptimization2021,
  title = {Bayesian {{Optimization}}},
  author = {Garnett, Roman},
  year = {2021},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Garnett_2021_Bayesian Optimization2.pdf}
}

@article{garnettBayesianQuadratureLessons,
  title = {Bayesian {{Quadrature}}: {{Lessons Learned}} and {{Looking Forward}}},
  author = {Garnett, Roman},
  pages = {63},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Garnett_Bayesian Quadrature.pdf}
}

@unpublished{garnettGPConditioningOutputs,
  title = {{{GP Conditioning}} on {{Outputs}} of {{Linear Operators}}},
  author = {Garnett, Roman},
  urldate = {2023-06-07},
  keywords = {ObsCite},
  file = {/Users/lichengk/Zotero/storage/QN27RBXZ/11.pdf}
}

@misc{gaussianprocesssummerschoolGPSS2019InvariancesGaussian2019,
  title = {{{GPSS2019}} - {{Invariances}} in {{Gaussian}} Processes and How to Learn Them},
  author = {{Gaussian Process Summer School}},
  year = {2019},
  month = sep,
  urldate = {2022-11-01}
}

@misc{geipingHowMuchData2022,
  title = {How {{Much Data Are Augmentations Worth}}? {{An Investigation}} into {{Scaling Laws}}, {{Invariance}}, and {{Implicit Regularization}}},
  shorttitle = {How {{Much Data Are Augmentations Worth}}?},
  author = {Geiping, Jonas and Goldblum, Micah and Somepalli, Gowthami and {Shwartz-Ziv}, Ravid and Goldstein, Tom and Wilson, Andrew Gordon},
  year = {2022},
  month = oct,
  number = {arXiv:2210.06441},
  eprint = {2210.06441},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-11-17},
  abstract = {Despite the clear performance benefits of data augmentations, little is known about why they are so effective. In this paper, we disentangle several key mechanisms through which data augmentations operate. Establishing an exchange rate between augmented and additional real data, we find that in out-of-distribution testing scenarios, augmentations which yield samples that are diverse, but inconsistent with the data distribution can be even more valuable than additional training data. Moreover, we find that data augmentations which encourage invariances can be more valuable than invariance alone, especially on small and medium sized training sets. Following this observation, we show that augmentations induce additional stochasticity during training, effectively flattening the loss landscape.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/R5XUJT2J/Geiping et al. - 2022 - How Much Data Are Augmentations Worth An Investig.pdf;/Users/lichengk/Zotero/storage/JDWTQ4WH/2210.html}
}

@article{gelmanBayesianWorkflow2020,
  title = {Bayesian {{Workflow}}},
  author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and B{\"u}rkner, Paul-Christian and Modr{\'a}k, Martin},
  year = {2020},
  month = nov,
  journal = {arXiv:2011.01808 [stat]},
  eprint = {2011.01808},
  primaryclass = {stat},
  urldate = {2021-05-17},
  abstract = {The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions.},
  archiveprefix = {arxiv},
  keywords = {ObsCite,Statistics - Methodology,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gelman et al_2020_Bayesian Workflow.pdf;/Users/lichengk/Zotero/storage/5MAFRRUQ/2011.html}
}

@article{gelmanHolesBayesianStatistics2021,
  title = {Holes in {{Bayesian}} Statistics},
  author = {Gelman, Andrew and Yao, Yuling},
  year = {2021},
  month = jan,
  journal = {Journal of Physics G: Nuclear and Particle Physics},
  volume = {48},
  number = {1},
  pages = {014002},
  issn = {0954-3899, 1361-6471},
  doi = {10.1088/1361-6471/abc3a5},
  urldate = {2021-05-19},
  abstract = {Every philosophy has holes, and it is the responsibility of proponents of a philosophy to point out these problems. Here are a few holes in Bayesian data analysis: (1) the usual rules of conditional probability fail in the quantum realm, (2) flat or weak priors lead to terrible inferences about things we care about, (3) subjective priors are incoherent, (4) Bayesian decision picks the wrong model, (5) Bayes factors fail in the presence of flat or weak priors, (6) for Cantorian reasons we need to check our models, but this destroys the coherence of Bayesian inference.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gelman_Yao_2021_Holes in Bayesian statistics.pdf}
}

@article{gelmanPriorCanOften2017,
  title = {The {{Prior Can Often Only Be Understood}} in the {{Context}} of the {{Likelihood}}},
  author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
  year = {2017},
  month = oct,
  journal = {Entropy},
  volume = {19},
  number = {10},
  pages = {555},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1099-4300},
  doi = {10.3390/e19100555},
  urldate = {2022-12-12},
  abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeffreys' priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {Bayesian inference,default priors,prior,prior distribution,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gelman et al_2017_The Prior Can Often Only Be Understood in the Context of the Likelihood.pdf}
}

@misc{GentleIntroductionConformal,
  title = {{$\mu$} \& {$\sigma$} - {{A Gentle Introduction}} to {{Conformal Prediction}} and {{Distribution-Free Uncertainty Quantification}}},
  urldate = {2023-05-28},
  howpublished = {https://people.eecs.berkeley.edu/\textasciitilde angelopoulos/blog/posts/gentle-intro/},
  file = {/Users/lichengk/Zotero/storage/24XHNZC8/gentle-intro.html}
}

@article{gentonClassesKernelsMachine2001,
  title = {Classes of {{Kernels}} for {{Machine Learning}}: {{A Statistics Perspective}}},
  shorttitle = {Classes of {{Kernels}} for {{Machine Learning}}},
  author = {Genton, Marc G.},
  year = {2001},
  journal = {Journal of Machine Learning Research},
  volume = {2},
  number = {Dec},
  pages = {299--312},
  issn = {ISSN 1533-7928},
  urldate = {2022-01-12},
  abstract = {In this paper, we present classes of kernels for machine learning from a statistics perspective. Indeed, kernels are positive definite functions and thus also covariances. After discussing key properties of kernels, as well as a new formula to construct kernels, we present several important classes of kernels: anisotropic stationary kernels, isotropic stationary kernels, compactly supported kernels, locally stationary kernels, nonstationary kernels, and separable nonstationary kernels. Compactly supported kernels and separable nonstationary kernels are of prime interest because they provide a computational reduction for kernel-based methods. We describe the spectral representation of the various classes of kernels and conclude with a discussion on the characterization of nonlinear maps that reduce nonstationary kernels to either stationarity or local stationarity.},
  keywords = {*5{$\medwhitestar\medwhitestar\medwhitestar\medwhitestar\medwhitestar$},ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Genton_2001_Classes of Kernels for Machine Learning.pdf}
}

@misc{germainMADEMaskedAutoencoder2015,
  title = {{{MADE}}: {{Masked Autoencoder}} for {{Distribution Estimation}}},
  shorttitle = {{{MADE}}},
  author = {Germain, Mathieu and Gregor, Karol and Murray, Iain and Larochelle, Hugo},
  year = {2015},
  month = jun,
  number = {arXiv:1502.03509},
  eprint = {1502.03509},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-16},
  abstract = {There has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples. We introduce a simple modification for autoencoder neural networks that yields powerful generative models. Our method masks the autoencoder's parameters to respect autoregressive constraints: each input is reconstructed only from previous inputs in a given ordering. Constrained this way, the autoencoder outputs can be interpreted as a set of conditional probabilities, and their product, the full joint probability. We can also train a single network that can decompose the joint probability in multiple different orderings. Our simple framework can be applied to multiple architectures, including deep ones. Vectorized implementations, such as on GPUs, are simple and fast. Experiments demonstrate that this approach is competitive with state-of-the-art tractable distribution estimators. At test time, the method is significantly faster and scales better than other autoregressive estimators.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/QH24425Z/Germain et al. - 2015 - MADE Masked Autoencoder for Distribution Estimati.pdf;/Users/lichengk/Zotero/storage/Q2SWKC4A/1502.html}
}

@inproceedings{gershmanNonparametricVariationalInference2012,
  title = {Nonparametric Variational Inference},
  booktitle = {Proceedings of the 29th International Conference on Machine Learning},
  author = {Gershman, Samuel J. and Hoffman, Matthew D. and Blei, David M.},
  year = {2012},
  series = {{{ICML}}'12},
  pages = {235--242},
  publisher = {{Omnipress}},
  address = {{Madison, WI, USA}},
  abstract = {Variational methods are widely used for approximate posterior inference. However, their use is typically limited to families of distributions that enjoy particular conjugacy properties. To circumvent this limitation, we propose a family of variational approximations inspired by nonparametric kernel density estimation. The locations of these kernels and their bandwidth are treated as variational parameters and optimized to improve an approximate lower bound on the marginal likelihood of the data. Unlike most other variational approximations, using multiple kernels allows the approximation to capture multiple modes of the posterior. We demonstrate the efficacy of the nonparametric approximation with a hierarchical logistic regression model and a nonlinear matrix factorization model. We obtain predictive performance as good as or better than more specialized variational methods and MCMC approximations. The method is easy to apply to graphical models for which standard variational methods are difficult to derive.},
  isbn = {978-1-4503-1285-1},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gershman et al_2012_Nonparametric variational inference.pdf;/Users/lichengk/Zotero/storage/VVHGBRTX/turner-sahani-2010-ildn.pdf}
}

@inproceedings{gessnerActiveMultiInformationSource2020,
  title = {Active {{Multi-Information Source Bayesian Quadrature}}},
  booktitle = {Uncertainty in {{Artificial Intelligence}}},
  author = {Gessner, Alexandra and Gonzalez, Javier and Mahsereci, Maren},
  year = {2020},
  month = aug,
  pages = {712--721},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-06-11},
  abstract = {Bayesian quadrature (BQ) is a sample-efficient probabilistic numerical method to solve integrals of expensive-to-evaluate black-box functions, yet so far, active BQ learning schemes focus merely on...},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gessner et al_2020_Active Multi-Information Source Bayesian Quadrature.pdf;/Users/lichengk/Zotero/storage/3MSFUUVX/gessner20a.html}
}

@article{gessnerActiveMultiInformationSource2021,
  title = {Active {{Multi-Information Source Bayesian Quadrature}}},
  author = {Gessner, Alexandra and Gonzalez, Javier and Mahsereci, Maren},
  year = {2021},
  month = feb,
  journal = {arXiv:1903.11331 [cs, stat]},
  eprint = {1903.11331},
  primaryclass = {cs, stat},
  urldate = {2021-08-08},
  abstract = {Bayesian quadrature (BQ) is a sample-efficient probabilistic numerical method to solve integrals of expensive-to-evaluate black-box functions, yet so far,active BQ learning schemes focus merely on the integrand itself as information source, and do not allow for information transfer from cheaper, related functions. Here, we set the scene for active learning in BQ when multiple related information sources of variable cost (in input and source) are accessible. This setting arises for example when evaluating the integrand requires a complex simulation to be run that can be approximated by simulating at lower levels of sophistication and at lesser expense. We construct meaningful cost-sensitive multi-source acquisition rates as an extension to common utility functions from vanilla BQ (VBQ),and discuss pitfalls that arise from blindly generalizing. Furthermore, we show that the VBQ acquisition policy is a corner-case of all considered cost-sensitive acquisition schemes, which collapse onto one single de-generate policy in the case of one source and constant cost. In proof-of-concept experiments we scrutinize the behavior of our generalized acquisition functions. On an epidemiological model, we demonstrate that active multi-source BQ (AMS-BQ) allocates budget more efficiently than VBQ for learning the integral to a good accuracy.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gessner et al_2021_Active Multi-Information Source Bayesian Quadrature.pdf;/Users/lichengk/Zotero/storage/8MBAZ9ZZ/1903.html}
}

@misc{GettingStartedPyro,
  title = {Getting {{Started With Pyro}}: {{Tutorials}}, {{How-to Guides}} and {{Examples}} \textemdash{} {{Pyro Tutorials}} 1.7.0 Documentation},
  urldate = {2021-08-23},
  howpublished = {https://pyro.ai/examples/index.html},
  file = {/Users/lichengk/Zotero/storage/IJ73PACA/index.html}
}

@misc{ghahramaniLect1bayesPdf,
  title = {Lect1bayes.Pdf},
  author = {Ghahramani, Zoubin},
  urldate = {2023-04-23},
  file = {/Users/lichengk/Zotero/storage/TT3266ZM/lect1bayes.pdf}
}

@article{ghahramaniProbabilisticMachineLearning2015,
  title = {Probabilistic Machine Learning and Artificial Intelligence},
  author = {Ghahramani, Zoubin},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {452--459},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature14541},
  urldate = {2021-09-02},
  abstract = {How can a machine learn from experience? Probabilistic modelling provides a framework for understanding what learning is, and has therefore emerged as one of the principal theoretical and practical approaches for designing machines that learn from data acquired through experience. The probabilistic framework, which describes how to represent and manipulate uncertainty about models and predictions, has a central role in scientific data analysis, machine learning, robotics, cognitive science and artificial intelligence. This Review provides an introduction to this framework, and discusses some of the state-of-the-art advances in the field, namely, probabilistic programming, Bayesian optimization, data compression and automatic model discovery.},
  copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Computer science;Mathematics and computing;Neuroscience Subject\_term\_id: computer-science;mathematics-and-computing;neuroscience},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Ghahramani_2015_Probabilistic machine learning and artificial intelligence.pdf;/Users/lichengk/Zotero/storage/7HHCGT2X/nature14541.html}
}

@book{ghoshChapterLineSearch,
  title = {Chapter 4 {{Line Search Descent Methods}} | {{Introduction}} to {{Mathematical Optimization}}},
  author = {Ghosh, Indranil},
  urldate = {2023-03-21},
  abstract = {A book for teaching introductory numerical optimization algorithms with Python},
  file = {/Users/lichengk/Zotero/storage/RNYPLT44/line-search-descent-methods.html}
}

@misc{giaquintoGradientBoostedNormalizing2020,
  title = {Gradient {{Boosted Normalizing Flows}}},
  author = {Giaquinto, Robert and Banerjee, Arindam},
  year = {2020},
  month = oct,
  number = {arXiv:2002.11896},
  eprint = {2002.11896},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-12-13},
  abstract = {By chaining a sequence of differentiable invertible transformations, normalizing flows (NF) provide an expressive method of posterior approximation, exact density evaluation, and sampling. The trend in normalizing flow literature has been to devise deeper, more complex transformations to achieve greater flexibility. We propose an alternative: Gradient Boosted Normalizing Flows (GBNF) model a density by successively adding new NF components with gradient boosting. Under the boosting framework, each new NF component optimizes a sample weighted likelihood objective, resulting in new components that are fit to the residuals of the previously trained components. The GBNF formulation results in a mixture model structure, whose flexibility increases as more components are added. Moreover, GBNFs offer a wider, as opposed to strictly deeper, approach that improves existing NFs at the cost of additional training---not more complex transformations. We demonstrate the effectiveness of this technique for density estimation and, by coupling GBNF with a variational autoencoder, generative modeling of images. Our results show that GBNFs outperform their non-boosted analog, and, in some cases, produce better results with smaller, simpler flows.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/XV9BLBPX/Giaquinto and Banerjee - 2020 - Gradient Boosted Normalizing Flows.pdf;/Users/lichengk/Zotero/storage/YQK5X55F/2002.html}
}

@book{gineMathematicalFoundationsInfinitedimensional2016,
  title = {Mathematical Foundations of Infinite-Dimensional Statistical Models},
  author = {Gin{\'e}, Evarist and Nickl, Richard},
  year = {2016},
  series = {Cambridge Series in Statistical and Probabilistic Mathematics},
  publisher = {{Cambridge University Press}},
  address = {{New York, NY}},
  isbn = {978-1-107-04316-9},
  langid = {english},
  lccn = {QA278.8 .G56 2016},
  keywords = {Function spaces,Nonparametric statistics},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Giné_Nickl_2016_Mathematical foundations of infinite-dimensional statistical models.pdf}
}

@article{giordanoCovariancesRobustnessVariational2018,
  title = {Covariances, {{Robustness}}, and {{Variational Bayes}}},
  author = {Giordano, Ryan and Broderick, Tamara and Jordan, Michael I.},
  year = {2018},
  journal = {Journal of Machine Learning Research},
  volume = {19},
  number = {51},
  pages = {1--49},
  issn = {1533-7928},
  urldate = {2022-02-21},
  abstract = {Mean-field Variational Bayes (MFVB) is an approximate Bayesian posterior inference technique that is increasingly popular due to its fast runtimes on large-scale data sets. However, even when MFVB provides accurate posterior means for certain parameters, it often mis-estimates variances and covariances. Furthermore, prior robustness measures have remained undeveloped for MFVB. By deriving a simple formula for the effect of infinitesimal model perturbations on MFVB posterior means, we provide both improved covariance estimates and local robustness measures for MFVB, thus greatly expanding the practical usefulness of MFVB posterior approximations. The estimates for MFVB posterior covariances rely on a result from the classical Bayesian robustness literature that relates derivatives of posterior expectations to posterior covariances and includes the Laplace approximation as a special case. Our key condition is that the MFVB approximation provides good estimates of a select subset of posterior means---an assumption that has been shown to hold in many practical settings. In our experiments, we demonstrate that our methods are simple, general, and fast, providing accurate posterior uncertainty estimates and robustness measures with runtimes that can be an order of magnitude faster than MCMC.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Giordano et al_2018_Covariances, Robustness, and Variational Bayes.pdf}
}

@article{giraldoFullyNaturalGradient2020,
  title = {A {{Fully Natural Gradient Scheme}} for {{Improving Inference}} of the {{Heterogeneous Multi-Output Gaussian Process Model}}},
  author = {Giraldo, Juan-Jos{\'e} and {\'A}lvarez, Mauricio A.},
  year = {2020},
  month = jul,
  journal = {arXiv:1911.10225 [cs, stat]},
  eprint = {1911.10225},
  primaryclass = {cs, stat},
  urldate = {2022-03-22},
  abstract = {A recent novel extension of multi-output Gaussian processes handles heterogeneous outputs assuming that each output has its own likelihood function. It uses a vector-valued Gaussian process prior to jointly model all likelihoods' parameters as latent functions drawn from a Gaussian process with a linear model of coregionalisation covariance. By means of an inducing points framework, the model is able to obtain tractable variational bounds amenable to stochastic variational inference. Nonetheless, the strong conditioning between the variational parameters and the hyper-parameters burdens the adaptive gradient optimisation methods used in the original approach. To overcome this issue we borrow ideas from variational optimisation introducing an exploratory distribution over the hyper-parameters, allowing inference together with the posterior's variational parameters through a fully natural gradient optimisation scheme. Furthermore, in this work we introduce an extension of the heterogeneous multi-output model, where its latent functions are drawn from convolution processes. We show that our optimisation scheme can achieve better local optima solutions with higher test performance rates than adaptive gradient methods, this for both the linear model of coregionalisation and the convolution processes model. We also show how to make the convolutional model scalable by means of stochastic variational inference and how to optimise it through a fully natural gradient scheme. We compare the performance of the different methods over toy and real databases.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Giraldo_Álvarez_2020_A Fully Natural Gradient Scheme for Improving Inference of the Heterogeneous.pdf;/Users/lichengk/Zotero/storage/GCHKYJ6Y/1911.html}
}

@book{givensComputationalStatistics,
  title = {Computational {{Statistics}}},
  author = {Givens, Geof H},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Givens_Computational Statistics.pdf}
}

@misc{glocklerVariationalMethodsSimulationbased2022,
  title = {Variational Methods for Simulation-Based Inference},
  author = {Gl{\"o}ckler, Manuel and Deistler, Michael and Macke, Jakob H.},
  year = {2022},
  month = oct,
  number = {arXiv:2203.04176},
  eprint = {2203.04176},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-12-16},
  abstract = {We present Sequential Neural Variational Inference (SNVI), an approach to perform Bayesian inference in models with intractable likelihoods. SNVI combines likelihood-estimation (or likelihood-ratio-estimation) with variational inference to achieve a scalable simulation-based inference approach. SNVI maintains the flexibility of likelihood(-ratio) estimation to allow arbitrary proposals for simulations, while simultaneously providing a functional estimate of the posterior distribution without requiring MCMC sampling. We present several variants of SNVI and demonstrate that they are substantially more computationally efficient than previous algorithms, without loss of accuracy on benchmark tasks. We apply SNVI to a neuroscience model of the pyloric network in the crab and demonstrate that it can infer the posterior distribution with one order of magnitude fewer simulations than previously reported. SNVI vastly reduces the computational cost of simulation-based inference while maintaining accuracy and flexibility, making it possible to tackle problems that were previously inaccessible.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/LWMQAZAA/Glöckler et al. - 2022 - Variational methods for simulation-based inference.pdf;/Users/lichengk/Zotero/storage/YK7NLLDL/2203.html}
}

@book{golubMatrixComputations2013,
  title = {Matrix Computations},
  author = {Golub, Gene H. and Van Loan, Charles F.},
  year = {2013},
  series = {Johns {{Hopkins}} Studies in the Mathematical Sciences},
  edition = {Fourth edition},
  publisher = {{The Johns Hopkins University Press}},
  address = {{Baltimore}},
  isbn = {978-1-4214-0794-4},
  langid = {english},
  lccn = {QA188 .G65 2013},
  keywords = {Data processing,Matrices},
  annotation = {OCLC: ocn824733531},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Golub_Van Loan_2013_Matrix computations.pdf}
}

@misc{gongInterpretingDiffusionScore2021,
  title = {Interpreting Diffusion Score Matching Using Normalizing Flow},
  author = {Gong, Wenbo and Li, Yingzhen},
  year = {2021},
  month = jul,
  number = {arXiv:2107.10072},
  eprint = {2107.10072},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-12-06},
  abstract = {Scoring matching (SM), and its related counterpart, Stein discrepancy (SD) have achieved great success in model training and evaluations. However, recent research shows their limitations when dealing with certain types of distributions. One possible fix is incorporating the original score matching (or Stein discrepancy) with a diffusion matrix, which is called diffusion score matching (DSM) (or diffusion Stein discrepancy (DSD)). However, the lack of interpretation of the diffusion limits its usage within simple distributions and manually chosen matrix. In this work, we plan to fill this gap by interpreting the diffusion matrix using normalizing flows. Specifically, we theoretically prove that DSM (or DSD) is equivalent to the original score matching (or Stein discrepancy) evaluated in the transformed space defined by the normalizing flow, where the diffusion matrix is the inverse of the flow's Jacobian matrix. In addition, we also build its connection to Riemannian manifolds and further extend it to continuous flows, where the change of DSM is characterized by an ODE.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/ERMSPVDY/Gong and Li - 2021 - Interpreting diffusion score matching using normal.pdf;/Users/lichengk/Zotero/storage/PEZGU5TV/2107.html}
}

@misc{gonzalezBatchBayesianOptimization2015,
  title = {Batch {{Bayesian Optimization}} via {{Local Penalization}}},
  author = {Gonz{\'a}lez, Javier and Dai, Zhenwen and Hennig, Philipp and Lawrence, Neil D.},
  year = {2015},
  month = oct,
  number = {arXiv:1505.08052},
  eprint = {1505.08052},
  primaryclass = {stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1505.08052},
  urldate = {2023-01-17},
  abstract = {The popularity of Bayesian optimization methods for efficient exploration of parameter spaces has lead to a series of papers applying Gaussian processes as surrogates in the optimization of functions. However, most proposed approaches only allow the exploration of the parameter space to occur sequentially. Often, it is desirable to simultaneously propose batches of parameter values to explore. This is particularly the case when large parallel processing facilities are available. These facilities could be computational or physical facets of the process being optimized. E.g. in biological experiments many experimental set ups allow several samples to be simultaneously processed. Batch methods, however, require modeling of the interaction between the evaluations in the batch, which can be expensive in complex scenarios. We investigate a simple heuristic based on an estimate of the Lipschitz constant that captures the most important aspect of this interaction (i.e. local repulsion) at negligible computational overhead. The resulting algorithm compares well, in running time, with much more elaborate alternatives. The approach assumes that the function of interest, \$f\$, is a Lipschitz continuous function. A wrap-loop around the acquisition function is used to collect batches of points of certain size minimizing the non-parallelizable computational effort. The speed-up of our method with respect to previous approaches is significant in a set of computationally expensive experiments.},
  archiveprefix = {arxiv},
  keywords = {ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/6AMV5CZP/González et al. - 2015 - Batch Bayesian Optimization via Local Penalization.pdf;/Users/lichengk/Zotero/storage/LJSGEUMP/1505.html}
}

@article{goodmanEnsembleSamplersAffine2010,
  title = {Ensemble Samplers with Affine Invariance},
  author = {Goodman, Jonathan and Weare, Jonathan},
  year = {2010},
  month = jan,
  journal = {Communications in Applied Mathematics and Computational Science},
  volume = {5},
  number = {1},
  pages = {65--80},
  issn = {2157-5452, 1559-3940},
  doi = {10.2140/camcos.2010.5.65},
  urldate = {2022-01-27},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/Zotero/storage/XIJ7L24C/Goodman and Weare - 2010 - Ensemble samplers with affine invariance.pdf}
}

@article{gravesStochasticBackpropagationMixture2016,
  title = {Stochastic {{Backpropagation}} through {{Mixture Density Distributions}}},
  author = {Graves, Alex},
  year = {2016},
  month = jul,
  journal = {arXiv:1607.05690 [cs]},
  eprint = {1607.05690},
  primaryclass = {cs},
  urldate = {2021-06-11},
  abstract = {The ability to backpropagate stochastic gradients through continuous latent distributions has been crucial to the emergence of variational autoencoders and stochastic gradient variational Bayes. The key ingredient is an unbiased and low-variance way of estimating gradients with respect to distribution parameters from gradients evaluated at distribution samples. The "reparameterization trick" provides a class of transforms yielding such estimators for many continuous distributions, including the Gaussian and other members of the location-scale family. However the trick does not readily extend to mixture density models, due to the difficulty of reparameterizing the discrete distribution over mixture weights. This report describes an alternative transform, applicable to any continuous multivariate distribution with a differentiable density function from which samples can be drawn, and uses it to derive an unbiased estimator for mixture density weight derivatives. Combined with the reparameterization trick applied to the individual mixture components, this estimator makes it straightforward to train variational autoencoders with mixture-distributed latent variables, or to perform stochastic variational inference with a mixture density variational posterior.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Neural and Evolutionary Computing,toread},
  annotation = {29 citations (Semantic Scholar/arXiv) [2021-06-11]},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Graves_2016_Stochastic Backpropagation through Mixture Density Distributions.pdf;/Users/lichengk/Zotero/storage/HMB3I2C7/1607.html}
}

@article{grettonNewDirectionsLearning2017,
  title = {New {{Directions}} for {{Learning}} with {{Kernels}} and {{Gaussian Processes}} ({{Dagstuhl Seminar}} 16481)},
  author = {Gretton, Arthur and Hennig, Philipp and Rasmussen, Carl Edward and Sch{\"o}lkopf, Bernhard},
  year = {2017},
  pages = {26 pages},
  publisher = {{Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany}},
  doi = {10.4230/DAGREP.6.11.142},
  urldate = {2021-12-19},
  abstract = {The Dagstuhl Seminar on 16481 ``New Directions for Learning with Kernels and Gaussian Processes'' brought together two principal theoretical camps of the machine learning community at a crucial time for the field. Kernel methods and Gaussian process models together form a significant part of the discipline's foundations, but their prominence is waning while more elaborate but poorly understood hierarchical models are ascendant. In a lively, amiable seminar, the participants re-discovered common conceptual ground (and some continued points of disagreement) and productively discussed how theoretical rigour can stay relevant during a hectic phase for the subject.},
  collaborator = {Herbstritt, Marc},
  langid = {english},
  keywords = {{000 Computer science, knowledge, general works},Computer Science,toread},
  file = {/Users/lichengk/Zotero/storage/AUKSKNNG/Gretton et al. - 2017 - New Directions for Learning with Kernels and Gauss.pdf}
}

@misc{grumittDeterministicLangevinMonte2022,
  title = {Deterministic {{Langevin Monte Carlo}} with {{Normalizing Flows}} for {{Bayesian Inference}}},
  author = {Grumitt, Richard D. P. and Dai, Biwei and Seljak, Uros},
  year = {2022},
  month = oct,
  number = {arXiv:2205.14240},
  eprint = {2205.14240},
  primaryclass = {cond-mat, physics:physics, stat},
  publisher = {{arXiv}},
  urldate = {2022-12-13},
  abstract = {We propose a general purpose Bayesian inference algorithm for expensive likelihoods, replacing the stochastic term in the Langevin equation with a deterministic density gradient term. The particle density is evaluated from the current particle positions using a Normalizing Flow (NF), which is differentiable and has good generalization properties in high dimensions. We take advantage of NF preconditioning and NF based Metropolis-Hastings updates for a faster convergence. We show on various examples that the method is competitive against state of the art sampling methods.},
  archiveprefix = {arxiv},
  keywords = {62-08,Computer Science - Machine Learning,Condensed Matter - Statistical Mechanics,{Physics - Data Analysis, Statistics and Probability},Statistics - Computation,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/Zotero/storage/CDMEET9F/Grumitt et al. - 2022 - Deterministic Langevin Monte Carlo with Normalizin.pdf;/Users/lichengk/Zotero/storage/ZKWKH4UD/2205.html}
}

@misc{guedjPrimerPACBayesianLearning2019,
  title = {A {{Primer}} on {{PAC-Bayesian Learning}}},
  author = {Guedj, Benjamin},
  year = {2019},
  month = may,
  number = {arXiv:1901.05353},
  eprint = {1901.05353},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-04-27},
  abstract = {Generalised Bayesian learning algorithms are increasingly popular in machine learning, due to their PAC generalisation properties and flexibility. The present paper aims at providing a self-contained survey on the resulting PAC-Bayes framework and some of its main theoretical and algorithmic developments.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/HF769KB8/Guedj - 2019 - A Primer on PAC-Bayesian Learning.pdf;/Users/lichengk/Zotero/storage/Q438RGDV/1901.html}
}

@phdthesis{gunterEfficientBayesianInference2017,
  type = {{{http://purl.org/dc/dcmitype/Text}}},
  title = {Towards Efficient {{Bayesian}} Inference: {{Cox}} Processes and Probabilistic Integration},
  shorttitle = {Towards Efficient {{Bayesian}} Inference},
  author = {Gunter, Tom},
  year = {2017},
  urldate = {2021-08-06},
  abstract = {{$<$}p{$>$}In this thesis we present a variety of new, continuous, Bayesian Gaussian-process-driven Cox process models. These are used to model sparse event data distributed on a continuous domain, where the events may have a tendency to cluster. These find direct use in application areas ranging from disease incidence modelling through to statistical cosmology, where the distribution of galaxies in the universe is weakly clustered due to the effects of dark matter. They may also be deployed in a more abstract sense, for example as a structured prior for network communications.{$<$}/p{$>$} {$<$}p{$>$}In previous work, the difficulty of performing inference in Gaussian-process-driven Cox processes has hindered their application to large, high-dimensional datasets. We develop novel and computationally efficient inference schemes for these models as well as our own extensions to them, demonstrating an improvement on the existing state of the art using real data. In particular, we present the first known variational inference scheme for such models, which scales linearly with the size of the dataset.{$<$}/p{$>$} {$<$}p{$>$}Spurred on to consider the problem of computationally efficient Bayesian inference in general, we tackle model evidence estimation. Arriving at an accurate measure of model evidence quickly allows for the objective measure of model fit, and ensures we select a set of assumptions which most closely embody the data-generating process.{$<$}/p{$>$} {$<$}p{$>$}We deviate from the traditional core Monte Carlo estimator, and instead present a computationally efficient general Bayesian quadrature scheme for model evidence computation. This is the first such scheme which can be shown to be demonstrably wall-clock competitive with state of the art Monte Carlo approaches.{$<$}/p{$>$}},
  langid = {english},
  school = {University of Oxford},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gunter_2017_Towards efficient Bayesian inference.pdf;/Users/lichengk/Zotero/storage/HZBCRTHL/uuid32ccb7f8-6eaf-420f-bf97-113d3504dfa5.html}
}

@inproceedings{gunterSamplingInferenceProbabilistic2014,
  title = {Sampling for Inference in Probabilistic Models with Fast Bayesian Quadrature},
  booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
  author = {Gunter, Tom and Osborne, Michael A. and Garnett, Roman and Hennig, Philipp and Roberts, Stephen J.},
  year = {2014},
  series = {{{NIPS}}'14},
  pages = {2789--2797},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  abstract = {We propose a novel sampling framework for inference in probabilistic models: an active learning approach that converges more quickly (in wall-clock time) than Markov chain Monte Carlo (MCMC) benchmarks. The central challenge in probabilistic inference is numerical integration, to average over ensembles of models or unknown (hyper-)parameters (for example to compute the marginal likelihood or a partition function). MCMC has provided approaches to numerical integration that deliver state-of-the-art inference, but can suffer from sample inefficiency and poor convergence diagnostics. Bayesian quadrature techniques offer a model-based solution to such problems, but their uptake has been hindered by prohibitive computation costs. We introduce a warped model for probabilistic integrands (likelihoods) that are known to be non-negative, permitting a cheap active learning scheme to optimally select sample locations. Our algorithm is demonstrated to offer faster convergence (in seconds) relative to simple Monte Carlo and annealed importance sampling on both synthetic and real-world examples.},
  keywords = {done,ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gunter et al_2014_Sampling for inference in probabilistic models with fast bayesian quadrature.pdf}
}

@inproceedings{guoCalibrationModernNeural2017,
  title = {On {{Calibration}} of {{Modern Neural Networks}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}}},
  author = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
  year = {2017},
  month = jul,
  pages = {1321--1330},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-11-10},
  abstract = {Confidence calibration \textendash{} the problem of predicting probability estimates representative of the true correctness likelihood \textendash{} is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling \textendash{} a single-parameter variant of Platt Scaling \textendash{} is surprisingly effective at calibrating predictions.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Guo et al_2017_On Calibration of Modern Neural Networks.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Guo et al_2017_On Calibration of Modern Neural Networks2.pdf}
}

@article{gutmannBayesianOptimizationLikelihoodFree,
  title = {Bayesian {{Optimization}} for {{Likelihood-Free Inference}} of {{Simulator-Based Statistical Models}}},
  author = {Gutmann, Michael U and Corander, Jukka},
  pages = {47},
  abstract = {Our paper deals with inferring simulator-based statistical models given some observed data. A simulator-based model is a parametrized mechanism which specifies how data are generated. It is thus also referred to as generative model. We assume that only a finite number of parameters are of interest and allow the generative process to be very general; it may be a noisy nonlinear dynamical system with an unrestricted number of hidden variables. This weak assumption is useful for devising realistic models but it renders statistical inference very difficult. The main challenge is the intractability of the likelihood function. Several likelihood-free inference methods have been proposed which share the basic idea of identifying the parameters by finding values for which the discrepancy between simulated and observed data is small. A major obstacle to using these methods is their computational cost. The cost is largely due to the need to repeatedly simulate data sets and the lack of knowledge about how the parameters affect the discrepancy. We propose a strategy which combines probabilistic modeling of the discrepancy with optimization to facilitate likelihood-free inference. The strategy is implemented using Bayesian optimization and is shown to accelerate the inference through a reduction in the number of required simulations by several orders of magnitude.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gutmann_Corander_Bayesian Optimization for Likelihood-Free Inference of Simulator-Based.pdf}
}

@misc{gutmannBregmanDivergenceGeneral2012,
  title = {Bregman Divergence as General Framework to Estimate Unnormalized Statistical Models},
  author = {Gutmann, Michael and Hirayama, Jun-ichiro},
  year = {2012},
  month = feb,
  number = {arXiv:1202.3727},
  eprint = {1202.3727},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-02-05},
  abstract = {We show that the Bregman divergence provides a rich framework to estimate unnormalized statistical models for continuous or discrete random variables, that is, models which do not integrate or sum to one, respectively. We prove that recent estimation methods such as noise-contrastive estimation, ratio matching, and score matching belong to the proposed framework, and explain their interconnection based on supervised learning. Further, we discuss the role of boosting in unsupervised learning.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gutmann_Hirayama_2012_Bregman divergence as general framework to estimate unnormalized statistical.pdf;/Users/lichengk/Zotero/storage/WZ3UZXNI/1202.html}
}

@article{gutmannESTIMATIONUNNORMALIZEDSTATISTICAL,
  title = {{{ESTIMATION OF UNNORMALIZED STATISTICAL MODELS WITHOUT NUMERICAL INTEGRATION}}},
  author = {Gutmann, Michael U and Hyvarinen, Aapo},
  abstract = {Parametric statistical models of continuous or discrete valued data are often not properly normalized, that is, they do not integrate or sum to unity. The normalization is essential for maximum likelihood estimation. While in principle, models can always be normalized by dividing them by their integral or sum (their partition function), this can in practice be extremely difficult. We have been developing methods for the estimation of unnormalized models which do not approximate the partition function using numerical integration. We review these methods, score matching and noise-contrastive estimation, point out extensions and connections both between them and methods by other authors, and discuss their pros and cons.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/Zotero/storage/QKDZPZCP/Gutmann and Hyvarinen - ESTIMATION OF UNNORMALIZED STATISTICAL MODELS WITH.pdf}
}

@inproceedings{gutmannNoisecontrastiveEstimationNew2010,
  title = {Noise-Contrastive Estimation: {{A}} New Estimation Principle for Unnormalized Statistical Models},
  shorttitle = {Noise-Contrastive Estimation},
  booktitle = {Proceedings of the {{Thirteenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  year = {2010},
  month = mar,
  pages = {297--304},
  publisher = {{JMLR Workshop and Conference Proceedings}},
  issn = {1938-7228},
  urldate = {2023-02-05},
  abstract = {We present a new estimation principle for parameterized statistical models. The idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise, using the model log-density function in the regression nonlinearity.  We show that this leads to a consistent (convergent) estimator of the parameters, and analyze the asymptotic variance.  In particular, the method is shown to directly work for unnormalized models, i.e. models where the density function does not integrate to one. The normalization constant can be estimated just like any other parameter. For a tractable ICA model, we compare the method with other estimation methods that can be used to learn unnormalized models, including score matching, contrastive divergence, and maximum-likelihood where the normalization constant is estimated with importance sampling. Simulations show that noise-contrastive estimation offers the best trade-off between computational and statistical efficiency. The method is then applied to the modeling of natural images: We show that the method can successfully estimate a large-scale two-layer model and a Markov random field.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Gutmann_Hyvärinen_2010_Noise-contrastive estimation.pdf}
}

@article{hagemannStochasticNormalizingFlows2022,
  title = {Stochastic {{Normalizing Flows}} for {{Inverse Problems}}: A {{Markov Chains Viewpoint}}},
  shorttitle = {Stochastic {{Normalizing Flows}} for {{Inverse Problems}}},
  author = {Hagemann, Paul and Hertrich, Johannes and Steidl, Gabriele},
  year = {2022},
  month = sep,
  journal = {SIAM/ASA Journal on Uncertainty Quantification},
  volume = {10},
  number = {3},
  eprint = {2109.11375},
  primaryclass = {cs, math},
  pages = {1162--1190},
  issn = {2166-2525},
  doi = {10.1137/21M1450604},
  urldate = {2023-01-05},
  abstract = {To overcome topological constraints and improve the expressiveness of normalizing flow architectures, Wu, K\textbackslash "ohler and No\textbackslash 'e introduced stochastic normalizing flows which combine deterministic, learnable flow transformations with stochastic sampling methods. In this paper, we consider stochastic normalizing flows from a Markov chain point of view. In particular, we replace transition densities by general Markov kernels and establish proofs via Radon-Nikodym derivatives which allows to incorporate distributions without densities in a sound way. Further, we generalize the results for sampling from posterior distributions as required in inverse problems. The performance of the proposed conditional stochastic normalizing flow is demonstrated by numerical examples.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Probability,ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hagemann et al_2022_Stochastic Normalizing Flows for Inverse Problems.pdf;/Users/lichengk/Zotero/storage/B2LZH3YX/Hagemann et al. - 2022 - Stochastic Normalizing Flows for Inverse Problems.pdf;/Users/lichengk/Zotero/storage/8BMK46C8/2109.html}
}

@inproceedings{hamelijnckSpatioTemporalVariationalGaussian2021,
  title = {Spatio-{{Temporal Variational Gaussian Processes}}},
  booktitle = {Thirty-{{Fifth Conference}} on {{Neural Information Processing Systems}}},
  author = {Hamelijnck, Oliver and Wilkinson, William J. and Loppi, Niki Andreas and Solin, Arno and Damoulas, Theo},
  year = {2021},
  month = may,
  urldate = {2021-12-15},
  abstract = {We derive a natural gradient variational inference method for Gaussian processes based on filtering and smoothing that improves the computational efficiency and predictive performance when applied...},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hamelijnck et al_2021_Spatio-Temporal Variational Gaussian Processes.pdf;/Users/lichengk/Zotero/storage/MQK2KSBK/forum.html}
}

@article{hamidMarginalisingStationaryKernels2021,
  title = {Marginalising over {{Stationary Kernels}} with {{Bayesian Quadrature}}},
  author = {Hamid, Saad and Schulze, Sebastian and Osborne, Michael A. and Roberts, Stephen J.},
  year = {2021},
  month = jun,
  journal = {arXiv:2106.07452 [cs, stat]},
  eprint = {2106.07452},
  primaryclass = {cs, stat},
  urldate = {2021-07-01},
  abstract = {Marginalising over families of Gaussian Process kernels produces flexible model classes with well-calibrated uncertainty estimates. Existing approaches require likelihood evaluations of many kernels, rendering them prohibitively expensive for larger datasets. We propose a Bayesian Quadrature scheme to make this marginalisation more efficient and thereby more practical. Through use of the maximum mean discrepancies between distributions, we define a kernel over kernels that captures invariances between Spectral Mixture (SM) Kernels. Kernel samples are selected by generalising an information-theoretic acquisition function for warped Bayesian Quadrature. We show that our framework achieves more accurate predictions with better calibrated uncertainty than state-of-the-art baselines, especially when given limited (wall-clock) time budgets.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hamid et al_2021_Marginalising over Stationary Kernels with Bayesian Quadrature.pdf;/Users/lichengk/Zotero/storage/K4TH55WN/2106.html}
}

@misc{hamidMarginalisingStationaryKernels2022,
  title = {Marginalising over {{Stationary Kernels}} with {{Bayesian Quadrature}}},
  author = {Hamid, Saad and Schulze, Sebastian and Osborne, Michael A. and Roberts, Stephen J.},
  year = {2022},
  month = mar,
  number = {arXiv:2106.07452},
  eprint = {2106.07452},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-07-25},
  abstract = {Marginalising over families of Gaussian Process kernels produces flexible model classes with well-calibrated uncertainty estimates. Existing approaches require likelihood evaluations of many kernels, rendering them prohibitively expensive for larger datasets. We propose a Bayesian Quadrature scheme to make this marginalisation more efficient and thereby more practical. Through use of the maximum mean discrepancies between distributions, we define a kernel over kernels that captures invariances between Spectral Mixture (SM) Kernels. Kernel samples are selected by generalising an information-theoretic acquisition function for warped Bayesian Quadrature. We show that our framework achieves more accurate predictions with better calibrated uncertainty than state-of-the-art baselines, especially when given limited (wall-clock) time budgets.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hamid et al_2022_Marginalising over Stationary Kernels with Bayesian Quadrature.pdf;/Users/lichengk/Zotero/storage/A8MTXR95/2106.html}
}

@article{hansenCMAEvolutionStrategy2016,
  title = {The {{CMA Evolution Strategy}}: {{A Tutorial}}},
  shorttitle = {The {{CMA Evolution Strategy}}},
  author = {Hansen, Nikolaus},
  year = {2016},
  month = apr,
  journal = {arXiv:1604.00772 [cs, stat]},
  eprint = {1604.00772},
  primaryclass = {cs, stat},
  urldate = {2021-10-07},
  abstract = {This tutorial introduces the CMA Evolution Strategy (ES), where CMA stands for Covariance Matrix Adaptation. The CMA-ES is a stochastic, or randomized, method for real-parameter (continuous domain) optimization of non-linear, non-convex functions. We try to motivate and derive the algorithm from intuitive concepts and from requirements of non-linear, non-convex search in continuous domain.},
  archiveprefix = {arxiv},
  keywords = {*5{$\medwhitestar\medwhitestar\medwhitestar\medwhitestar\medwhitestar$},Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/VJCN7JG8/Hansen - 2016 - The CMA Evolution Strategy A Tutorial.pdf;/Users/lichengk/Zotero/storage/E3H66F3N/1604.html}
}

@article{hardtPatternsPredictionsActions,
  title = {Patterns, {{Predictions}}, and {{Actions}}},
  author = {Hardt, Moritz and Recht, Benjamin},
  pages = {309},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hardt_Recht_Patterns, Predictions, and Actions.pdf}
}

@misc{HarmonicMeanLikelihood2008,
  title = {The {{Harmonic Mean}} of the {{Likelihood}}: {{Worst Monte Carlo Method Ever}}},
  shorttitle = {The {{Harmonic Mean}} of the {{Likelihood}}},
  year = {2008},
  month = aug,
  journal = {Radford Neal's blog},
  urldate = {2022-01-28},
  abstract = {Many Bayesian statisticians decide which of several models is most appropriate for a given dataset by computing the marginal likelihood of each model (also called the integrated likelihood or the e\ldots},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/5RBJLSPP/the-harmonic-mean-of-the-likelihood-worst-monte-carlo-method-ever.html}
}

@unpublished{haughMCMCBayesianModeling2017,
  title = {{{MCMC}} and {{Bayesian Modeling}}},
  author = {Haugh, Martin},
  year = {2017},
  urldate = {2021-08-09},
  keywords = {toread},
  annotation = {more detailed version: https://papers.ssrn.com/sol3/papers.cfm?abstract\_id=3759243},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Haugh_2017_MCMC and Bayesian Modeling.pdf}
}

@article{havasiSamplingVariationalPosterior2021,
  title = {Sampling the {{Variational Posterior}} with {{Local Refinement}}},
  author = {Havasi, Marton and Snoek, Jasper and Tran, Dustin and Gordon, Jonathan and {Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel},
  year = {2021},
  month = nov,
  journal = {Entropy},
  volume = {23},
  number = {11},
  pages = {1475},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1099-4300},
  doi = {10.3390/e23111475},
  urldate = {2022-11-01},
  abstract = {Variational inference is an optimization-based method for approximating the posterior distribution of the parameters in Bayesian probabilistic models. A key challenge of variational inference is to approximate the posterior with a distribution that is computationally tractable yet sufficiently expressive. We propose a novel method for generating samples from a highly flexible variational approximation. The method starts with a coarse initial approximation and generates samples by refining it in selected, local regions. This allows the samples to capture dependencies and multi-modality in the posterior, even when these are absent from the initial approximation. We demonstrate theoretically that our method always improves the quality of the approximation (as measured by the evidence lower bound). In experiments, our method consistently outperforms recent variational inference methods in terms of log-likelihood and ELBO across three example tasks: the Eight-Schools example (an inference task in a hierarchical model), training a ResNet-20 (Bayesian inference in a large neural network), and the Mushroom task (posterior sampling in a contextual bandit problem).},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {bayesian inference,contextual bandits,deep neural networks,variational inference},
  file = {/Users/lichengk/Zotero/storage/MB8GSJU2/Havasi et al. - 2021 - Sampling the Variational Posterior with Local Refi.pdf;/Users/lichengk/Zotero/storage/RKUARF5N/htm.html}
}

@misc{hayakawaPositivelyWeightedKernel2022,
  title = {Positively {{Weighted Kernel Quadrature}} via {{Subsampling}}},
  author = {Hayakawa, Satoshi and Oberhauser, Harald and Lyons, Terry},
  year = {2022},
  month = oct,
  number = {arXiv:2107.09597},
  eprint = {2107.09597},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  urldate = {2022-10-24},
  abstract = {We study kernel quadrature rules with convex weights. Our approach combines the spectral properties of the kernel with recombination results about point measures. This results in effective algorithms that construct convex quadrature rules using only access to i.i.d. samples from the underlying measure and evaluation of the kernel and that result in a small worst-case error. In addition to our theoretical results and the benefits resulting from convex weights, our experiments indicate that this construction can compete with the optimal bounds in well-known examples.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hayakawa et al_2022_Positively Weighted Kernel Quadrature via Subsampling.pdf;/Users/lichengk/Zotero/storage/CPCYCMIV/2107.html}
}

@misc{hayakawaSamplingbasedNystrOm2023,
  title = {Sampling-Based {{Nystr}}\textbackslash "om {{Approximation}} and {{Kernel Quadrature}}},
  author = {Hayakawa, Satoshi and Oberhauser, Harald and Lyons, Terry},
  year = {2023},
  month = jan,
  number = {arXiv:2301.09517},
  eprint = {2301.09517},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  urldate = {2023-03-06},
  abstract = {We analyze the Nystr\textbackslash "om approximation of a positive definite kernel associated with a probability measure. We first prove an improved error bound for the conventional Nystr\textbackslash "om approximation with i.i.d. sampling and singular-value decomposition in the continuous regime; the proof techniques are borrowed from statistical learning theory. We further introduce a refined selection of subspaces in Nystr\textbackslash "om approximation with theoretical guarantees that is applicable to non-i.i.d. landmark points. Finally, we discuss their application to convex kernel quadrature and give novel theoretical guarantees as well as numerical observations.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hayakawa et al_2023_Sampling-based Nystr-om Approximation and Kernel Quadrature.pdf;/Users/lichengk/Zotero/storage/7LEU7H9Q/2301.html}
}

@unpublished{heMultivariateNormalDistribution,
  title = {Multivariate {{Normal Distribution Exponential Family}}},
  author = {He, Xi and Pan, Jiangwei and Razeen, Ali and Srivastava, Animesh},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/He et al_Multivariate Normal Distribution Exponential Family.pdf}
}

@article{hennigProbabilisticNumerics,
  title = {Probabilistic {{Numerics}}},
  author = {Hennig, P and Osborne, M A and Kersting, H P},
  pages = {412},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/MMWSHG6Y/Hennig et al. - Probabilistic Numerics.pdf}
}

@inproceedings{hensmanFastVariationalInference2012,
  title = {Fast {{Variational Inference}} in the {{Conjugate Exponential Family}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Hensman, James and Rattray, Magnus and Lawrence, Neil},
  year = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-02-11},
  keywords = {toread},
  file = {/Users/lichengk/Zotero/storage/YQF69A8H/Hensman et al. - 2012 - Fast Variational Inference in the Conjugate Expone.pdf}
}

@article{hensmanGaussianProcessesBig,
  title = {Gaussian {{Processes}} for {{Big Data}}},
  author = {Hensman, James and Fusi, Nicolo and Lawrence, Neil D},
  pages = {9},
  abstract = {We introduce stochastic variational inference for Gaussian process models. This enables the application of Gaussian process (GP) models to data sets containing millions of data points. We show how GPs can be variationally decomposed to depend on a set of globally relevant inducing variables which factorize the model in the necessary manner to perform variational inference. Our approach is readily extended to models with non-Gaussian likelihoods and latent variable models based around Gaussian processes. We demonstrate the approach on a simple toy problem and two real world data sets.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/LM9NKQT5/Hensman et al. - Gaussian Processes for Big Data.pdf}
}

@inproceedings{hensmanMCMCVariationallySparse2015,
  title = {{{MCMC}} for {{Variationally Sparse Gaussian Processes}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Hensman, James and Matthews, Alexander G and Filippone, Maurizio and Ghahramani, Zoubin},
  year = {2015},
  volume = {28},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-02-15},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hensman et al_2015_MCMC for Variationally Sparse Gaussian Processes.pdf}
}

@article{hensmanScalableVariationalGaussian,
  title = {Scalable {{Variational Gaussian Process Classification}}},
  author = {Hensman, James and Ghahramani, Zoubin},
  pages = {10},
  abstract = {Gaussian process classification is a popular method with a number of appealing properties. We show how to scale the model within a variational inducing point framework, outperforming the state of the art on benchmark datasets. Importantly, the variational formulation can be exploited to allow classification in problems with millions of data points, as we demonstrate in experiments.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/8DV5IGJP/Hensman and Ghahramani - Scalable Variational Gaussian Process Classiﬁcatio.pdf}
}

@inproceedings{hensmanScalableVariationalGaussian2015,
  title = {Scalable Variational {{Gaussian}} Process Classification},
  booktitle = {Artificial {{Intelligence}} and {{Statistics}}},
  author = {Hensman, James and Matthews, Alexander and Ghahramani, Zoubin},
  year = {2015},
  pages = {351--360},
  publisher = {{PMLR}},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hensman et al_2015_Scalable variational Gaussian process classification.pdf;/Users/lichengk/Zotero/storage/D4MUYS9T/hensman15.html}
}

@article{hensmanVariationalFourierFeatures2018,
  title = {Variational Fourier Features for Gaussian Processes},
  author = {Hensman, James and Durrande, Nicolas and Solin, Arno},
  year = {2018},
  journal = {Journal of Machine Learning Research},
  volume = {Volume 18, issue 1},
  pages = {52},
  issn = {1532-4435, 1533-7928},
  langid = {english},
  keywords = {113 Computer and information sciences,APPROXIMATION,COX PROCESSES,Fourier features,Gaussian processes,MODELS,ObsCite,PROCESS REGRESSION,toread,variational inference},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hensman et al_2018_Variational fourier features for gaussian processes.pdf}
}

@inproceedings{hernandez-lobatoPredictiveEntropySearch2014,
  title = {Predictive Entropy Search for Efficient Global Optimization of Black-Box Functions},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {{Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel and Hoffman, Matthew W and Ghahramani, Zoubin},
  editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. and Weinberger, K. Q.},
  year = {2014},
  volume = {27},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hernández-Lobato et al_2014_Predictive entropy search for efficient global optimization of black-box.pdf}
}

@article{hernandez-lobatoProbabilisticBackpropagationScalable,
  title = {Probabilistic {{Backpropagation}} for {{Scalable Learning}} of {{Bayesian Neural Networks}}},
  author = {{Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel and Adams, Ryan P},
  pages = {9},
  abstract = {Large multilayer neural networks trained with backpropagation have recently achieved state-ofthe-art results in a wide range of problems. However, using backprop for neural net learning still has some disadvantages, e.g., having to tune a large number of hyperparameters to the data, lack of calibrated probabilistic predictions, and a tendency to overfit the training data. In principle, the Bayesian approach to learning neural networks does not have these problems. However, existing Bayesian techniques lack scalability to large dataset and network sizes. In this work we present a novel scalable method for learning Bayesian neural networks, called probabilistic backpropagation (PBP). Similar to classical backpropagation, PBP works by computing a forward propagation of probabilities through the network and then doing a backward computation of gradients. A series of experiments on ten real-world datasets show that PBP is significantly faster than other techniques, while offering competitive predictive abilities. Our experiments also show that PBP provides accurate estimates of the posterior variance on the network weights.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hernández-Lobato_Adams_Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks.pdf}
}

@misc{hertrichProximalResidualFlows2022,
  title = {Proximal {{Residual Flows}} for {{Bayesian Inverse Problems}}},
  author = {Hertrich, Johannes},
  year = {2022},
  month = nov,
  number = {arXiv:2211.17158},
  eprint = {2211.17158},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-01-05},
  abstract = {Normalizing flows are a powerful tool for generative modelling, density estimation and posterior reconstruction in Bayesian inverse problems. In this paper, we introduce proximal residual flows, a new architecture of normalizing flows. Based on the fact, that proximal neural networks are by definition averaged operators, we ensure invertibility of certain residual blocks. Moreover, we extend the architecture to conditional proximal residual flows for posterior reconstruction within Bayesian inverse problems. We demonstrate the performance of proximal residual flows on numerical examples.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/RWGPF34Z/Hertrich - 2022 - Proximal Residual Flows for Bayesian Inverse Probl.pdf;/Users/lichengk/Zotero/storage/F4M3FP9K/2211.html}
}

@book{highamAccuracyStabilityNumerical2002,
  title = {Accuracy and Stability of Numerical Algorithms},
  author = {Higham, Nicholas J.},
  year = {2002},
  edition = {2nd ed},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia}},
  isbn = {978-0-89871-521-7},
  langid = {english},
  lccn = {QA297 .H53 2002},
  keywords = {Computer algorithms,Data processing,Numerical analysis},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Higham_2002_Accuracy and stability of numerical algorithms.pdf}
}

@book{highamFunctionsMatricesTheory2008,
  title = {Functions of {{Matrices}}: {{Theory}} and {{Computation}}},
  shorttitle = {Functions of {{Matrices}}},
  author = {Higham, Nicholas J.},
  year = {2008},
  month = jan,
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9780898717778},
  urldate = {2022-01-19},
  isbn = {978-0-89871-646-7 978-0-89871-777-8},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Higham_2008_Functions of Matrices.pdf}
}

@misc{hobsonBayesianInferenceNested2019,
  title = {Bayesian Inference with Nested Sampling},
  shorttitle = {Multimodal Nested Sampling},
  author = {Hobson, M. P.},
  year = {2019},
  month = sep,
  eprint = {0704.3704},
  urldate = {2022-01-05},
  abstract = {In performing a Bayesian analysis of astronomical data, two difficult problems often emerge. First, in estimating the parameters of some model for the data, the resulting posterior distribution may be multimodal or exhibit pronounced (curving) degeneracies, which can cause problems for traditional MCMC sampling methods. Second, in selecting between a set of competing models, calculation of the Bayesian evidence for each model is computationally expensive. The nested sampling method introduced by Skilling (2004), has greatly reduced the computational expense of calculating evidences and also produces posterior inferences as a by-product. This method has been applied successfully in cosmological applications by Mukherjee et al. (2006), but their implementation was efficient only for unimodal distributions without pronounced degeneracies. Shaw et al. (2007), recently introduced a clustered nested sampling method which is significantly more efficient in sampling from multimodal posteriors and also determines the expectation and variance of the final evidence from a single run of the algorithm, hence providing a further increase in efficiency. In this paper, we build on the work of Shaw et al. and present three new methods for sampling and evidence evaluation from distributions that may contain multiple modes and significant degeneracies; we also present an even more efficient technique for estimating the uncertainty on the evaluated evidence. These methods lead to a further substantial improvement in sampling efficiency and robustness, and are applied to toy problems to demonstrate the accuracy and economy of the evidence calculation and parameter estimation. Finally, we discuss the use of these methods in performing Bayesian object detection in astronomical datasets.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Astrophysics,ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Feroz_Hobson_2008_Multimodal nested sampling.pdf}
}

@book{hoffFirstCourseBayesian2009,
  title = {A {{First Course}} in {{Bayesian Statistical Methods}}},
  author = {Hoff, Peter D.},
  year = {2009},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-92407-6},
  urldate = {2022-08-21},
  isbn = {978-0-387-92299-7 978-0-387-92407-6},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hoff_2009_A First Course in Bayesian Statistical Methods.pdf}
}

@article{hoffmanBlackBoxVariationalInference,
  title = {Black-{{Box Variational Inference}} as {{Distilled Langevin Dynamics}}},
  author = {Hoffman, Matthew and Ma, Yi-An},
  pages = {18},
  abstract = {Variational inference (VI) and Markov chain Monte Carlo (MCMC) are approximate posterior inference algorithms that are often said to have complementary strengths, with VI being fast but biased and MCMC being slower but asymptotically unbiased. In this paper, we analyze gradientbased MCMC and VI procedures and find theoretical and empirical evidence that these procedures are not as different as one might think. In particular, a close examination of the FokkerPlanck equation that governs the Langevin dynamics (LD) MCMC procedure reveals that LD implicitly follows a gradient flow that corresponds to a variational inference procedure based on optimizing a nonparametric normalizing flow. This result suggests that the transient bias of LD (due to the Markov chain not having burned in) may track that of VI (due to the optimizer not having converged), up to differences due to VI's asymptotic bias and parameterization. Empirically, we find that the transient biases of these algorithms (and their momentum-accelerated counterparts) do evolve similarly. This suggests that practitioners with a limited time budget may get more accurate results by running an MCMC procedure (even if it's far from burned in) than a VI procedure, as long as the variance of the MCMC estimator can be dealt with (e.g., by running many parallel chains).},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/A6G6BGP6/Hoffman and Ma - Black-Box Variational Inference as Distilled Lange.pdf}
}

@article{hoffmanNoUTurnSamplerAdaptively,
  title = {The {{No-U-Turn Sampler}}: {{Adaptively Setting Path Lengths}} in {{Hamiltonian Monte Carlo}}},
  author = {Hoffman, Matthew D and Gelman, Andrew},
  pages = {31},
  abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS performs at least as efficiently as (and sometimes more efficiently than) a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all, making it suitable for applications such as BUGS-style automatic inference engines that require efficient ``turnkey'' samplers.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hoﬀman_Gelman_The No-U-Turn Sampler.pdf}
}

@article{hoffmanPortfolioAllocationBayesian,
  title = {Portfolio {{Allocation}} for {{Bayesian Optimization}}},
  author = {Hoffman, Matthew and Brochu, Eric and {de Freitas}, Nando},
  pages = {12},
  abstract = {Bayesian optimization with Gaussian processes has become an increasingly popular tool in the machine learning community. It is efficient and can be used when very little is known about the objective function, making it popular in expensive black-box optimization scenarios. It uses Bayesian methods to sample the objective efficiently using an acquisition function which incorporates the posterior estimate of the objective. However, there are several different parameterized acquisition functions in the literature, and it is often unclear which one to use. Instead of using a single acquisition function, we adopt a portfolio of acquisition functions governed by an online multi-armed bandit strategy. We propose several portfolio strategies, the best of which we call GP-Hedge, and show that this method outperforms the best individual acquisition function. We also provide a theoretical bound on the algorithm's performance.},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hoﬀman et al_Portfolio Allocation for Bayesian Optimization.pdf}
}

@article{hoffmanStochasticVariationalInference,
  title = {Stochastic {{Variational Inference}}},
  author = {Hoffman, Matthew D},
  pages = {45},
  abstract = {We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/Zotero/storage/QQZ8L6YV/Hoffman - Stochastic Variational Inference.pdf}
}

@article{hoggDataAnalysisRecipes2018,
  title = {Data Analysis Recipes: {{Using Markov Chain Monte Carlo}}},
  shorttitle = {Data Analysis Recipes},
  author = {Hogg, David W. and {Foreman-Mackey}, Daniel},
  year = {2018},
  month = may,
  journal = {The Astrophysical Journal Supplement Series},
  volume = {236},
  number = {1},
  eprint = {1710.06068},
  primaryclass = {astro-ph, physics:physics, stat},
  pages = {11},
  issn = {1538-4365},
  doi = {10.3847/1538-4365/aab76e},
  urldate = {2022-05-26},
  abstract = {Markov Chain Monte Carlo (MCMC) methods for sampling probability density functions (combined with abundant computational resources) have transformed the sciences, especially in performing probabilistic inferences, or fitting models to data. In this primarily pedagogical contribution, we give a brief overview of the most basic MCMC method and some practical advice for the use of MCMC in real inference problems. We give advice on method choice, tuning for performance, methods for initialization, tests of convergence, troubleshooting, and use of the chain output to produce or report parameter estimates with associated uncertainties. We argue that autocorrelation time is the most important test for convergence, as it directly connects to the uncertainty on the sampling estimate of any quantity of interest. We emphasize that sampling is a method for doing integrals; this guides our thinking about how MCMC output is best used.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics,{Physics - Data Analysis, Statistics and Probability},Statistics - Computation},
  file = {/Users/lichengk/Zotero/storage/5IDH5WRP/Hogg and Foreman-Mackey - 2018 - Data analysis recipes Using Markov Chain Monte Ca.pdf;/Users/lichengk/Zotero/storage/7KPHZ2X4/1710.html}
}

@inproceedings{holbrookNonparametricFisherGeometry2020,
  title = {Nonparametric {{Fisher Geometry}} with {{Application}} to {{Density Estimation}}},
  booktitle = {Conference on {{Uncertainty}} in {{Artificial Intelligence}}},
  author = {Holbrook, Andrew and Lan, Shiwei and Streets, Jeffrey and Shahbaba, Babak},
  year = {2020},
  pages = {101--110},
  publisher = {{PMLR}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Holbrook et al_2020_Nonparametric Fisher Geometry with Application to Density Estimation.pdf;/Users/lichengk/Zotero/storage/H7QJNU3H/holbrook20a.html}
}

@book{honkelaComputationalStatistics,
  title = {Computational {{Statistics I}}},
  author = {Honkela, Antti},
  urldate = {2021-08-11},
  abstract = {Course notes for Computational Statistics I},
  file = {/Users/lichengk/Zotero/storage/QIF97DTB/book.html}
}

@book{hsingTheoreticalFoundationsFunctional,
  title = {Theoretical {{Foundations}} of {{Functional Data Analysis}}, with an {{Introduction}} to {{Linear Operators}}},
  author = {Hsing, Tailen},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hsing_Theoretical Foundations of Functional Data Analysis, with an Introduction to.pdf}
}

@article{hualuogengLunYiZhiFenBuYuJinSiFenXiShuLunFangFa,
  title = {论一致分布与近似分析\textemdash\textemdash 数论方法(I)},
  author = {华罗庚 and 王元},
  journal = {Scientia Sinica (in Chinese)},
  volume = {3},
  number = {4},
  pages = {339--357},
  publisher = {{Science China Press}},
  issn = {1000--000,},
  doi = {10.1360/za1973-3-4-339},
  urldate = {2021-06-11},
  abstract = {本文研究由实分圆域定义的一致分布点列贯,求出了它们的偏差,并应用于数值积分问题.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/华罗庚_王元_论一致分布与近似分析——数论方法(Ⅰ).pdf;/Users/lichengk/Zotero/storage/YZR8U2D4/za1973-3-4-339.html}
}

@inproceedings{huangNeuralAutoregressiveFlows2018,
  title = {Neural {{Autoregressive Flows}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Huang, Chin-Wei and Krueger, David and Lacoste, Alexandre and Courville, Aaron},
  year = {2018},
  month = jul,
  pages = {2078--2087},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-01-16},
  abstract = {Normalizing flows and autoregressive models have been successfully combined to produce state-of-the-art results in density estimation, via Masked Autoregressive Flows (MAF) (Papamakarios et al., 2017), and to accelerate state-of-the-art WaveNet-based speech synthesis to 20x faster than real-time (Oord et al., 2017), via Inverse Autoregressive Flows (IAF) (Kingma et al., 2016). We unify and generalize these approaches, replacing the (conditionally) affine univariate transformations of MAF/IAF with a more general class of invertible univariate transformations expressed as monotonic neural networks. We demonstrate that the proposed neural autoregressive flows (NAF) are universal approximators for continuous probability distributions, and their greater expressivity allows them to better capture multimodal target distributions. Experimentally, NAF yields state-of-the-art performance on a suite of density estimation tasks and outperforms IAF in variational autoencoders trained on binarized MNIST.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/6US6Z5RP/Huang et al. - 2018 - Neural Autoregressive Flows.pdf;/Users/lichengk/Zotero/storage/ATAVMTUU/Huang et al. - 2018 - Neural Autoregressive Flows.pdf}
}

@inproceedings{huberEntropyApproximationGaussian2008,
  title = {On Entropy Approximation for {{Gaussian}} Mixture Random Vectors},
  booktitle = {2008 {{IEEE International Conference}} on {{Multisensor Fusion}} and {{Integration}} for {{Intelligent Systems}}},
  author = {Huber, Marco F. and Bailey, Tim and {Durrant-Whyte}, Hugh and Hanebeck, Uwe D.},
  year = {2008},
  month = aug,
  pages = {181--188},
  publisher = {{IEEE}},
  address = {{Seoul}},
  doi = {10.1109/MFI.2008.4648062},
  urldate = {2021-06-10},
  abstract = {For many practical probability density representations such as for the widely used Gaussian mixture densities, an analytic evaluation of the differential entropy is not possible and thus, approximate calculations are inevitable. For this purpose, the first contribution of this paper deals with a novel entropy approximation method for Gaussian mixture random vectors, which is based on a component-wise Taylor-series expansion of the logarithm of a Gaussian mixture and on a splitting method of Gaussian mixture components. The employed order of the Taylor-series expansion and the number of components used for splitting allows balancing between accuracy and computational demand. The second contribution is the determination of meaningful and efficiently to calculate lower and upper bounds of the entropy, which can be also used for approximation purposes. In addition, a refinement method for the more important upper bound is proposed in order to approach the true entropy value.},
  isbn = {978-1-4244-2143-5},
  langid = {english},
  annotation = {214 citations (Semantic Scholar/DOI) [2021-06-10]},
  file = {/Users/lichengk/Zotero/storage/L4VZPXDI/Huber et al. - 2008 - On entropy approximation for Gaussian mixture rand.pdf}
}

@inproceedings{hugginsScalableGaussianProcess2019,
  title = {Scalable {{Gaussian Process Inference}} with {{Finite-data Mean}} and {{Variance Guarantees}}},
  booktitle = {Proceedings of the {{Twenty-Second International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Huggins, Jonathan H. and Campbell, Trevor and Kasprzak, Mikolaj and Broderick, Tamara},
  year = {2019},
  month = apr,
  pages = {796--805},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-02-15},
  abstract = {Gaussian processes (GPs) offer a flexible class of priors for nonparametric Bayesian regression, but popular GP posterior inference methods are typically prohibitively slow or lack desirable finite-data guarantees on quality. We develop a scalable approach to approximate GP regression, with finite-data guarantees on the accuracy of our pointwise posterior mean and variance estimates. Our main contribution is a novel objective for approximate inference in the nonparametric setting: the preconditioned Fisher (pF) divergence. We show that unlike the Kullback\textendash Leibler divergence (used in variational inference), the pF divergence bounds bounds the 2-Wasserstein distance, which in turn provides tight bounds on the pointwise error of mean and variance estimates. We demonstrate that, for sparse GP likelihood approximations, we can minimize the pF divergence bounds efficiently. Our experiments show that optimizing the pF divergence bounds has the same computational requirements as variational sparse GPs while providing comparable empirical performance\textemdash in addition to our novel finite-data quality guarantees.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Huggins et al_2019_Scalable Gaussian Process Inference with Finite-data Mean and Variance.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Huggins et al_2019_Scalable Gaussian Process Inference with Finite-data Mean and Variance2.pdf}
}

@article{hummelSparseInferenceBayesian2020,
  title = {Sparse {{Inference}} for {{Bayesian Quadrature}}},
  author = {Hummel, Philipp},
  year = {2020}
}

@article{huszarOptimallyWeightedHerdingBayesian,
  title = {Optimally-{{Weighted Herding}} Is {{Bayesian Quadrature}}},
  author = {Huszar, Ferenc and Duvenaud, David},
  pages = {10},
  abstract = {Herding and kernel herding are deterministic methods of choosing samples which summarise a probability distribution. A related task is choosing samples for estimating integrals using Bayesian quadrature. We show that the criterion minimised when selecting samples in kernel herding is equivalent to the posterior variance in Bayesian quadrature. We then show that sequential Bayesian quadrature can be viewed as a weighted version of kernel herding which achieves performance superior to any other weighted herding method. We demonstrate empirically a rate of convergence faster than O(1/N ). Our results also imply an upper bound on the empirical error of the Bayesian quadrature estimate.},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/Zotero/storage/3XIBVHYE/Huszar and Duvenaud - Optimally-Weighted Herding is Bayesian Quadrature.pdf}
}

@misc{hvarfnerJointEntropySearch2022,
  title = {Joint {{Entropy Search}} for {{Maximally-Informed Bayesian Optimization}}},
  author = {Hvarfner, Carl and Hutter, Frank and Nardi, Luigi},
  year = {2022},
  month = oct,
  number = {arXiv:2206.04771},
  eprint = {2206.04771},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-11-01},
  abstract = {Information-theoretic Bayesian optimization techniques have become popular for optimizing expensive-to-evaluate black-box functions due to their non-myopic qualities. Entropy Search and Predictive Entropy Search both consider the entropy over the optimum in the input space, while the recent Max-value Entropy Search considers the entropy over the optimal value in the output space. We propose Joint Entropy Search (JES), a novel information-theoretic acquisition function that considers an entirely new quantity, namely the entropy over the joint optimal probability density over both input and output space. To incorporate this information, we consider the reduction in entropy from conditioning on fantasized optimal input/output pairs. The resulting approach primarily relies on standard GP machinery and removes complex approximations typically associated with information-theoretic methods. With minimal computational overhead, JES shows superior decision-making, and yields state-of-the-art performance for information-theoretic approaches across a wide suite of tasks. As a light-weight approach with superior results, JES provides a new go-to acquisition function for Bayesian optimization.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/TA2YDIVX/Hvarfner et al. - 2022 - Joint Entropy Search for Maximally-Informed Bayesi.pdf;/Users/lichengk/Zotero/storage/II8WNUIA/2206.html}
}

@article{hyvarinenEstimationNonNormalizedStatistical,
  title = {Estimation of {{Non-Normalized Statistical Models}} by {{Score Matching}}},
  author = {Hyvarinen, Aapo},
  pages = {15},
  abstract = {One often wants to estimate statistical models where the probability density function is known only up to a multiplicative normalization constant. Typically, one then has to resort to Markov Chain Monte Carlo methods, or approximations of the normalization constant. Here, we propose that such models can be estimated by minimizing the expected squared distance between the gradient of the log-density given by the model and the gradient of the log-density of the observed data. While the estimation of the gradient of log-density function is, in principle, a very difficult non-parametric problem, we prove a surprising result that gives a simple formula for this objective function. The density function of the observed data does not appear in this formula, which simplifies to a sample average of a sum of some derivatives of the log-density given by the model. The validity of the method is demonstrated on multivariate Gaussian and independent component analysis models, and by estimating an overcomplete filter set for natural image data.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Hyvarinen_Estimation of Non-Normalized Statistical Models by Score Matching.pdf}
}

@article{igeaCyclicalVariationalBayes2022,
  title = {Cyclical {{Variational Bayes Monte Carlo}} for {{Efficient Multi-Modal Posterior Distributions Evaluation}}},
  author = {Igea, Felipe and Cicirello, Alice},
  year = {2022},
  month = feb,
  journal = {arXiv:2202.11645 [cs, eess, math, stat]},
  eprint = {2202.11645},
  primaryclass = {cs, eess, math, stat},
  urldate = {2022-04-04},
  abstract = {Statistical model updating is frequently used in engineering to calculate the uncertainty of some unknown latent parameters when a set of measurements on observable quantities is given. Variational inference is an alternative approach to sampling methods that has been developed by the machine learning community to estimate posterior approximations through an optimization approach. In this paper, the Variational Bayesian Monte Carlo (VBMC) method is investigated with the purpose of dealing with statistical model updating problems in engineering involving expensive-to-run models. This method combines the active-sampling Bayesian quadrature with a Gaussian-process based variational inference to yield a non-parametric estimation of the posterior distribution of the identified parameters involving few runs of the expensive-to-run model. VBMC can also be used for model selection as it produces an estimation of the model's evidence lower bound. In this paper, a variant of the VBMC algorithm is developed through the introduction of a cyclical annealing schedule into the algorithm. The proposed cyclical VBMC algorithm allows to deal effectively with multi-modal posteriors by having multiple cycles of exploration and exploitation phases. Four numerical examples are used to compare the standard VBMC algorithm, the monotonic VBMC, the cyclical VBMC and the Transitional Ensemble Markov Chain Monte Carlo (TEMCMC). Overall, it is found that the proposed cyclical VBMC approach yields accurate results with a very reduced number of model runs compared to the state of the art sampling technique TEMCMC. In the presence of potential multi-modal problems, the proposed cyclical VBMC algorithm outperforms all the other approaches in terms of accuracy of the resulting posterior.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing,Mathematics - Optimization and Control,Statistics - Computation},
  file = {/Users/lichengk/Zotero/storage/DJMRCW2B/Igea and Cicirello - 2022 - Cyclical Variational Bayes Monte Carlo for Efficie.pdf;/Users/lichengk/Zotero/storage/IDSZ6Y97/2202.html}
}

@misc{immerScalableMarginalLikelihood2021,
  title = {Scalable {{Marginal Likelihood Estimation}} for {{Model Selection}} in {{Deep Learning}}},
  author = {Immer, Alexander and Bauer, Matthias and Fortuin, Vincent and R{\"a}tsch, Gunnar and Khan, Mohammad Emtiyaz},
  year = {2021},
  month = jun,
  number = {arXiv:2104.04975},
  eprint = {2104.04975},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-03-22},
  abstract = {Marginal-likelihood based model-selection, even though promising, is rarely used in deep learning due to estimation difficulties. Instead, most approaches rely on validation data, which may not be readily available. In this work, we present a scalable marginal-likelihood estimation method to select both hyperparameters and network architectures, based on the training data alone. Some hyperparameters can be estimated online during training, simplifying the procedure. Our marginal-likelihood estimate is based on Laplace's method and Gauss-Newton approximations to the Hessian, and it outperforms cross-validation and manual-tuning on standard regression and image classification datasets, especially in terms of calibration and out-of-distribution detection. Our work shows that marginal likelihoods can improve generalization and be useful when validation data is unavailable (e.g., in nonstationary settings).},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/US3N279E/Immer et al. - 2021 - Scalable Marginal Likelihood Estimation for Model .pdf;/Users/lichengk/Zotero/storage/YAQ7ES4L/2104.html}
}

@misc{ImplicitRegularizationPdfYou,
  title = {{{ImplicitRegularization}}.Pdf | 由 {{Box}} 提供支持},
  urldate = {2021-05-01},
  howpublished = {https://uofi.app.box.com/v/implicitregularization},
  file = {/Users/lichengk/Zotero/storage/MRK77IFD/implicitregularization.html}
}

@unpublished{ImportanceSampling,
  title = {Importance Sampling},
  urldate = {2021-09-22},
  file = {/Users/lichengk/Zotero/storage/C3T879CT/Ch-var-is.pdf}
}

@incollection{ImportanceSamplinga,
  title = {Importance Sampling},
  urldate = {2022-12-21},
  file = {/Users/lichengk/Zotero/storage/JFC9L3B7/book_chap6.pdf}
}

@misc{IntroductionFourierTransform,
  title = {Introduction to the {{Fourier Transform}}},
  urldate = {2022-11-21},
  howpublished = {https://lpsa.swarthmore.edu/Fourier/Xforms/FXformIntro.html},
  file = {/Users/lichengk/Zotero/storage/2MHGRPCH/FXformIntro.html}
}

@article{izmailovFasterVariationalInducing2017,
  title = {Faster Variational Inducing Input {{Gaussian}} Process Classification},
  author = {{Izmailov} and {Kropotov}},
  year = {2017},
  journal = {Machine Learning and Data Analysis},
  volume = {3},
  number = {1},
  pages = {20--35},
  issn = {22233792},
  doi = {10.21469/22233792.3.1.02},
  urldate = {2022-05-21},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/Zotero/storage/8973P2PX/Izmailov and Kropotov - 2017 - Faster variational inducing input Gaussian process.pdf}
}

@inproceedings{izmailovScalableGaussianProcesses2018,
  title = {Scalable {{Gaussian Processes}} with {{Billions}} of {{Inducing Inputs}} via {{Tensor Train Decomposition}}},
  booktitle = {Proceedings of the {{Twenty-First International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Izmailov, Pavel and Novikov, Alexander and Kropotov, Dmitry},
  year = {2018},
  month = mar,
  pages = {726--735},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-04-11},
  abstract = {We propose a method (TT-GP) for approximate inference in Gaussian Process (GP) models. We build on previous scalable GP research including stochastic variational inference based on inducing inputs, kernel interpolation, and structure exploiting algebra. The key idea of our method is to use Tensor Train decomposition for variational parameters, which allows us to train GPs with billions of inducing inputs and achieve state-of-the-art results on several benchmarks. Further, our approach allows for training kernels based on deep neural networks without any modifications to the underlying GP model. A neural network learns a multidimensional embedding for the data, which is used by the GP to make the final prediction. We train GP and neural network parameters end-to-end without pretraining, through maximization of GP marginal likelihood. We show the efficiency of the proposed approach on several regression and classification benchmark datasets including MNIST, CIFAR-10, and Airline.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/Zotero/storage/GT539GRK/Izmailov et al. - 2018 - Scalable Gaussian Processes with Billions of Induc.pdf}
}

@misc{jankowiakParametricGaussianProcess2020,
  title = {Parametric {{Gaussian Process Regressors}}},
  author = {Jankowiak, Martin and Pleiss, Geoff and Gardner, Jacob R.},
  year = {2020},
  month = dec,
  number = {arXiv:1910.07123},
  eprint = {1910.07123},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1910.07123},
  urldate = {2023-04-27},
  abstract = {The combination of inducing point methods with stochastic variational inference has enabled approximate Gaussian Process (GP) inference on large datasets. Unfortunately, the resulting predictive distributions often exhibit substantially underestimated uncertainties. Notably, in the regression case the predictive variance is typically dominated by observation noise, yielding uncertainty estimates that make little use of the input-dependent function uncertainty that makes GP priors attractive. In this work we propose two simple methods for scalable GP regression that address this issue and thus yield substantially improved predictive uncertainties. The first applies variational inference to FITC (Fully Independent Training Conditional; Snelson et.\textasciitilde al.\textasciitilde 2006). The second bypasses posterior approximations and instead directly targets the posterior predictive distribution. In an extensive empirical comparison with a number of alternative methods for scalable GP regression, we find that the resulting predictive distributions exhibit significantly better calibrated uncertainties and higher log likelihoods--often by as much as half a nat per datapoint.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/DYUS22UH/Jankowiak et al. - 2020 - Parametric Gaussian Process Regressors.pdf;/Users/lichengk/Zotero/storage/UAXYYHLC/1910.html}
}

@inproceedings{janzBanditOptimisationFunctions2020,
  title = {Bandit Optimisation of Functions in the {{Mat\'ern}} Kernel {{RKHS}}},
  booktitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Janz, David and Burt, David and Gonzalez, Javier},
  year = {2020},
  month = jun,
  pages = {2486--2495},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-08-16},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Janz et al_2020_Bandit optimisation of functions in the Matérn kernel RKHS.pdf;/Users/lichengk/Zotero/storage/P4KD8HDZ/Janz et al. - 2020 - Bandit optimisation of functions in the Matérn ker.pdf}
}

@article{jarvenpaaApproximateBayesianInference2021,
  title = {Approximate {{Bayesian}} Inference from Noisy Likelihoods with {{Gaussian}} Process Emulated {{MCMC}}},
  author = {J{\"a}rvenp{\"a}{\"a}, Marko and Corander, Jukka},
  year = {2021},
  journal = {arXiv preprint arXiv:2104.03942},
  eprint = {2104.03942},
  archiveprefix = {arxiv},
  keywords = {ObsCite,toread,相关性高},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Järvenpää_Corander_2021_Approximate Bayesian inference from noisy likelihoods with Gaussian process.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Järvenpää_Corander_2021_Approximate Bayesian inference from noisy likelihoods with Gaussian process2.pdf;/Users/lichengk/Zotero/storage/VZSBA8DX/2104.html;/Users/lichengk/Zotero/storage/W6CYFZ34/2104.html}
}

@article{jarvenpaaEfficientAcquisitionRules2019,
  title = {Efficient Acquisition Rules for Model-Based Approximate {{Bayesian}} Computation},
  author = {J{\"a}rvenp{\"a}{\"a}, Marko and Gutmann, Michael U. and Pleska, Arijus and Vehtari, Aki and Marttinen, Pekka},
  year = {2019},
  month = jun,
  journal = {Bayesian Analysis},
  volume = {14},
  number = {2},
  eprint = {1704.00520},
  primaryclass = {stat},
  issn = {1936-0975},
  doi = {10.1214/18-BA1121},
  urldate = {2022-07-04},
  abstract = {Approximate Bayesian computation (ABC) is a method for Bayesian inference when the likelihood is unavailable but simulating from the model is possible. However, many ABC algorithms require a large number of simulations, which can be costly. To reduce the computational cost, Bayesian optimisation (BO) and surrogate models such as Gaussian processes have been proposed. Bayesian optimisation enables one to intelligently decide where to evaluate the model next but common BO strategies are not designed for the goal of estimating the posterior distribution. Our paper addresses this gap in the literature. We propose to compute the uncertainty in the ABC posterior density, which is due to a lack of simulations to estimate this quantity accurately, and define a loss function that measures this uncertainty. We then propose to select the next evaluation location to minimise the expected loss. Experiments show that the proposed method often produces the most accurate approximations as compared to common BO strategies.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Järvenpää et al_2019_Efficient acquisition rules for model-based approximate Bayesian computation.pdf;/Users/lichengk/Zotero/storage/74DYSC7U/1704.html}
}

@book{jarvenpaaGaussianProcessSurrogate2020,
  title = {Gaussian {{Process Surrogate Methods}} for {{Sample-Efficient Approximate Bayesian Computation}}},
  author = {J{\"a}rvenp{\"a}{\"a}, Marko},
  year = {2020},
  publisher = {{Aalto University}},
  issn = {1799-4942 (electronic)},
  urldate = {2021-08-10},
  abstract = {In many application fields such as ecology, epidemiology and astronomy, simulation models are used to study complex phenomena that occur in nature. Often the analytical form of the likelihood function of these models is either unavailable or too costly to evaluate which complicates statistical inference. Likelihood-free inference (LFI) methods such as approximate Bayesian computation (ABC), based on replacing the evaluations of the intractable likelihood with forward simulations of the model, have become a popular approach to conduct inference for simulation models. Nevertheless, current LFI methods feature several computational and statistical challenges. Especially, standard ABC algorithms require a huge number of simulations which makes them infeasible when the forward simulations are expensive.   This thesis deals with likelihood-free inference for computationally costly models. The main contribution is a coherent framework for LFI based on Gaussian process (GP) surrogate models. GP models allow to encode smoothness assumptions of the simulation model output to reduce the amount of simulations needed. Additionally, the uncertainty in the resulting model-based posterior approximations due to the limited simulation budget can be quantified. We develop Bayesian experimental design strategies to select the evaluation locations as to minimise the computational cost. Both sequential designs, where simulations are chosen one-at-a-time basis, and batch strategies, which allow to take advantage of parallel computing, are derived. In addition to the LFI scenario, the proposed methods also apply when the likelihood can be evaluated but is expensive.   In essence, the proposed framework can be viewed as an LFI counterpart of probabilistic numerical methods such as Bayesian optimisation, developed for optimising expensive objective functions, and Bayesian quadrature, developed for computing integrals of expensive functions. We demonstrate the advantages of the proposed LFI methods using extensive empirical simulations. Some theoretical analysis of the proposed algorithms is also provided and their relation to some other GP surrogate methods are discussed.   In addition to the contributions to statistical methodology, applications in population genomics are also considered. In particular, we use the GP-based ABC methodology to obtain an approximate posterior of a simulation model describing horizontal gene transfer in bacteria. We also develop a probabilistic model and an inference algorithm using a novel combination of ABC and Metropolis-within-Gibbs sampling to facilitate better understanding of bacterial colonisation.},
  isbn = {978-952-60-3997-8},
  langid = {english},
  keywords = {相关性高},
  annotation = {Accepted: 2020-08-29T09:00:05Z},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Järvenpää_2020_Gaussian Process Surrogate Methods for Sample-Efficient Approximate Bayesian.pdf;/Users/lichengk/Zotero/storage/CD7V4SWY/46310.html}
}

@article{jarvenpaaParallelGaussianProcess2021,
  title = {Parallel {{Gaussian Process Surrogate Bayesian Inference}} with {{Noisy Likelihood Evaluations}}},
  author = {J{\"a}rvenp{\"a}{\"a}, Marko and Gutmann, Michael U. and Vehtari, Aki and Marttinen, Pekka},
  year = {2021},
  month = mar,
  journal = {Bayesian Analysis},
  volume = {16},
  number = {1},
  pages = {147--178},
  publisher = {{International Society for Bayesian Analysis}},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/20-BA1200},
  urldate = {2021-08-10},
  abstract = {We consider Bayesian inference when only a limited number of noisy log-likelihood evaluations can be obtained. This occurs for example when complex simulator-based statistical models are fitted to data, and synthetic likelihood (SL) method is used to form the noisy log-likelihood estimates using computationally costly forward simulations. We frame the inference task as a sequential Bayesian experimental design problem, where the log-likelihood function is modelled with a hierarchical Gaussian process (GP) surrogate model, which is used to efficiently select additional log-likelihood evaluation locations. Motivated by recent progress in the related problem of batch Bayesian optimisation, we develop various batch-sequential design strategies which allow to run some of the potentially costly simulations in parallel. We analyse the properties of the resulting method theoretically and empirically. Experiments with several toy problems and simulation models suggest that our method is robust, highly parallelisable, and sample-efficient.},
  keywords = {expensive likelihoods,Gaussian processes,likelihood-free inference,ObsCite,parallel computing,sequential experiment design,surrogate modelling,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Järvenpää et al_2021_Parallel Gaussian Process Surrogate Bayesian Inference with Noisy Likelihood.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Järvenpää et al_2021_Parallel Gaussian Process Surrogate Bayesian Inference with Noisy Likelihood2.pdf;/Users/lichengk/Zotero/storage/RNUP8YCV/20-BA1200.html}
}

@article{jewsonBayesianInferenceMopen,
  title = {Bayesian {{Inference}} in the {{M-open}} World},
  author = {Jewson, Jack Edward},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/WV4YE2S5/Jewson - Bayesian Inference in the M-open world.pdf}
}

@article{jiangEfficientNonmyopicBayesian2020,
  title = {Efficient {{Nonmyopic Bayesian Optimization}} via {{One-Shot Multi-Step Trees}}},
  author = {Jiang, Shali and Jiang, Daniel R. and Balandat, Maximilian and Karrer, Brian and Gardner, Jacob R. and Garnett, Roman},
  year = {2020},
  month = jun,
  journal = {arXiv:2006.15779 [cs, math, stat]},
  eprint = {2006.15779},
  primaryclass = {cs, math, stat},
  urldate = {2021-11-10},
  abstract = {Bayesian optimization is a sequential decision making framework for optimizing expensive-to-evaluate black-box functions. Computing a full lookahead policy amounts to solving a highly intractable stochastic dynamic program. Myopic approaches, such as expected improvement, are often adopted in practice, but they ignore the long-term impact of the immediate decision. Existing nonmyopic approaches are mostly heuristic and/or computationally expensive. In this paper, we provide the first efficient implementation of general multi-step lookahead Bayesian optimization, formulated as a sequence of nested optimization problems within a multi-step scenario tree. Instead of solving these problems in a nested way, we equivalently optimize all decision variables in the full tree jointly, in a ``one-shot'' fashion. Combining this with an efficient method for implementing multi-step Gaussian process ``fantasization,'' we demonstrate that multi-step expected improvement is computationally tractable and exhibits performance superior to existing methods on a wide range of benchmarks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/Zotero/storage/UCCZWFBT/Jiang et al. - 2020 - Efficient Nonmyopic Bayesian Optimization via One-.pdf;/Users/lichengk/Zotero/storage/5DHYWY6S/2006.html}
}

@phdthesis{jiangEfficientNonmyopicSequential2020,
  title = {Efficient {{Nonmyopic Sequential Experimental Design}}},
  author = {Jiang, Shali},
  year = {2020},
  school = {Washington University in St. Louis},
  file = {/Users/lichengk/Zotero/storage/EYQ4KCS5/1.html}
}

@misc{jiangFantasticGeneralizationMeasures2019,
  title = {Fantastic {{Generalization Measures}} and {{Where}} to {{Find Them}}},
  author = {Jiang, Yiding and Neyshabur, Behnam and Mobahi, Hossein and Krishnan, Dilip and Bengio, Samy},
  year = {2019},
  month = dec,
  number = {arXiv:1912.02178},
  eprint = {1912.02178},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-06-05},
  abstract = {Generalization of deep networks has been of great interest in recent years, resulting in a number of theoretically and empirically motivated complexity measures. However, most papers proposing such measures study only a small set of models, leaving open the question of whether the conclusion drawn from those experiments would remain valid in other settings. We present the first large scale study of generalization in deep networks. We investigate more then 40 complexity measures taken from both theoretical bounds and empirical studies. We train over 10,000 convolutional networks by systematically varying commonly used hyperparameters. Hoping to uncover potentially causal relationships between each measure and generalization, we analyze carefully controlled experiments and show surprising failures of some measures as well as promising measures for further research.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Jiang et al_2019_Fantastic Generalization Measures and Where to Find Them.pdf;/Users/lichengk/Zotero/storage/8XTKZQYI/1912.html}
}

@article{JMLR:v23:20-1426,
  title = {Stacking for Non-Mixing Bayesian Computations: {{The}} Curse and Blessing of Multimodal Posteriors},
  author = {Yao, Yuling and Vehtari, Aki and Gelman, Andrew},
  year = {2022},
  journal = {Journal of Machine Learning Research},
  volume = {23},
  number = {79},
  pages = {1--45},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Yao et al_2022_Stacking for non-mixing bayesian computations.pdf}
}

@article{jonesDIRECTAlgorithm252021,
  title = {The {{DIRECT}} Algorithm: 25 Years {{Later}}},
  shorttitle = {The {{DIRECT}} Algorithm},
  author = {Jones, Donald R. and Martins, Joaquim R. R. A.},
  year = {2021},
  month = mar,
  journal = {Journal of Global Optimization},
  volume = {79},
  number = {3},
  pages = {521--566},
  issn = {1573-2916},
  doi = {10.1007/s10898-020-00952-6},
  urldate = {2021-11-01},
  abstract = {Introduced in 1993, the DIRECT global optimization algorithm provided a fresh approach to minimizing a black-box function subject to lower and upper bounds on the variables. In contrast to the plethora of nature-inspired heuristics, DIRECT was deterministic and had only one hyperparameter (the desired accuracy). Moreover, the algorithm was simple, easy to implement, and usually performed well on low-dimensional problems (up to six variables). Most importantly, DIRECT balanced local and global search (exploitation vs. exploration) in a unique way: in each iteration, several points were sampled, some for global and some for local search. This approach eliminated the need for ``tuning parameters'' that set the balance between local and global search. However, the very same features that made DIRECT simple and conceptually attractive also created weaknesses. For example, it was commonly observed that, while DIRECT is often fast to find the basin of the global optimum, it can be slow to fine-tune the solution to high accuracy. In this paper, we identify several such weaknesses and survey the work of various researchers to extend DIRECT so that it performs better. All of the extensions show substantial improvement over DIRECT on various test functions. An outstanding challenge is to improve performance robustly across problems of different degrees of difficulty, ranging from simple (unimodal, few variables) to very hard (multimodal, sharply peaked, many variables). Opportunities for further improvement may lie in combining the best features of the different extensions.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/8BESQVPD/Jones and Martins - 2021 - The DIRECT algorithm 25 years Later.pdf}
}

@article{jonesEfficientGlobalOptimization1998,
  title = {Efficient {{Global Optimization}} of {{Expensive Black-Box Functions}}},
  author = {Jones, Donald R. and Schonlau, Matthias and Welch, William J.},
  year = {1998},
  month = dec,
  journal = {Journal of Global Optimization},
  volume = {13},
  number = {4},
  pages = {455--492},
  issn = {1573-2916},
  doi = {10.1023/A:1008306431147},
  urldate = {2021-10-20},
  abstract = {In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome.},
  langid = {english},
  keywords = {seminal},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Jones et al_1998_Efficient Global Optimization of Expensive Black-Box Functions.pdf}
}

@misc{jorgensenEzierGaussianProcesses2022,
  title = {B\textbackslash 'ezier {{Gaussian Processes}} for {{Tall}} and {{Wide Data}}},
  author = {J{\o}rgensen, Martin and Osborne, Michael A.},
  year = {2022},
  month = oct,
  number = {arXiv:2209.00343},
  eprint = {2209.00343},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-10-17},
  abstract = {Modern approximations to Gaussian processes are suitable for "tall data", with a cost that scales well in the number of observations, but under-performs on ``wide data'', scaling poorly in the number of input features. That is, as the number of input features grows, good predictive performance requires the number of summarising variables, and their associated cost, to grow rapidly. We introduce a kernel that allows the number of summarising variables to grow exponentially with the number of input features, but requires only linear cost in both number of observations and input features. This scaling is achieved through our introduction of the B\textbackslash 'ezier buttress, which allows approximate inference without computing matrix inverses or determinants. We show that our kernel has close similarities to some of the most used kernels in Gaussian process regression, and empirically demonstrate the kernel's ability to scale to both tall and wide datasets.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/Zotero/storage/RNTQT9LQ/Jørgensen and Osborne - 2022 - B'ezier Gaussian Processes for Tall and Wide Data.pdf;/Users/lichengk/Zotero/storage/DU637IEF/2209.html}
}

@article{jospinHandsonBayesianNeural2021,
  title = {Hands-on {{Bayesian Neural Networks}} -- a {{Tutorial}} for {{Deep Learning Users}}},
  author = {Jospin, Laurent Valentin and Buntine, Wray and Boussaid, Farid and Laga, Hamid and Bennamoun, Mohammed},
  year = {2021},
  month = sep,
  journal = {arXiv:2007.06823 [cs, stat]},
  eprint = {2007.06823},
  primaryclass = {cs, stat},
  urldate = {2021-11-11},
  abstract = {Modern deep learning methods constitute incredibly powerful tools to tackle a myriad of challenging problems. However, since deep learning methods operate as black boxes, the uncertainty associated with their predictions is often challenging to quantify. Bayesian statistics offer a formalism to understand and quantify the uncertainty associated with deep neural network predictions. This tutorial provides an overview of the relevant literature and a complete toolset to design, implement, train, use and evaluate Bayesian Neural Networks, i.e. Stochastic Artificial Neural Networks trained using Bayesian methods.},
  archiveprefix = {arxiv},
  keywords = {62-02 (Primary),Computer Science - Machine Learning,G.3,I.2.6,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Jospin et al_2021_Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users.pdf;/Users/lichengk/Zotero/storage/PD3NE44D/2007.html}
}

@article{jungSpectralMixtureKernel2019,
  title = {Spectral {{Mixture Kernel Approximation Using Reparameterized Random Fourier Feature}}},
  author = {Jung, Yohan and Park, Jinkyoo},
  year = {2019},
  pages = {12},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Jung_Park_2019_Spectral Mixture Kernel Approximation Using Reparameterized Random Fourier.pdf}
}

@inproceedings{kanagawaConvergenceGuaranteesAdaptive2019a,
  title = {Convergence {{Guarantees}} for {{Adaptive Bayesian Quadrature Methods}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Kanagawa, Motonobu and Hennig, Philipp},
  year = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-07-26},
  abstract = {Adaptive Bayesian quadrature (ABQ) is a powerful approach to numerical integration that empirically compares favorably with Monte Carlo integration on problems of medium dimensionality (where non-adaptive quadrature is not competitive). Its key ingredient is an acquisition function that changes as a function of  previously collected values of the integrand. While this adaptivity appears to be empirically powerful, it complicates analysis. Consequently, there are no theoretical guarantees so far for this class of methods. In this work, for a broad class of adaptive Bayesian quadrature methods, we prove consistency, deriving non-tight but informative convergence rates. To do so we introduce a new concept we call \textbackslash emph\{weak adaptivity\}. Our results identify a large and flexible class of adaptive Bayesian quadrature rules as consistent, within which practitioners can develop empirically efficient methods.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kanagawa_Hennig_2019_Convergence Guarantees for Adaptive Bayesian Quadrature Methods.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Kanagawa_Hennig_2019_Convergence Guarantees for Adaptive Bayesian Quadrature Methods2.pdf}
}

@article{kanagawaGaussianProcessesKernel2018,
  title = {Gaussian {{Processes}} and {{Kernel Methods}}: {{A Review}} on {{Connections}} and {{Equivalences}}},
  shorttitle = {Gaussian {{Processes}} and {{Kernel Methods}}},
  author = {Kanagawa, Motonobu and Hennig, Philipp and Sejdinovic, Dino and Sriperumbudur, Bharath K.},
  year = {2018},
  month = jul,
  journal = {arXiv:1807.02582 [cs, stat]},
  eprint = {1807.02582},
  primaryclass = {cs, stat},
  urldate = {2021-08-18},
  abstract = {This paper is an attempt to bridge the conceptual gaps between researchers working on the two widely used approaches based on positive definite kernels: Bayesian learning or inference using Gaussian processes on the one side, and frequentist kernel methods based on reproducing kernel Hilbert spaces on the other. It is widely known in machine learning that these two formalisms are closely related; for instance, the estimator of kernel ridge regression is identical to the posterior mean of Gaussian process regression. However, they have been studied and developed almost independently by two essentially separate communities, and this makes it difficult to seamlessly transfer results between them. Our aim is to overcome this potential difficulty. To this end, we review several old and new results and concepts from either side, and juxtapose algorithmic quantities from each framework to highlight close similarities. We also provide discussions on subtle philosophical and theoretical differences between the two approaches.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kanagawa et al_2018_Gaussian Processes and Kernel Methods.pdf;/Users/lichengk/Zotero/storage/LCPWIL4C/1807.html}
}

@article{kandasamyBayesianActiveLearning,
  title = {Bayesian {{Active Learning}} for {{Posterior Estimation}}},
  author = {Kandasamy, Kirthevasan and Schneider, Jeff and Poczos, Barnabas},
  pages = {7},
  abstract = {This paper studies active posterior estimation in a Bayesian setting when the likelihood is expensive to evaluate. Existing techniques for posterior estimation are based on generating samples representative of the posterior. Such methods do not consider efficiency in terms of likelihood evaluations. In order to be query efficient we treat posterior estimation in an active regression framework. We propose two myopic query strategies to choose where to evaluate the likelihood and implement them using Gaussian processes. Via experiments on a series of synthetic and real examples we demonstrate that our approach is significantly more query efficient than existing techniques and other heuristics for posterior estimation.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kandasamy et al_Bayesian Active Learning for Posterior Estimation.pdf}
}

@inproceedings{kandasamyHighDimensionalBayesian2015,
  title = {High {{Dimensional Bayesian Optimisation}} and {{Bandits}} via {{Additive Models}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}}},
  author = {Kandasamy, Kirthevasan and Schneider, Jeff and Poczos, Barnabas},
  year = {2015},
  month = jun,
  pages = {295--304},
  publisher = {{PMLR}},
  issn = {1938-7228},
  urldate = {2021-10-20},
  abstract = {Bayesian Optimisation (BO) is a technique used in optimising a D-dimensional function which is typically expensive to evaluate. While there have been many successes for BO in low dimensions, scaling it to high dimensions has been notoriously difficult. Existing literature on the topic are under very restrictive settings. In this paper, we identify two key challenges in this endeavour. We tackle these challenges by assuming an additive structure for the function. This setting is substantially more expressive and contains a richer class of functions than previous work. We prove that, for additive functions the regret has only linear dependence on D even though the function depends on all D dimensions. We also demonstrate several other statistical and computational benefits in our framework. Via synthetic examples, a scientific simulation and a face detection problem we demonstrate that our method outperforms naive BO on additive functions and on several examples where the function is not additive.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kandasamy et al_2015_High Dimensional Bayesian Optimisation and Bandits via Additive Models.pdf}
}

@article{kaplanQuantificationModelUncertainty2021,
  title = {On the {{Quantification}} of {{Model Uncertainty}}: {{A Bayesian Perspective}}},
  shorttitle = {On the {{Quantification}} of {{Model Uncertainty}}},
  author = {Kaplan, David},
  year = {2021},
  month = mar,
  journal = {Psychometrika},
  volume = {86},
  number = {1},
  pages = {215--238},
  issn = {1860-0980},
  doi = {10.1007/s11336-021-09754-5},
  urldate = {2023-02-14},
  abstract = {Issues of model selection have dominated the theoretical and applied statistical literature for decades. Model selection methods such as ridge regression, the lasso, and the elastic net have replaced ad hoc methods such as stepwise regression as a means of model selection. In the end, however, these methods lead to a single final model that is often taken to be the model considered ahead of time, thus ignoring the uncertainty inherent in the search for a final model. One method that has enjoyed a long history of theoretical developments and substantive applications, and that accounts directly for uncertainty in model selection, is Bayesian model averaging (BMA). BMA addresses the problem of model selection by not selecting a final model, but rather by averaging over a space of possible models that could have generated the data. The purpose of this paper is to provide a detailed and up-to-date review of BMA with a focus on its foundations in Bayesian decision theory and Bayesian predictive modeling. We consider the selection of parameter and model priors as well as methods for evaluating predictions based on BMA. We also consider important assumptions regarding BMA and extensions of model averaging methods to address these assumptions, particularly the method of Bayesian stacking. Simple empirical examples are provided and directions for future research relevant to psychometrics are discussed.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kaplan_2021_On the Quantification of Model Uncertainty.pdf}
}

@article{kapoorUncertaintyTemperingData2022,
  title = {On {{Uncertainty}}, {{Tempering}}, and {{Data Augmentation}} in {{Bayesian Classification}}},
  author = {Kapoor, Sanyam and Maddox, Wesley J. and Izmailov, Pavel and Wilson, Andrew Gordon},
  year = {2022},
  month = mar,
  journal = {arXiv:2203.16481 [cs, stat]},
  eprint = {2203.16481},
  primaryclass = {cs, stat},
  urldate = {2022-04-06},
  abstract = {Aleatoric uncertainty captures the inherent randomness of the data, such as measurement noise. In Bayesian regression, we often use a Gaussian observation model, where we control the level of aleatoric uncertainty with a noise variance parameter. By contrast, for Bayesian classification we use a categorical distribution with no mechanism to represent our beliefs about aleatoric uncertainty. Our work shows that explicitly accounting for aleatoric uncertainty significantly improves the performance of Bayesian neural networks. We note that many standard benchmarks, such as CIFAR, have essentially no aleatoric uncertainty. Moreover, we show data augmentation in approximate inference has the effect of softening the likelihood, leading to underconfidence and profoundly misrepresenting our honest beliefs about aleatoric uncertainty. Accordingly, we find that a cold posterior, tempered by a power greater than one, often more honestly reflects our beliefs about aleatoric uncertainty than no tempering -- providing an explicit link between data augmentation and cold posteriors. We show that we can match or exceed the performance of posterior tempering by using a Dirichlet observation model, where we explicitly control the level of aleatoric uncertainty, without any need for tempering.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kapoor et al_2022_On Uncertainty, Tempering, and Data Augmentation in Bayesian Classification.pdf;/Users/lichengk/Zotero/storage/WMIX559W/2203.html}
}

@article{karamanisAcceleratingAstronomicalCosmological2022,
  title = {Accelerating Astronomical and Cosmological Inference with {{Preconditioned Monte Carlo}}},
  author = {Karamanis, Minas and Beutler, Florian and Peacock, John A. and Nabergoj, David and Seljak, Uros},
  year = {2022},
  month = sep,
  journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {516},
  number = {2},
  eprint = {2207.05652},
  primaryclass = {astro-ph, physics:physics},
  pages = {1644--1653},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/stac2272},
  urldate = {2022-12-13},
  abstract = {We introduce Preconditioned Monte Carlo (PMC), a novel Monte Carlo method for Bayesian inference that facilitates efficient sampling of probability distributions with non-trivial geometry. PMC utilises a Normalising Flow (NF) in order to decorrelate the parameters of the distribution and then proceeds by sampling from the preconditioned target distribution using an adaptive Sequential Monte Carlo (SMC) scheme. The results produced by PMC include samples from the posterior distribution and an estimate of the model evidence that can be used for parameter inference and model comparison respectively. The aforementioned framework has been thoroughly tested in a variety of challenging target distributions achieving state-of-the-art sampling performance. In the cases of primordial feature analysis and gravitational wave inference, PMC is approximately 50 and 25 times faster respectively than Nested Sampling (NS). We found that in higher dimensional applications the acceleration is even greater. Finally, PMC is directly parallelisable, manifesting linear scaling up to thousands of CPUs.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics,Physics - Computational Physics},
  file = {/Users/lichengk/Zotero/storage/6Z57Y9EW/Karamanis et al. - 2022 - Accelerating astronomical and cosmological inferen.pdf;/Users/lichengk/Zotero/storage/7FPZW3LZ/2207.html}
}

@article{karamanisZeusPythonImplementation2021,
  title = {Zeus: {{A Python}} Implementation of {{Ensemble Slice Sampling}} for Efficient {{Bayesian}} Parameter Inference},
  shorttitle = {Zeus},
  author = {Karamanis, Minas and Beutler, Florian and Peacock, John A.},
  year = {2021},
  month = oct,
  journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {508},
  number = {3},
  eprint = {2105.03468},
  pages = {3589--3603},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/stab2867},
  urldate = {2022-01-27},
  abstract = {We introduce zeus, a well-tested Python implementation of the Ensemble Slice Sampling (ESS) method for Bayesian parameter inference. ESS is a novel Markov chain Monte Carlo (MCMC) algorithm specifically designed to tackle the computational challenges posed by modern astronomical and cosmological analyses. In particular, the method requires only minimal hand--tuning of 1-2 hyper-parameters that are often trivial to set; its performance is insensitive to linear correlations and it can scale up to 1000s of CPUs without any extra effort. Furthermore, its locally adaptive nature allows to sample efficiently even when strong non-linear correlations are present. Lastly, the method achieves a high performance even in strongly multimodal distributions in high dimensions. Compared to emcee, a popular MCMC sampler, zeus performs 9 and 29 times better in a cosmological and an exoplanet application respectively.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Earth and Planetary Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics,ObsCite,Physics - Computational Physics},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Karamanis et al_2021_zeus.pdf;/Users/lichengk/Zotero/storage/7WLSSR5Y/2105.html}
}

@inproceedings{karvonenClassicalQuadratureRules2017,
  title = {Classical Quadrature Rules via {{Gaussian}} Processes},
  booktitle = {2017 {{IEEE}} 27th {{International Workshop}} on {{Machine Learning}} for {{Signal Processing}} ({{MLSP}})},
  author = {Karvonen, Toni and Sarkka, Simo},
  year = {2017},
  month = sep,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Tokyo}},
  doi = {10.1109/MLSP.2017.8168195},
  urldate = {2021-05-24},
  abstract = {In an extension to some previous work on the topic, we show how all classical polynomial-based quadrature rules can be interpreted as Bayesian quadrature rules if the covariance kernel is selected suitably. As the resulting Bayesian quadrature rules have zero posterior integral variance, the results of this article are mostly of theoretical interest in clarifying the relationship between the two different approaches to numerical integration.},
  isbn = {978-1-5090-6341-3},
  langid = {english},
  keywords = {bayesian quadrature},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Karvonen_Sarkka_2017_Classical quadrature rules via Gaussian processes.pdf}
}

@misc{karvonenMaximumLikelihoodEstimation2022,
  title = {Maximum {{Likelihood Estimation}} in {{Gaussian Process Regression}} Is {{Ill-Posed}}},
  author = {Karvonen, Toni and Oates, Chris J.},
  year = {2022},
  month = oct,
  number = {arXiv:2203.09179},
  eprint = {2203.09179},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  urldate = {2023-03-06},
  abstract = {Gaussian process regression underpins countless academic and industrial applications of machine learning and statistics, with maximum likelihood estimation routinely used to select appropriate parameters for the covariance kernel. However, it remains an open problem to establish the circumstances in which maximum likelihood estimation is well-posed, that is, when the predictions of the regression model are insensitive to small perturbations of the data. This article identifies scenarios where the maximum likelihood estimator fails to be well-posed. These failure cases occur in the noiseless data setting, for any Gaussian process with a stationary covariance function whose lengthscale parameter is estimated using maximum likelihood. Although the failure of maximum likelihood estimation is part of Gaussian process folklore, these rigorous theoretical results appear to be the first of their kind. The implication of these negative results is that well-posedness may need to be assessed post-hoc, on a case-by-case basis, when maximum likelihood estimation is used to train a Gaussian process model.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/7DIRTTFB/Karvonen and Oates - 2022 - Maximum Likelihood Estimation in Gaussian Process .pdf;/Users/lichengk/Zotero/storage/D55ZZR4I/2203.html}
}

@inproceedings{kawaguchiBayesianOptimizationExponential2015,
  title = {Bayesian {{Optimization}} with {{Exponential Convergence}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Kawaguchi, Kenji and Kaelbling, Leslie Pack and {Lozano-P{\'e}rez}, Tom{\'a}s},
  year = {2015},
  volume = {28},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-05-19},
  abstract = {This paper presents a Bayesian optimization method with exponential convergence without the need of auxiliary optimization and without the delta-cover sampling. Most Bayesian optimization methods require auxiliary optimization: an additional non-convex global optimization problem, which can be time-consuming and hard to implement in practice. Also, the existing Bayesian optimization method with exponential convergence requires access to the delta-cover sampling, which was considered to be impractical. Our approach eliminates both requirements and achieves an exponential convergence rate.},
  file = {/Users/lichengk/Zotero/storage/GIH5HE5P/Kawaguchi et al. - 2016 - Bayesian Optimization with Exponential Convergence.pdf}
}

@misc{kengImportanceSamplingEstimating2019,
  title = {Importance {{Sampling}} and {{Estimating Marginal Likelihood}} in {{Variational}}},
  author = {Keng, Brian},
  year = {2019},
  month = feb,
  journal = {Bounded Rationality},
  urldate = {2022-03-03},
  abstract = {A short post describing how to use importance sampling to estimate marginal likelihood in variational autoencoders.},
  howpublished = {http://bjlkeng.github.io/posts/importance-sampling-and-estimating-marginal-likelihood-in-variational-autoencoders/},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/IXG2PNWW/importance-sampling-and-estimating-marginal-likelihood-in-variational-autoencoders.html}
}

@article{kennedyBayesianCalibrationComputer2001,
  title = {Bayesian Calibration of Computer Models},
  author = {Kennedy, Marc C. and O'Hagan, Anthony},
  year = {2001},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {63},
  number = {3},
  pages = {425--464},
  issn = {1467-9868},
  doi = {10.1111/1467-9868.00294},
  urldate = {2021-08-05},
  abstract = {We consider prediction and uncertainty analysis for systems which are approximated using complex mathematical models. Such models, implemented as computer codes, are often generic in the sense that by a suitable choice of some of the model's input parameters the code can be used to predict the behaviour of the system in a variety of specific applications. However, in any specific application the values of necessary parameters may be unknown. In this case, physical observations of the system in the specific context are used to learn about the unknown parameters. The process of fitting the model to the observed data by adjusting the parameters is known as calibration. Calibration is typically effected by ad hoc fitting, and after calibration the model is used, with the fitted input values, to predict the future behaviour of the system. We present a Bayesian calibration technique which improves on this traditional approach in two respects. First, the predictions allow for all sources of uncertainty, including the remaining uncertainty over the fitted parameters. Second, they attempt to correct for any inadequacy of the model which is revealed by a discrepancy between the observed data and the model predictions from even the best-fitting parameter values. The method is illustrated by using data from a nuclear radiation release at Tomsk, and from a more complex simulated nuclear accident exercise.},
  langid = {english},
  keywords = {Calibration,Computer experiments,Deterministic models,Gaussian process,Interpolation,Model inadequacy,Sensitivity analysis,Uncertainty analysis},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kennedy_O'Hagan_2001_Bayesian calibration of computer models.pdf;/Users/lichengk/Zotero/storage/C43ZQSBA/1467-9868.html}
}

@article{kennedyBayesianQuadratureNonnormal1998,
  title = {Bayesian Quadrature with Non-Normal Approximating Functions},
  author = {KENNEDY, {\relax MARC}},
  year = {1998},
  month = dec,
  journal = {Statistics and Computing},
  volume = {8},
  number = {4},
  pages = {365--375},
  issn = {1573-1375},
  doi = {10.1023/A:1008832824006},
  urldate = {2022-05-18},
  abstract = {We consider an efficient Bayesian approach to estimating integration-based posterior summaries from a separate Bayesian application. In Bayesian quadrature we model an intractable posterior density function f({$\cdot$}) as a Gaussian process, using an approximating function g({$\cdot$}), and find a posterior distribution for the integral of f({$\cdot$}), conditional on a few evaluations of f ({$\cdot$}) at selected design points. Bayesian quadrature using normal g ({$\cdot$}) is called Bayes-Hermite quadrature. We extend this theory by allowing g({$\cdot$}) to be chosen from two wider classes of functions. One is a family of skew densities and the other is the family of finite mixtures of normal densities. For the family of skew densities we describe an iterative updating procedure to select the most suitable approximation and apply the method to two simulated posterior density functions.},
  langid = {english},
  keywords = {approximating posterior densities,Bayesian quadrature,finite mixture of normals,Gaussian process,numerical integration},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/KENNEDY_1998_Bayesian quadrature with non-normal approximating functions.pdf}
}

@misc{KernelCookbook,
  title = {Kernel {{Cookbook}}},
  urldate = {2021-07-04},
  howpublished = {https://www.cs.toronto.edu/\textasciitilde duvenaud/cookbook/},
  file = {/Users/lichengk/Zotero/storage/38KHZK89/cookbook.html}
}

@article{khanBayesianLearningRule2021,
  title = {The {{Bayesian Learning Rule}}},
  author = {Khan, Mohammad Emtiyaz and Rue, H{\aa}vard},
  year = {2021},
  month = jul,
  journal = {arXiv:2107.04562 [cs, stat]},
  eprint = {2107.04562},
  primaryclass = {cs, stat},
  urldate = {2022-02-20},
  abstract = {We show that many machine-learning algorithms are specific instances of a single algorithm called the Bayesian learning rule. The rule, derived from Bayesian principles, yields a wide-range of algorithms from fields such as optimization, deep learning, and graphical models. This includes classical algorithms such as ridge regression, Newton's method, and Kalman filter, as well as modern deep-learning algorithms such as stochastic-gradient descent, RMSprop, and Dropout. The key idea in deriving such algorithms is to approximate the posterior using candidate distributions estimated by using natural gradients. Different candidate distributions result in different algorithms and further approximations to natural gradients give rise to variants of those algorithms. Our work not only unifies, generalizes, and improves existing algorithms, but also helps us design new ones.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Khan_Rue_2021_The Bayesian Learning Rule.pdf;/Users/lichengk/Zotero/storage/B6FBLTTU/2107.html}
}

@inproceedings{khanConjugateComputationVariationalInference2017,
  title = {Conjugate-{{Computation Variational Inference}} : {{Converting Variational Inference}} in {{Non-Conjugate Models}} to {{Inferences}} in {{Conjugate Models}}},
  shorttitle = {Conjugate-{{Computation Variational Inference}}},
  booktitle = {Proceedings of the 20th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Khan, Mohammad and Lin, Wu},
  year = {2017},
  month = apr,
  pages = {878--887},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-02-14},
  abstract = {Variational inference is computationally challenging in models that contain both conjugate and non-conjugate terms. Methods specifically designed for conjugate models, even though computationally efficient, find it difficult to deal with non-conjugate terms. On the other hand, stochastic-gradient methods can handle the non-conjugate terms but they usually ignore the conjugate structure of the model which might result in slow convergence. In this paper, we propose a new algorithm called Conjugate-computation Variational Inference (CVI) which brings the best of the two worlds together \textendash{} it uses conjugate computations for the conjugate terms and employs stochastic gradients for the rest. We derive this algorithm by using a stochastic mirror-descent method in the mean-parameter space, and then expressing each gradient step as a variational inference in a conjugate model. We demonstrate our algorithm's applicability to a large class of models and establish its convergence. Our experimental results show that our method converges much faster than the methods that ignore the conjugate structure of the model.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Khan_Lin_2017_Conjugate-Computation Variational Inference.pdf;/Users/lichengk/Zotero/storage/Y2IY5QRF/Khan and Lin - 2017 - Conjugate-Computation Variational Inference  Conv.pdf}
}

@article{khanLearningAlgorithmsBayesianPrinciples,
  title = {Learning-{{Algorithms}} from {{Bayesian Principles}}},
  author = {Khan, Mohammad Emtiyaz},
  pages = {23},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/3RT54HTG/Khan - Learning-Algorithms from Bayesian Principles.pdf}
}

@article{khorunzhinaFiniteGaussianMixture2019,
  title = {Finite {{Gaussian Mixture Approximations}} to {{Analytically Intractable Density Kernels}}},
  author = {Khorunzhina, Natalia and Richard, Jean-Fran{\c c}ois},
  year = {2019},
  month = mar,
  journal = {Computational Economics},
  volume = {53},
  number = {3},
  pages = {991--1017},
  issn = {1572-9974},
  doi = {10.1007/s10614-017-9777-2},
  urldate = {2021-08-19},
  abstract = {The objective of the paper is that of constructing finite Gaussian mixture approximations to analytically intractable density kernels. The proposed method is adaptive in that terms are added one at the time and the mixture is fully re-optimized at each step using a distance measure that approximates the corresponding importance sampling variance. All functions of interest are evaluated under Gaussian product rules. Since product rules suffer from an obvious curse of dimensionality, the proposed algorithm as presented is only applicable to models whose non-linear and/or non-Gaussian subspace is of dimension up to three. Extensions to higher-dimensional applications would require the use of sparse grids, as discussed in the paper. Examples include a sequential (filtering) evaluation of the likelihood function of a stochastic volatility model where all relevant densities (filtering, predictive and likelihood) are closely approximated by mixtures.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Khorunzhina_Richard_2019_Finite Gaussian Mixture Approximations to Analytically Intractable Density.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Khorunzhina_Richard_2019_Finite Gaussian Mixture Approximations to Analytically Intractable Density2.pdf}
}

@misc{kindapNonGaussianProcessRegression2022,
  title = {Non-{{Gaussian Process Regression}}},
  author = {K{\i}ndap, Yaman and Godsill, Simon},
  year = {2022},
  month = sep,
  number = {arXiv:2209.03117},
  eprint = {2209.03117},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-24},
  abstract = {Standard GPs offer a flexible modelling tool for well-behaved processes. However, deviations from Gaussianity are expected to appear in real world datasets, with structural outliers and shocks routinely observed. In these cases GPs can fail to model uncertainty adequately and may over-smooth inferences. Here we extend the GP framework into a new class of time-changed GPs that allow for straightforward modelling of heavy-tailed non-Gaussian behaviours, while retaining a tractable conditional GP structure through an infinite mixture of non-homogeneous GPs representation. The conditional GP structure is obtained by conditioning the observations on a latent transformed input space and the random evolution of the latent transformation is modelled using a L\textbackslash '\{e\}vy process which allows Bayesian inference in both the posterior predictive density and the latent transformation function. We present Markov chain Monte Carlo inference procedures for this model and demonstrate the potential benefits compared to a standard GP.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/IHBWUMEJ/Kındap and Godsill - 2022 - Non-Gaussian Process Regression.pdf;/Users/lichengk/Zotero/storage/KLD9LFCI/2209.html}
}

@article{kingmaIntroductionVariationalAutoencoders2019,
  title = {An {{Introduction}} to {{Variational Autoencoders}}},
  author = {Kingma, Diederik P. and Welling, Max},
  year = {2019},
  journal = {Foundations and Trends\textregistered{} in Machine Learning},
  volume = {12},
  number = {4},
  eprint = {1906.02691},
  pages = {307--392},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000056},
  urldate = {2022-03-02},
  abstract = {Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/AZP2ZGLA/Kingma and Welling - 2019 - An Introduction to Variational Autoencoders.pdf;/Users/lichengk/Zotero/storage/Z99I73I4/1906.html}
}

@article{kleijnBernsteinVonMisesTheoremMisspecification2012,
  title = {The {{Bernstein-Von-Mises}} Theorem under Misspecification},
  author = {Kleijn, B.J.K. and {van der Vaart}, A.W.},
  year = {2012},
  month = jan,
  journal = {Electronic Journal of Statistics},
  volume = {6},
  number = {none},
  issn = {1935-7524},
  doi = {10.1214/12-EJS675},
  urldate = {2022-12-12},
  abstract = {We prove that the posterior distribution of a parameter in misspecified LAN parametric models can be approximated by a random normal distribution. We derive from this that Bayesian credible sets are not valid confidence sets if the model is misspecified. We obtain the result under conditions that are comparable to those in the well-specified situation: uniform testability against fixed alternatives and sufficient prior mass in neighbourhoods of the point of convergence. The rate of convergence is considered in detail, with special attention for the existence and construction of suitable test sequences. We also give a lemma to exclude testable model subsets which implies a misspecified version of Schwartz' consistency theorem, establishing weak convergence of the posterior to a measure degenerate at the point at minimal Kullback-Leibler divergence with respect to the true distribution.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kleijn_van der Vaart_2012_The Bernstein-Von-Mises theorem under misspecification.pdf}
}

@book{klenkeProbabilityTheoryComprehensive2014,
  title = {Probability {{Theory}}: {{A Comprehensive Course}}},
  shorttitle = {Probability {{Theory}}},
  author = {Klenke, Achim},
  year = {2014},
  series = {Universitext},
  publisher = {{Springer London}},
  address = {{London}},
  doi = {10.1007/978-1-4471-5361-0},
  urldate = {2023-05-26},
  isbn = {978-1-4471-5360-3 978-1-4471-5361-0},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Klenke_2014_Probability Theory.pdf}
}

@article{knoblauchOptimizationcentricViewBayes2022,
  title = {An {{Optimization-centric View}} on {{Bayes}}' {{Rule}}: {{Reviewing}} and {{Generalizing Variational Inference}}},
  shorttitle = {An {{Optimization-centric View}} on {{Bayes}}' {{Rule}}},
  author = {Knoblauch, Jeremias and Jewson, Jack and Damoulas, Theodoros},
  year = {2022},
  journal = {Journal of Machine Learning Research},
  volume = {23},
  number = {132},
  pages = {1--109},
  issn = {1533-7928},
  urldate = {2023-04-27},
  abstract = {We advocate an optimization-centric view of Bayesian inference. Our inspiration is the representation of Bayes' rule as infinite-dimensional optimization (Csiszar, 1975; Donsker and Varadhan, 1975; Zellner, 1988). Equipped with this perspective, we study Bayesian inference when one does not have access to (1) well-specified priors, (2) well-specified likelihoods, (3) infinite computing power. While these three assumptions underlie the standard Bayesian paradigm, they are typically inappropriate for modern Machine Learning applications. We propose addressing this through an optimization-centric generalization of Bayesian posteriors that we call the Rule of Three (RoT). The RoT can be justified axiomatically and recovers Bayesian, PAC-Bayesian and VI posteriors as special cases. While the RoT is primarily a conceptual and theoretical device, it also encompasses a novel sub-class of tractable posteriors which we call Generalized Variational Inference (GVI) posteriors. Just as the RoT, GVI posteriors are specified by three arguments: a loss, a divergence and a variational family. They also possess a number of desirable properties, including modularity, Frequentist consistency and an interpretation as approximate ELBO. We explore applications of GVI posteriors, and show that they can be used to improve robustness and posterior marginals on Bayesian Neural Networks and Deep Gaussian Processes.},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Knoblauch et al_2022_An Optimization-centric View on Bayes' Rule.pdf;/Users/lichengk/Zotero/storage/YJCVZ2TX/GVIPublic.html}
}

@article{kobyzevNormalizingFlowsIntroduction2021a,
  title = {Normalizing {{Flows}}: {{An Introduction}} and {{Review}} of {{Current Methods}}},
  shorttitle = {Normalizing {{Flows}}},
  author = {Kobyzev, Ivan and Prince, Simon J. D. and Brubaker, Marcus A.},
  year = {2021},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {43},
  number = {11},
  eprint = {1908.09257},
  primaryclass = {cs, stat},
  pages = {3964--3979},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2020.2992934},
  urldate = {2022-11-22},
  abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kobyzev et al_2021_Normalizing Flows.pdf;/Users/lichengk/Zotero/storage/4D54XVE9/1908.html}
}

@book{kochenderferAlgorithmsOptimization2019,
  title = {Algorithms for Optimization},
  author = {Kochenderfer, Mykel J. and Wheeler, Tim A.},
  year = {2019},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  isbn = {978-0-262-03942-0},
  lccn = {QA9.58 .K65425 2019},
  keywords = {Algorithms,ObsCite,{Problems, exercises, etc}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kochenderfer_Wheeler_2019_Algorithms for optimization.pdf}
}

@article{kolchinskyEstimatingMixtureEntropy2017,
  title = {Estimating {{Mixture Entropy}} with {{Pairwise Distances}}},
  author = {Kolchinsky, Artemy and Tracey, Brendan D.},
  year = {2017},
  month = jul,
  journal = {Entropy},
  volume = {19},
  number = {7},
  pages = {361},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/e19070361},
  urldate = {2021-06-17},
  abstract = {Mixture distributions arise in many parametric and non-parametric settings\textemdash for example, in Gaussian mixture models and in non-parametric estimation. It is often necessary to compute the entropy of a mixture, but, in most cases, this quantity has no closed-form expression, making some form of approximation necessary. We propose a family of estimators based on a pairwise distance function between mixture components, and show that this estimator class has many attractive properties. For many distributions of interest, the proposed estimators are efficient to compute, differentiable in the mixture parameters, and become exact when the mixture components are clustered. We prove this family includes lower and upper bounds on the mixture entropy. The Chernoff    {$\alpha$}   -divergence gives a lower bound when chosen as the distance function, with the Bhattacharyaa distance providing the tightest lower bound for components that are symmetric and members of a location family. The Kullback\textendash Leibler divergence gives an upper bound when used as the distance function. We provide closed-form expressions of these bounds for mixtures of Gaussians, and discuss their applications to the estimation of mutual information. We then demonstrate that our bounds are significantly tighter than well-known existing bounds using numeric simulations. This estimator class is very useful in optimization problems involving maximization/minimization of entropy and mutual information, such as MaxEnt and rate distortion problems.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {entropy estimation,MaxEnt,mixture distribution,mixture of Gaussians,rate distortion,toread,相关性高},
  annotation = {68 citations (Semantic Scholar/DOI) [2021-06-17]},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kolchinsky_Tracey_2017_Estimating Mixture Entropy with Pairwise Distances.pdf;/Users/lichengk/Zotero/storage/TQJHW8GV/361.html}
}

@book{kolmogorovFoundationsTheoryProbability1933,
  title = {Foundations of the {{Theory}} of {{Probability}}},
  year = {1933},
  collaborator = {Kolmogorov, Andrey},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/1933_Foundations of the Theory of Probability.pdf}
}

@inproceedings{kongExpressivePowerClass2020,
  title = {The {{Expressive Power}} of a {{Class}} of {{Normalizing Flow Models}}},
  booktitle = {Proceedings of the {{Twenty Third International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Kong, Zhifeng and Chaudhuri, Kamalika},
  year = {2020},
  month = jun,
  pages = {3599--3609},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-03-03},
  abstract = {Normalizing flows have received a great deal of recent attention as they allow flexible generative modeling as well as easy likelihood computation. While a wide variety of flow models have been proposed, there is little formal understanding of the representation power of these models. In this work, we study some basic normalizing flows and rigorously establish bounds on their expressive power. Our results indicate that while these flows are highly expressive in one dimension, in higher dimensions their representation power may be limited, especially when the flows have moderate depth.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kong_Chaudhuri_2020_The Expressive Power of a Class of Normalizing Flow Models.pdf;/Users/lichengk/Zotero/storage/3REW8T8P/Kong and Chaudhuri - 2020 - The Expressive Power of a Class of Normalizing Flo.pdf;/Users/lichengk/Zotero/storage/KTTEEN65/Kong and Chaudhuri - 2020 - The Expressive Power of a Class of Normalizing Flo.pdf}
}

@article{krauseNearOptimalSensorPlacements,
  title = {Near-{{Optimal Sensor Placements}} in {{Gaussian Processes}}: {{Theory}}, {{Efficient Algorithms}} and {{Empirical Studies}}},
  author = {Krause, Andreas and Singh, Ajit and Guestrin, Carlos},
  pages = {50},
  abstract = {When monitoring spatial phenomena, which can often be modeled as Gaussian processes (GPs), choosing sensor locations is a fundamental task. There are several common strategies to address this task, for example, geometry or disk models, placing sensors at the points of highest entropy (variance) in the GP model, and A-, D-, or E-optimal design. In this paper, we tackle the combinatorial optimization problem of maximizing the mutual information between the chosen locations and the locations which are not selected. We prove that the problem of finding the configuration that maximizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1 - 1/e) of the optimum by exploiting the submodularity of mutual information. We also show how submodularity can be used to obtain online bounds, and design branch and bound search procedures. We then extend our algorithm to exploit lazy evaluations and local structure in the GP, yielding significant speedups. We also extend our approach to find placements which are robust against node failures and uncertainties in the model. These extensions are again associated with rigorous theoretical approximation guarantees, exploiting the submodularity of the objective function. We demonstrate the advantages of our approach towards optimizing mutual information in a very extensive empirical study on two real-world data sets.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/TQ4NWXR6/Krause et al. - Near-Optimal Sensor Placements in Gaussian Process.pdf}
}

@misc{krauthAutoGPExploringCapabilities2017,
  title = {{{AutoGP}}: {{Exploring}} the {{Capabilities}} and {{Limitations}} of {{Gaussian Process Models}}},
  shorttitle = {{{AutoGP}}},
  author = {Krauth, Karl and Bonilla, Edwin V. and Cutajar, Kurt and Filippone, Maurizio},
  year = {2017},
  month = mar,
  number = {arXiv:1610.05392},
  eprint = {1610.05392},
  primaryclass = {stat},
  institution = {{arXiv}},
  urldate = {2022-05-21},
  abstract = {We investigate the capabilities and limitations of Gaussian process models by jointly exploring three complementary directions: (i) scalable and statistically efficient inference; (ii) flexible kernels; and (iii) objective functions for hyperparameter learning alternative to the marginal likelihood. Our approach outperforms all previously reported GP methods on the standard MNIST dataset; performs comparatively to previous kernel-based methods using the RECTANGLES-IMAGE dataset; and breaks the 1\% error-rate barrier in GP models using the MNIST8M dataset, showing along the way the scalability of our method at unprecedented scale for GP models (8 million observations) in classification problems. Overall, our approach represents a significant breakthrough in kernel methods and GP models, bridging the gap between deep learning approaches and kernel machines.},
  archiveprefix = {arxiv},
  keywords = {ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/KG9MQ5VD/Krauth et al. - 2017 - AutoGP Exploring the Capabilities and Limitations.pdf;/Users/lichengk/Zotero/storage/MEZW3SWN/1610.html}
}

@book{kreyszigAdvancedEngineeringMathematics2011,
  title = {Advanced Engineering Mathematics},
  author = {Kreyszig, Erwin and Kreyszig, Herbert and Norminton, E. J.},
  year = {2011},
  edition = {10th ed},
  publisher = {{John Wiley}},
  address = {{Hoboken, NJ}},
  isbn = {978-0-470-45836-5},
  lccn = {QA401 .K7 2011},
  keywords = {Engineering mathematics,Mathematical physics},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kreyszig et al_2011_Advanced engineering mathematics.pdf}
}

@misc{kristiadiPromisesPitfallsLinearized2023,
  title = {Promises and {{Pitfalls}} of the {{Linearized Laplace}} in {{Bayesian Optimization}}},
  author = {Kristiadi, Agustinus and Immer, Alexander and Eschenhagen, Runa and Fortuin, Vincent},
  year = {2023},
  month = apr,
  number = {arXiv:2304.08309},
  eprint = {2304.08309},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-06-01},
  abstract = {The linearized-Laplace approximation (LLA) has been shown to be effective and efficient in constructing Bayesian neural networks. It is theoretically compelling since it can be seen as a Gaussian process posterior with the mean function given by the neural network's maximum-a-posteriori predictive function and the covariance function induced by the empirical neural tangent kernel. However, while its efficacy has been studied in large-scale tasks like image classification, it has not been studied in sequential decision-making problems like Bayesian optimization where Gaussian processes -- with simple mean functions and kernels such as the radial basis function -- are the de-facto surrogate models. In this work, we study the usefulness of the LLA in Bayesian optimization and highlight its strong performance and flexibility. However, we also present some pitfalls that might arise and a potential problem with the LLA when the search space is unbounded.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kristiadi et al_2023_Promises and Pitfalls of the Linearized Laplace in Bayesian Optimization.pdf;/Users/lichengk/Zotero/storage/3QNDPLJ5/2304.html}
}

@article{kucukelbirAutomaticDifferentiationVariational2017,
  title = {Automatic Differentiation Variational Inference},
  author = {Kucukelbir, Alp and Tran, Dustin and Ranganath, Rajesh and Gelman, Andrew and Blei, David M.},
  year = {2017},
  month = jan,
  journal = {Journal of Machine Learning Research},
  volume = {18},
  number = {1},
  pages = {430--474},
  publisher = {{JMLR.org}},
  issn = {1532-4435},
  abstract = {Probabilistic modeling is iterative. A scientist posits a simple model, fits it to her data, refines it according to her analysis, and repeats. However, fitting complex models to large data is a bottleneck in this process. Deriving algorithms for new models can be both mathematically and computationally challenging, which makes it difficult to efficiently cycle through the steps. To this end, we develop automatic differentiation variational inference (ADVI). Using our method, the scientist only provides a probabilistic model and a dataset, nothing else. ADVI automatically derives an efficient variational inference algorithm, freeing the scientist to refine and explore many models. ADVI supports a broad class of models\textendash no conjugacy assumptions are required. We study ADVI across ten modern probabilistic models and apply it to a dataset with millions of observations. We deploy ADVI as part of Stan, a probabilistic programming system.},
  issue_date = {January 2017},
  keywords = {approximate inference,Bayesian inference,ObsCite,probabilistic programming,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Kucukelbir et al_2017_Automatic differentiation variational inference.pdf}
}

@article{kuleszaKDPPsFixedSizeDeterminantal,
  title = {K-{{DPPs}}: {{Fixed-Size Determinantal Point Processes}}},
  author = {Kulesza, Alex and Taskar, Ben},
  pages = {8},
  abstract = {Determinantal point processes (DPPs) have recently been proposed as models for set selection problems where diversity is preferred. For example, they can be used to select diverse sets of sentences to form document summaries, or to find multiple nonoverlapping human poses in an image. However, DPPs conflate the modeling of two distinct characteristics: the size of the set, and its content. For many realistic tasks, the size of the desired set is known up front; e.g., in search we may want to show the user exactly ten results. In these situations the effort spent by DPPs modeling set size is not only wasteful, but actually introduces unwanted bias into the modeling of content. Instead, we propose the k-DPP, a conditional DPP that models only sets of cardinality k. In exchange for this restriction, k-DPPs offer greater expressiveness and control over content, and simplified integration into applications like search. We derive algorithms for efficiently normalizing, sampling, and marginalizing kDPPs, and propose an experts-style algorithm for learning combinations of k-DPPs. We demonstrate the usefulness of the model on an image search task, where k-DPPs significantly outperform MMR as judged by human annotators.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/IWZ2CCRJ/Kulesza and Taskar - k-DPPs Fixed-Size Determinantal Point Processes.pdf}
}

@inproceedings{kusmierczykVariationalBayesianDecisionmaking2019,
  title = {Variational {{Bayesian Decision-making}} for {{Continuous Utilities}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Ku{\'s}mierczyk, Tomasz and Sakaya, Joseph and Klami, Arto},
  year = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2021-12-08},
  keywords = {toread},
  file = {/Users/lichengk/Zotero/storage/EQYPA4PJ/Kuśmierczyk et al. - 2019 - Variational Bayesian Decision-making for Continuou.pdf}
}

@article{lakeBuildingMachinesThat2017,
  title = {Building Machines That Learn and Think like People},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  year = {2017},
  journal = {Behavioral and Brain Sciences},
  volume = {40},
  pages = {e253},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X16001837},
  urldate = {2021-06-10},
  abstract = {Abstract             Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
  langid = {english},
  keywords = {toread},
  annotation = {1184 citations (Semantic Scholar/DOI) [2021-06-10]},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Lake et al_2017_Building machines that learn and think like people.pdf}
}

@misc{lakshminarayananSimpleScalablePredictive2017,
  title = {Simple and {{Scalable Predictive Uncertainty Estimation}} Using {{Deep Ensembles}}},
  author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  year = {2017},
  month = nov,
  number = {arXiv:1612.01474},
  eprint = {1612.01474},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-17},
  abstract = {Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/GWEX2A6V/Lakshminarayanan et al. - 2017 - Simple and Scalable Predictive Uncertainty Estimat.pdf;/Users/lichengk/Zotero/storage/F8FC6FYK/1612.html}
}

@inproceedings{lalchandApproximateInferenceFully2020,
  title = {Approximate {{Inference}} for {{Fully Bayesian Gaussian Process Regression}}},
  booktitle = {Symposium on {{Advances}} in {{Approximate Bayesian Inference}}},
  author = {Lalchand, Vidhi and Rasmussen, Carl Edward},
  year = {2020},
  month = feb,
  pages = {1--12},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-08-09},
  langid = {english},
  keywords = {*2{$\medwhitestar\medwhitestar$},ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Lalchand_Rasmussen_2020_Approximate Inference for Fully Bayesian Gaussian Process Regression.pdf}
}

@misc{lalchandSparseGaussianProcess2022,
  title = {Sparse {{Gaussian Process Hyperparameters}}: {{Optimize}} or {{Integrate}}?},
  shorttitle = {Sparse {{Gaussian Process Hyperparameters}}},
  author = {Lalchand, Vidhi and Bruinsma, Wessel P. and Burt, David R. and Rasmussen, Carl E.},
  year = {2022},
  month = nov,
  number = {arXiv:2211.02476},
  eprint = {2211.02476},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-11-08},
  abstract = {The kernel function and its hyperparameters are the central model selection choice in a Gaussian proces (Rasmussen and Williams, 2006). Typically, the hyperparameters of the kernel are chosen by maximising the marginal likelihood, an approach known as Type-II maximum likelihood (ML-II). However, ML-II does not account for hyperparameter uncertainty, and it is well-known that this can lead to severely biased estimates and an underestimation of predictive uncertainty. While there are several works which employ a fully Bayesian characterisation of GPs, relatively few propose such approaches for the sparse GPs paradigm. In this work we propose an algorithm for sparse Gaussian process regression which leverages MCMC to sample from the hyperparameter posterior within the variational inducing point framework of Titsias (2009). This work is closely related to Hensman et al. (2015b) but side-steps the need to sample the inducing points, thereby significantly improving sampling efficiency in the Gaussian likelihood case. We compare this scheme against natural baselines in literature along with stochastic variational GPs (SVGPs) along with an extensive computational analysis.},
  archiveprefix = {arxiv},
  keywords = {60G15 (Primary),Computer Science - Machine Learning,G.3,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Lalchand et al_2022_Sparse Gaussian Process Hyperparameters.pdf;/Users/lichengk/Zotero/storage/M9EABCMX/2211.html}
}

@misc{LargeScaleKernel2019,
  title = {Large {{Scale Kernel Methods}}},
  year = {2019},
  month = mar,
  urldate = {2023-06-07},
  abstract = {Supervised Learning Algorithms},
  howpublished = {https://maelfabien.github.io/machinelearning/largescale/},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/8U2EHW4Z/largescale.html}
}

@article{larsenAllLikelihoodStatistical2003,
  title = {In {{All Likelihood}}: {{Statistical Modelling}} and {{Inference Using Likelihood}}},
  shorttitle = {In {{All Likelihood}}},
  author = {Larsen, Pia Veldt},
  year = {2003},
  month = oct,
  journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
  volume = {52},
  number = {3},
  pages = {416--417},
  issn = {0039-0526, 1467-9884},
  doi = {10.1111/1467-9884.00369_20},
  urldate = {2023-04-05},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/FCXV45C9/Larsen - 2003 - In All Likelihood Statistical Modelling and Infer.pdf}
}

@article{larsonDerivativefreeOptimizationMethods2019,
  title = {Derivative-Free Optimization Methods},
  author = {Larson, Jeffrey and Menickelly, Matt and Wild, Stefan M.},
  year = {2019},
  month = may,
  journal = {Acta Numerica},
  volume = {28},
  eprint = {1904.11585},
  pages = {287--404},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492919000060},
  urldate = {2021-11-01},
  abstract = {In many optimization problems arising from scientific, engineering and artificial intelligence applications, objective and constraint functions are available only as the output of a black-box or simulation oracle that does not provide derivative information. Such settings necessitate the use of methods for derivative-free, or zeroth-order, optimization. We provide a review and perspectives on developments in these methods, with an emphasis on highlighting recent developments and on unifying treatment of such problems in the non-linear optimization and machine learning literature. We categorize methods based on assumed properties of the black-box functions, as well as features of the methods. We first overview the primary setting of deterministic methods applied to unconstrained, non-convex optimization problems where the objective function is defined by a deterministic black-box oracle. We then discuss developments in randomized methods, methods that assume some additional structure about the objective (including convexity, separability and general non-smooth compositions), methods for problems where the output of the black-box oracle is stochastic, and methods for handling different types of constraints.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Optimization and Control},
  file = {/Users/lichengk/Zotero/storage/4DCAFCBK/Larson et al. - 2019 - Derivative-free optimization methods.pdf;/Users/lichengk/Zotero/storage/FU97N5AY/1904.html}
}

@article{lazaro-gredillaBayesianWarpedGaussian,
  title = {Bayesian {{Warped Gaussian Processes}}},
  author = {{Lazaro-Gredilla}, Miguel},
  abstract = {Warped Gaussian processes (WGP) [1] model output observations in regression tasks as a parametric nonlinear transformation of a Gaussian process (GP). The use of this nonlinear transformation, which is included as part of the probabilistic model, was shown to enhance performance by providing a better prior model on several data sets. In order to learn its parameters, maximum likelihood was used. In this work we show that it is possible to use a non-parametric nonlinear transformation in WGP and variationally integrate it out. The resulting Bayesian WGP is then able to work in scenarios in which the maximum likelihood WGP failed: Low data regime, data with censored values, classification, etc. We demonstrate the superior performance of Bayesian warped GPs on several real data sets.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/L5HWTZ6E/Lazaro-Gredilla - Bayesian Warped Gaussian Processes.pdf}
}

@misc{leeDeepNeuralNetworks2018,
  title = {Deep {{Neural Networks}} as {{Gaussian Processes}}},
  author = {Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S. and Pennington, Jeffrey and {Sohl-Dickstein}, Jascha},
  year = {2018},
  month = mar,
  number = {arXiv:1711.00165},
  eprint = {1711.00165},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1711.00165},
  urldate = {2022-11-06},
  abstract = {It has long been known that a single-layer fully-connected neural network with an i.i.d. prior over its parameters is equivalent to a Gaussian process (GP), in the limit of infinite network width. This correspondence enables exact Bayesian inference for infinite width neural networks on regression tasks by means of evaluating the corresponding GP. Recently, kernel functions which mimic multi-layer random neural networks have been developed, but only outside of a Bayesian framework. As such, previous work has not identified that these kernels can be used as covariance functions for GPs and allow fully Bayesian prediction with a deep neural network. In this work, we derive the exact equivalence between infinitely wide deep networks and GPs. We further develop a computationally efficient pipeline to compute the covariance function for these GPs. We then use the resulting GPs to perform Bayesian inference for wide deep neural networks on MNIST and CIFAR-10. We observe that trained neural network accuracy approaches that of the corresponding GP with increasing layer width, and that the GP uncertainty is strongly correlated with trained network prediction error. We further find that test performance increases as finite-width trained networks are made wider and more similar to a GP, and thus that GP predictions typically outperform those of finite-width networks. Finally we connect the performance of these GPs to the recent theory of signal propagation in random neural networks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Lee et al_2018_Deep Neural Networks as Gaussian Processes.pdf;/Users/lichengk/Zotero/storage/WHBMI8VC/1711.html}
}

@inproceedings{leeFiniteInfiniteNeural2020,
  title = {Finite {{Versus Infinite Neural Networks}}: An {{Empirical Study}}},
  shorttitle = {Finite {{Versus Infinite Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lee, Jaehoon and Schoenholz, Samuel and Pennington, Jeffrey and Adlam, Ben and Xiao, Lechao and Novak, Roman and {Sohl-Dickstein}, Jascha},
  year = {2020},
  volume = {33},
  pages = {15156--15172},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-06-02},
  abstract = {We perform a careful, thorough, and large scale empirical study of the correspondence between wide neural networks and kernel methods. By doing so, we resolve a variety of open questions related to the study of infinitely wide neural networks. Our experimental results include: kernel methods outperform fully-connected finite-width networks, but underperform convolutional finite width networks; neural network Gaussian process (NNGP) kernels frequently outperform neural tangent (NT) kernels; centered and ensembled finite networks have reduced posterior variance and behave more similarly to infinite networks; weight decay and the use of a large learning rate break the correspondence between finite and infinite networks; the NTK parameterization outperforms the standard parameterization for finite width networks; diagonal regularization of kernels acts similarly to early stopping; floating point precision limits kernel performance beyond a critical dataset size; regularized ZCA whitening improves accuracy; finite network performance depends non-monotonically on width in ways not captured by double descent phenomena; equivariance of CNNs is only beneficial for narrow networks far from the kernel regime. Our experiments additionally motivate an improved layer-wise scaling for weight decay which improves generalization in finite-width networks. Finally, we develop improved best practices for using NNGP and NT kernels for prediction, including a novel ensembling technique. Using these best practices we achieve state-of-the-art results on CIFAR-10 classification for kernels corresponding to each architecture class we consider.},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Lee et al_2020_Finite Versus Infinite Neural Networks.pdf}
}

@article{leFastfoodApproximatingKernel,
  title = {Fastfood \textemdash{} {{Approximating Kernel Expansions}} in {{Loglinear Time}}},
  author = {Le, Quoc and Sarl{\'o}s, Tam{\'a}s and Smola, Alex},
  pages = {11},
  abstract = {Despite their successes, what makes kernel methods difficult to use in many large scale problems is the fact that computing the decision function is typically expensive, especially at prediction time. In this paper, we overcome this difficulty by proposing Fastfood, an approximation that accelerates such computation significantly. Key to Fastfood is the observation that Hadamard matrices when combined with diagonal Gaussian matrices exhibit properties similar to dense Gaussian random matrices. Yet unlike the latter, Hadamard and diagonal matrices are inexpensive to multiply and store. These two matrices can be used in lieu of Gaussian matrices in Random Kitchen Sinks (Rahimi \& Recht, 2007) and thereby speeding up the computation for a large range of kernel functions. Specifically, Fastfood requires O(n log d) time and O(n) storage to compute n non-linear basis functions in d dimensions, a significant improvement from O(nd) computation and storage, without sacrificing accuracy. We prove that the approximation is unbiased and has low variance. Extensive experiments show that we achieve similar accuracy to full kernel expansions and Random Kitchen Sinks while being 100x faster and using 1000x less memory. These improvements, especially in terms of memory usage, make kernel methods more practical for applications that have large training sets and/or require real-time prediction.},
  langid = {english}
}

@inproceedings{leFastfoodcomputingHilbertSpace2013,
  title = {Fastfood-Computing Hilbert Space Expansions in Loglinear Time},
  booktitle = {International Conference on Machine Learning},
  author = {Le, Quoc and Sarl{\'o}s, Tam{\'a}s and Smola, Alexander},
  year = {2013},
  pages = {244--252},
  organization = {{PMLR}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Le et al_2013_Fastfood-computing hilbert space expansions in loglinear time.pdf}
}

@article{leibfriedTutorialSparseGaussian2021,
  title = {A {{Tutorial}} on {{Sparse Gaussian Processes}} and {{Variational Inference}}},
  author = {Leibfried, Felix and Dutordoir, Vincent and John, S. T. and Durrande, Nicolas},
  year = {2021},
  month = jul,
  journal = {arXiv:2012.13962 [cs, stat]},
  eprint = {2012.13962},
  primaryclass = {cs, stat},
  urldate = {2021-08-16},
  abstract = {Gaussian processes (GPs) provide a framework for Bayesian inference that can offer principled uncertainty estimates for a large range of problems. For example, if we consider regression problems with Gaussian likelihoods, a GP model enjoys a posterior in closed form. However, identifying the posterior GP scales cubically with the number of training examples and requires to store all examples in memory. In order to overcome these obstacles, sparse GPs have been proposed that approximate the true posterior GP with pseudo-training examples. Importantly, the number of pseudo-training examples is user-defined and enables control over computational and memory complexity. In the general case, sparse GPs do not enjoy closed-form solutions and one has to resort to approximate inference. In this context, a convenient choice for approximate inference is variational inference (VI), where the problem of Bayesian inference is cast as an optimization problem -- namely, to maximize a lower bound of the log marginal likelihood. This paves the way for a powerful and versatile framework, where pseudo-training examples are treated as optimization arguments of the approximate posterior that are jointly identified together with hyperparameters of the generative model (i.e. prior and likelihood). The framework can naturally handle a wide scope of supervised learning problems, ranging from regression with heteroscedastic and non-Gaussian likelihoods to classification problems with discrete labels, but also multilabel problems. The purpose of this tutorial is to provide access to the basic matter for readers without prior knowledge in both GPs and VI. A proper exposition to the subject enables also access to more recent advances (like importance-weighted VI as well as interdomain, multioutput and deep GPs) that can serve as an inspiration for new research ideas.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Leibfried et al_2021_A Tutorial on Sparse Gaussian Processes and Variational Inference.pdf;/Users/lichengk/Zotero/storage/6EIHEDTS/2012.html}
}

@misc{liFourierNeuralOperator2021,
  title = {Fourier {{Neural Operator}} for {{Parametric Partial Differential Equations}}},
  author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
  year = {2021},
  month = may,
  number = {arXiv:2010.08895},
  eprint = {2010.08895},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  urldate = {2022-07-25},
  abstract = {The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Li et al_2021_Fourier Neural Operator for Parametric Partial Differential Equations.pdf;/Users/lichengk/Zotero/storage/MQ4XYBVJ/2010.html}
}

@article{lintusaariELFIEngineLikelihoodFree,
  title = {{{ELFI}}: {{Engine}} for {{Likelihood-Free Inference}}},
  author = {Lintusaari, Jarno and Vuollekoski, Henri and Kangasraasio, Antti and Skyten, Kusti and Jarvenpaa, Marko and Marttinen, Pekka and Gutmann, Michael U and Vehtari, Aki and Corander, Jukka and Kaski, Samuel},
  pages = {7},
  abstract = {Engine for Likelihood-Free Inference (ELFI) is a Python software library for performing likelihood-free inference (LFI). ELFI provides a convenient syntax for arranging components in LFI, such as priors, simulators, summaries or distances, to a network called ELFI graph. The components can be implemented in a wide variety of languages. The stand-alone ELFI graph can be used with any of the available inference methods without modifications. A central method implemented in ELFI is Bayesian Optimization for Likelihood-Free Inference (BOLFI), which has recently been shown to accelerate likelihood-free inference up to several orders of magnitude by surrogate-modelling the distance. ELFI also has an inbuilt support for output data storing for reuse and analysis, and supports parallelization of computation from multiple cores up to a cluster environment. ELFI is designed to be extensible and provides interfaces for widening its functionality. This makes the adding of new inference methods to ELFI straightforward and automatically compatible with the inbuilt features.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/PQFNUMBA/Lintusaari et al. - ELFI Engine for Likelihood-Free Inference.pdf}
}

@inproceedings{liRenyiDivergenceVariational2016,
  title = {R\'enyi {{Divergence Variational Inference}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Li, Yingzhen and Turner, Richard E},
  year = {2016},
  volume = {29},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-06-17},
  abstract = {This paper introduces the variational R\'enyi bound (VR) that extends traditional variational inference to R\'enyi's alpha-divergences. This new family of variational methods unifies a number of existing approaches, and enables a smooth interpolation from the evidence lower-bound to the log (marginal) likelihood that is controlled by the value of alpha that parametrises the divergence. The reparameterization trick, Monte Carlo approximation and stochastic optimisation methods are deployed to obtain a tractable and unified framework for optimisation. We further consider negative alpha values and propose a novel variational inference method as a new special case in the proposed framework. Experiments on Bayesian neural networks and variational auto-encoders demonstrate the wide applicability of the VR bound.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Li_Turner_2016_Rényi Divergence Variational Inference.pdf}
}

@misc{liStudyBayesianNeural2023,
  title = {A {{Study}} of {{Bayesian Neural Network Surrogates}} for {{Bayesian Optimization}}},
  author = {Li, Yucen Lily and Rudner, Tim G. J. and Wilson, Andrew Gordon},
  year = {2023},
  month = may,
  number = {arXiv:2305.20028},
  eprint = {2305.20028},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-06-01},
  abstract = {Bayesian optimization is a highly efficient approach to optimizing objective functions which are expensive to query. These objectives are typically represented by Gaussian process (GP) surrogate models which are easy to optimize and support exact inference. While standard GP surrogates have been well-established in Bayesian optimization, Bayesian neural networks (BNNs) have recently become practical function approximators, with many benefits over standard GPs such as the ability to naturally handle non-stationarity and learn representations for high-dimensional data. In this paper, we study BNNs as alternatives to standard GP surrogates for optimization. We consider a variety of approximate inference procedures for finite-width BNNs, including high-quality Hamiltonian Monte Carlo, low-cost stochastic MCMC, and heuristics such as deep ensembles. We also consider infinite-width BNNs and partially stochastic models such as deep kernel learning. We evaluate this collection of surrogate models on diverse problems with varying dimensionality, number of objectives, non-stationarity, and discrete and continuous inputs. We find: (i) the ranking of methods is highly problem dependent, suggesting the need for tailored inductive biases; (ii) HMC is the most successful approximate inference procedure for fully stochastic BNNs; (iii) full stochasticity may be unnecessary as deep kernel learning is relatively competitive; (iv) infinite-width BNNs are particularly promising, especially in high dimensions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Li et al_2023_A Study of Bayesian Neural Network Surrogates for Bayesian Optimization.pdf;/Users/lichengk/Zotero/storage/MBCES8C3/2305.html}
}

@misc{liuRandomFeaturesKernel2021,
  title = {Random {{Features}} for {{Kernel Approximation}}: {{A Survey}} on {{Algorithms}}, {{Theory}}, and {{Beyond}}},
  shorttitle = {Random {{Features}} for {{Kernel Approximation}}},
  author = {Liu, Fanghui and Huang, Xiaolin and Chen, Yudong and Suykens, Johan A. K.},
  year = {2021},
  month = jul,
  number = {arXiv:2004.11154},
  eprint = {2004.11154},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-06-07},
  abstract = {Random features is one of the most popular techniques to speed up kernel methods in large-scale problems. Related works have been recognized by the NeurIPS Test-of-Time award in 2017 and the ICML Best Paper Finalist in 2019. The body of work on random features has grown rapidly, and hence it is desirable to have a comprehensive overview on this topic explaining the connections among various algorithms and theoretical results. In this survey, we systematically review the work on random features from the past ten years. First, the motivations, characteristics and contributions of representative random features based algorithms are summarized according to their sampling schemes, learning procedures, variance reduction properties and how they exploit training data. Second, we review theoretical results that center around the following key question: how many random features are needed to ensure a high approximation quality or no loss in the empirical/expected risks of the learned estimator. Third, we provide a comprehensive evaluation of popular random features based algorithms on several large-scale benchmark datasets and discuss their approximation quality and prediction performance for classification. Last, we discuss the relationship between random features and modern over-parameterized deep neural networks (DNNs), including the use of high dimensional random features in the analysis of DNNs as well as the gaps between current theoretical and empirical results. This survey may serve as a gentle introduction to this topic, and as a users' guide for practitioners interested in applying the representative algorithms and understanding theoretical results under various technical assumptions. We hope that this survey will facilitate discussion on the open problems in this topic, and more importantly, shed light on future research directions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Liu et al_2021_Random Features for Kernel Approximation.pdf;/Users/lichengk/Zotero/storage/AJMYGREG/2004.html}
}

@article{liuSteinVariationalGradient2019,
  title = {Stein {{Variational Gradient Descent}}: {{A General Purpose Bayesian Inference Algorithm}}},
  shorttitle = {Stein {{Variational Gradient Descent}}},
  author = {Liu, Qiang and Wang, Dilin},
  year = {2019},
  month = sep,
  journal = {arXiv:1608.04471 [cs, stat]},
  eprint = {1608.04471},
  primaryclass = {cs, stat},
  urldate = {2021-10-12},
  abstract = {We propose a general purpose variational inference algorithm that forms a natural counterpart of gradient descent for optimization. Our method iteratively transports a set of particles to match the target distribution, by applying a form of functional gradient descent that minimizes the KL divergence. Empirical studies are performed on various real world models and datasets, on which our method is competitive with existing state-of-the-art methods. The derivation of our method is based on a new theoretical result that connects the derivative of KL divergence under smooth transforms with Stein's identity and a recently proposed kernelized Stein discrepancy, which is of independent interest.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/IR9PNA5S/Liu and Wang - 2019 - Stein Variational Gradient Descent A General Purp.pdf;/Users/lichengk/Zotero/storage/HSTHX5PR/1608.html}
}

@inproceedings{liuTaskagnosticAmortizedInference2020,
  title = {Task-Agnostic Amortized Inference of Gaussian Process Hyperparameters},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Liu, Sulin and Sun, Xingyuan and Ramadge, Peter J and Adams, Ryan P},
  editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M. F. and Lin, H.},
  year = {2020},
  volume = {33},
  pages = {21440--21452},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Liu et al_2020_Task-agnostic amortized inference of gaussian process hyperparameters.pdf}
}

@article{llorenteSurveyMonteCarlo2021,
  title = {A Survey of {{Monte Carlo}} Methods for Noisy and Costly Densities with Application to Reinforcement Learning},
  author = {Llorente, F. and Martino, L. and Read, J. and Delgado, D.},
  year = {2021},
  month = aug,
  journal = {arXiv:2108.00490 [cs, stat]},
  eprint = {2108.00490},
  primaryclass = {cs, stat},
  urldate = {2021-08-10},
  abstract = {This survey gives an overview of Monte Carlo methodologies using surrogate models, for dealing with densities which are intractable, costly, and/or noisy. This type of problem can be found in numerous real-world scenarios, including stochastic optimization and reinforcement learning, where each evaluation of a density function may incur some computationally-expensive or even physical (real-world activity) cost, likely to give different results each time. The surrogate model does not incur this cost, but there are important trade-offs and considerations involved in the choice and design of such methodologies. We classify the different methodologies into three main classes and describe specific instances of algorithms under a unified notation. A modular scheme which encompasses the considered methods is also presented. A range of application scenarios is discussed, with special attention to the likelihood-free setting and reinforcement learning. Several numerical comparisons are also provided.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Llorente et al_2021_A survey of Monte Carlo methods for noisy and costly densities with application.pdf;/Users/lichengk/Zotero/storage/6IRHNPBK/2108.html}
}

@article{lotfiBayesianModelSelection2022,
  title = {Bayesian {{Model Selection}}, the {{Marginal Likelihood}}, and {{Generalization}}},
  author = {Lotfi, Sanae and Izmailov, Pavel and Benton, Gregory and Goldblum, Micah and Wilson, Andrew Gordon},
  year = {2022},
  month = feb,
  journal = {arXiv:2202.11678 [cs, stat]},
  eprint = {2202.11678},
  primaryclass = {cs, stat},
  urldate = {2022-02-25},
  abstract = {How do we compare between hypotheses that are entirely consistent with observations? The marginal likelihood (aka Bayesian evidence), which represents the probability of generating our observations from a prior, provides a distinctive approach to this foundational question, automatically encoding Occam's razor. Although it has been observed that the marginal likelihood can overfit and is sensitive to prior assumptions, its limitations for hyperparameter learning and discrete model comparison have not been thoroughly investigated. We first revisit the appealing properties of the marginal likelihood for learning constraints and hypothesis testing. We then highlight the conceptual and practical issues in using the marginal likelihood as a proxy for generalization. Namely, we show how marginal likelihood can be negatively correlated with generalization, with implications for neural architecture search, and can lead to both underfitting and overfitting in hyperparameter learning. We provide a partial remedy through a conditional marginal likelihood, which we show is more aligned with generalization, and practically valuable for large-scale hyperparameter learning, such as in deep kernel learning.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Lotfi et al_2022_Bayesian Model Selection, the Marginal Likelihood, and Generalization.pdf}
}

@misc{luAdditiveGaussianProcesses2022,
  title = {Additive {{Gaussian Processes Revisited}}},
  author = {Lu, Xiaoyu and Boukouvalas, Alexis and Hensman, James},
  year = {2022},
  month = jun,
  number = {arXiv:2206.09861},
  eprint = {2206.09861},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-09-29},
  abstract = {Gaussian Process (GP) models are a class of flexible non-parametric models that have rich representational power. By using a Gaussian process with additive structure, complex responses can be modelled whilst retaining interpretability. Previous work showed that additive Gaussian process models require high-dimensional interaction terms. We propose the orthogonal additive kernel (OAK), which imposes an orthogonality constraint on the additive functions, enabling an identifiable, low-dimensional representation of the functional relationship. We connect the OAK kernel to functional ANOVA decomposition, and show improved convergence rates for sparse computation methods. With only a small number of additive low-dimensional terms, we demonstrate the OAK model achieves similar or better predictive performance compared to black-box models, while retaining interpretability.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/UYHGLDXT/Lu et al. - 2022 - Additive Gaussian Processes Revisited.pdf;/Users/lichengk/Zotero/storage/TKX2KYID/2206.html}
}

@inproceedings{lueckmannBenchmarkingSimulationBasedInference2021,
  title = {Benchmarking {{Simulation-Based Inference}}},
  booktitle = {Proceedings of {{The}} 24th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Lueckmann, Jan-Matthis and Boelts, Jan and Greenberg, David and Goncalves, Pedro and Macke, Jakob},
  year = {2021},
  month = mar,
  pages = {343--351},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-05-20},
  abstract = {Recent advances in probabilistic modelling have led to a large number of simulation-based inference algorithms which do not require numerical evaluation of likelihoods. However, a public benchmark with appropriate performance metrics for such 'likelihood-free' algorithms has been lacking. This has made it difficult to compare algorithms and identify their strengths and weaknesses. We set out to fill this gap: We provide a benchmark with inference tasks and suitable performance metrics, with an initial selection of algorithms including recent approaches employing neural networks and classical Approximate Bayesian Computation methods. We found that the choice of performance metric is critical, that even state-of-the-art algorithms have substantial room for improvement, and that sequential estimation improves sample efficiency. Neural network-based approaches generally exhibit better performance, but there is no uniformly best algorithm. We provide practical advice and highlight the potential of the benchmark to diagnose problems and improve algorithms. The results can be explored interactively on a companion website. All code is open source, making it possible to contribute further benchmark tasks and inference algorithms.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Lueckmann et al_2021_Benchmarking Simulation-Based Inference.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Lueckmann et al_2021_Benchmarking Simulation-Based Inference2.pdf}
}

@article{lugosiNonparametricEstimationEmpirical1995,
  title = {Nonparametric {{Estimation}} via {{Empirical Risk Miriimization}}},
  author = {Lugosi, {\relax Ga}bor},
  year = {1995},
  journal = {IEEE TRANSACTIONS ON INFORMATION THEORY},
  volume = {41},
  number = {3},
  abstract = {A general notion of universal consistency of nonparametric estimators is introduced that applies to regression estimation, conditional median estimation, curve fitting, pattern recognition, and learning concepts. General methods for proving consistency of estimators based on minimizing the empirical error are shown. In particular, distribution-free almost sure consistency of neural network estimates and generalized linear estimators is established.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/732CA6TA/Lugosi - 1995 - Nonparametric Estimation via Empirical Risk Miriim.pdf}
}

@article{lugosiUniversalKernels,
  title = {Universal {{Kernels}}},
  author = {Lugosi, Gabor},
  pages = {17},
  abstract = {In this paper we investigate conditions on the features of a continuous kernel so that it may approximate an arbitrary continuous target function uniformly on any compact subset of the input space. A number of concrete examples are given of kernels with this universal approximating property.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/K2MW4JGW/Lugosi - YXU06@SYR.EDU HZHANG12@SYR.EDU.pdf}
}

@book{mackayInformationTheoryInference2002,
  title = {Information {{Theory}}, {{Inference}} and {{Learning Algorithms}}},
  author = {MacKay, David J. C.},
  year = {2002},
  publisher = {{Cambridge University Press}},
  address = {{USA}},
  isbn = {0-521-64298-1},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/MacKay_2002_Information Theory, Inference and Learning Algorithms.pdf}
}

@article{maddoxBayesianOptimizationHighDimensional2021,
  title = {Bayesian {{Optimization}} with {{High-Dimensional Outputs}}},
  author = {Maddox, Wesley J. and Balandat, Maximilian and Wilson, Andrew Gordon and Bakshy, Eytan},
  year = {2021},
  month = oct,
  journal = {arXiv:2106.12997 [cs, stat]},
  eprint = {2106.12997},
  primaryclass = {cs, stat},
  urldate = {2021-11-04},
  abstract = {Bayesian Optimization is a sample-efficient black-box optimization procedure that is typically applied to problems with a small number of independent objectives. However, in practice we often wish to optimize objectives defined over many correlated outcomes (or "tasks"). For example, scientists may want to optimize the coverage of a cell tower network across a dense grid of locations. Similarly, engineers may seek to balance the performance of a robot across dozens of different environments via constrained or robust optimization. However, the Gaussian Process (GP) models typically used as probabilistic surrogates for multi-task Bayesian Optimization scale poorly with the number of outcomes, greatly limiting applicability. We devise an efficient technique for exact multi-task GP sampling that combines exploiting Kronecker structure in the covariance matrices with Matheron's identity, allowing us to perform Bayesian Optimization using exact multi-task GP models with tens of thousands of correlated outputs. In doing so, we achieve substantial improvements in sample efficiency compared to existing approaches that only model aggregate functions of the outcomes. We demonstrate how this unlocks a new class of applications for Bayesian Optimization across a range of tasks in science and engineering, including optimizing interference patterns of an optical interferometer with more than 65,000 outputs.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/KCDAXG85/Maddox et al. - 2021 - Bayesian Optimization with High-Dimensional Output.pdf;/Users/lichengk/Zotero/storage/DWBTFDW5/2106.html}
}

@article{maddoxConditioningSparseVariational2021,
  title = {Conditioning {{Sparse Variational Gaussian Processes}} for {{Online Decision-making}}},
  author = {Maddox, Wesley J. and Stanton, Samuel and Wilson, Andrew Gordon},
  year = {2021},
  month = oct,
  journal = {arXiv:2110.15172 [cs, stat]},
  eprint = {2110.15172},
  primaryclass = {cs, stat},
  urldate = {2021-12-16},
  abstract = {With a principled representation of uncertainty and closed form posterior updates, Gaussian processes (GPs) are a natural choice for online decision making. However, Gaussian processes typically require at least \$\textbackslash mathcal\{O\}(n\^2)\$ computations for \$n\$ training points, limiting their general applicability. Stochastic variational Gaussian processes (SVGPs) can provide scalable inference for a dataset of fixed size, but are difficult to efficiently condition on new data. We propose online variational conditioning (OVC), a procedure for efficiently conditioning SVGPs in an online setting that does not require re-training through the evidence lower bound with the addition of new data. OVC enables the pairing of SVGPs with advanced look-ahead acquisition functions for black-box optimization, even with non-Gaussian likelihoods. We show OVC provides compelling performance in a range of applications including active learning of malaria incidence, and reinforcement learning on MuJoCo simulated robotic control tasks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Maddox et al_2021_Conditioning Sparse Variational Gaussian Processes for Online Decision-making.pdf;/Users/lichengk/Zotero/storage/BMB6ETDP/2110.html}
}

@inproceedings{maddoxConditioningSparseVariational2021a,
  title = {Conditioning {{Sparse Variational Gaussian Processes}} for {{Online Decision-making}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Maddox, Wesley J and Stanton, Samuel and Wilson, Andrew G},
  editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P. S. and Vaughan, J. Wortman},
  year = {2021},
  volume = {34},
  pages = {6365--6379},
  publisher = {{Curran Associates, Inc.}}
}

@misc{maddoxConditioningSparseVariational2021b,
  title = {Conditioning {{Sparse Variational Gaussian Processes}} for {{Online Decision-making}}},
  author = {Maddox, Wesley J. and Stanton, Samuel and Wilson, Andrew Gordon},
  year = {2021},
  month = oct,
  number = {arXiv:2110.15172},
  eprint = {2110.15172},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-02-08},
  abstract = {With a principled representation of uncertainty and closed form posterior updates, Gaussian processes (GPs) are a natural choice for online decision making. However, Gaussian processes typically require at least \$\textbackslash mathcal\{O\}(n\^2)\$ computations for \$n\$ training points, limiting their general applicability. Stochastic variational Gaussian processes (SVGPs) can provide scalable inference for a dataset of fixed size, but are difficult to efficiently condition on new data. We propose online variational conditioning (OVC), a procedure for efficiently conditioning SVGPs in an online setting that does not require re-training through the evidence lower bound with the addition of new data. OVC enables the pairing of SVGPs with advanced look-ahead acquisition functions for black-box optimization, even with non-Gaussian likelihoods. We show OVC provides compelling performance in a range of applications including active learning of malaria incidence, and reinforcement learning on MuJoCo simulated robotic control tasks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/WM7S3APU/Maddox et al. - 2021 - Conditioning Sparse Variational Gaussian Processes.pdf;/Users/lichengk/Zotero/storage/ZR92KYUP/2110.html}
}

@article{maddoxSimpleBaselineBayesian,
  title = {A {{Simple Baseline}} for {{Bayesian Uncertainty}} in {{Deep Learning}}},
  author = {Maddox, Wesley J and Garipov, Timur and Izmailov, Pavel and Vetrov, Dmitry and Wilson, Andrew Gordon},
  abstract = {We propose SWA-Gaussian (SWAG), a simple, scalable, and general purpose approach for uncertainty representation and calibration in deep learning. Stochastic Weight Averaging (SWA), which computes the first moment of stochastic gradient descent (SGD) iterates with a modified learning rate schedule, has recently been shown to improve generalization in deep learning. With SWAG, we fit a Gaussian using the SWA solution as the first moment and a low rank plus diagonal covariance also derived from the SGD iterates, forming an approximate posterior distribution over neural network weights; we then sample from this Gaussian distribution to perform Bayesian model averaging. We empirically find that SWAG approximates the shape of the true posterior, in accordance with results describing the stationary distribution of SGD iterates. Moreover, we demonstrate that SWAG performs well on a wide variety of tasks, including out of sample detection, calibration, and transfer learning, in comparison to many popular alternatives including MC dropout, KFAC Laplace, SGLD, and temperature scaling.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Maddox et al_A Simple Baseline for Bayesian Uncertainty in Deep Learning.pdf}
}

@article{maddoxWhenAreIterative,
  title = {When Are {{Iterative Gaussian Processes Reliably Accurate}}?},
  author = {Maddox, Wesley J and Kapoor, Sanyam and Wilson, Andrew Gordon},
  pages = {9},
  abstract = {While recent work on conjugate gradient methods and Lanczos decompositions have achieved scalable Gaussian process inference with highly accurate point predictions, in several implementations these iterative methods appear to struggle with numerical instabilities in learning kernel hyperparameters, and poor test likelihoods. By investigating CG tolerance, preconditioner rank, and Lanczos decomposition rank, we provide a particularly simple prescription to correct these issues: we recommend that one should use a small CG tolerance ( {$\leq$} 0.01) and a large root decomposition size (r {$\geq$} 5000). Moreover, we show that L-BFGS-B is a compelling optimizer for Iterative GPs, achieving convergence with fewer gradient updates.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/GND93AFI/Maddox et al. - When are Iterative Gaussian Processes Reliably Acc.pdf}
}

@misc{maddoxWhenAreIterative2021,
  title = {When Are {{Iterative Gaussian Processes Reliably Accurate}}?},
  author = {Maddox, Wesley J. and Kapoor, Sanyam and Wilson, Andrew Gordon},
  year = {2021},
  month = dec,
  number = {arXiv:2112.15246},
  eprint = {2112.15246},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-04-12},
  abstract = {While recent work on conjugate gradient methods and Lanczos decompositions have achieved scalable Gaussian process inference with highly accurate point predictions, in several implementations these iterative methods appear to struggle with numerical instabilities in learning kernel hyperparameters, and poor test likelihoods. By investigating CG tolerance, preconditioner rank, and Lanczos decomposition rank, we provide a particularly simple prescription to correct these issues: we recommend that one should use a small CG tolerance (\$\textbackslash epsilon \textbackslash leq 0.01\$) and a large root decomposition size (\$r \textbackslash geq 5000\$). Moreover, we show that L-BFGS-B is a compelling optimizer for Iterative GPs, achieving convergence with fewer gradient updates.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/92TV7UDS/Maddox et al. - 2021 - When are Iterative Gaussian Processes Reliably Acc.pdf;/Users/lichengk/Zotero/storage/5HE7QC7I/2112.html}
}

@article{mahsereciProbabilisticLineSearches2016,
  title = {Probabilistic {{Line Searches}} for {{Stochastic Optimization}}},
  author = {Mahsereci, Maren and Hennig, Philipp},
  year = {2016},
  month = jan,
  journal = {arXiv:1502.02846 [cs, math, stat]},
  eprint = {1502.02846},
  primaryclass = {cs, math, stat},
  urldate = {2022-03-21},
  abstract = {In deterministic optimization, line searches are a standard tool ensuring stability and efficiency. Where only stochastic gradients are available, no direct equivalent has so far been formulated, because uncertain gradients do not allow for a strict sequence of decisions collapsing the search space. We construct a probabilistic line search by combining the structure of existing deterministic methods with notions from Bayesian optimization. Our method retains a Gaussian process surrogate of the univariate optimization objective, and uses a probabilistic belief over the Wolfe conditions to monitor the descent. The algorithm has very low computational cost, and no user-controlled parameters. Experiments show that it effectively removes the need to define a learning rate for stochastic gradient descent.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Mahsereci_Hennig_2016_Probabilistic Line Searches for Stochastic Optimization.pdf;/Users/lichengk/Zotero/storage/ZH47KHRY/1502.html}
}

@article{makSupportPoints2018,
  title = {Support Points},
  author = {Mak, Simon and Joseph, V. Roshan},
  year = {2018},
  month = dec,
  journal = {The Annals of Statistics},
  volume = {46},
  number = {6A},
  pages = {2562--2592},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/17-AOS1629},
  urldate = {2023-02-28},
  abstract = {This paper introduces a new way to compact a continuous probability distribution \$F\$ into a set of representative points called support points. These points are obtained by minimizing the energy distance, a statistical potential measure initially proposed by Sz\'ekely and Rizzo [InterStat 5 (2004) 1\textendash 6] for testing goodness-of-fit. The energy distance has two appealing features. First, its distance-based structure allows us to exploit the duality between powers of the Euclidean distance and its Fourier transform for theoretical analysis. Using this duality, we show that support points converge in distribution to \$F\$, and enjoy an improved error rate to Monte Carlo for integrating a large class of functions. Second, the minimization of the energy distance can be formulated as a difference-of-convex program, which we manipulate using two algorithms to efficiently generate representative point sets. In simulation studies, support points provide improved integration performance to both Monte Carlo and a specific quasi-Monte Carlo method. Two important applications of support points are then highlighted: (a) as a way to quantify the propagation of uncertainty in expensive simulations and (b) as a method to optimally compact Markov chain Monte Carlo (MCMC) samples in Bayesian computation.},
  keywords = {62E17,Bayesian computation,energy distance,Monte Carlo,numerical integration,quasi-Monte Carlo,representative points},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Mak_Joseph_2018_Support points.pdf}
}

@misc{malininUncertaintyGradientBoosting2021,
  title = {Uncertainty in {{Gradient Boosting}} via {{Ensembles}}},
  author = {Malinin, Andrey and Prokhorenkova, Liudmila and Ustimenko, Aleksei},
  year = {2021},
  month = apr,
  number = {arXiv:2006.10562},
  eprint = {2006.10562},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-12-14},
  abstract = {For many practical, high-risk applications, it is essential to quantify uncertainty in a model's predictions to avoid costly mistakes. While predictive uncertainty is widely studied for neural networks, the topic seems to be under-explored for models based on gradient boosting. However, gradient boosting often achieves state-of-the-art results on tabular data. This work examines a probabilistic ensemble-based framework for deriving uncertainty estimates in the predictions of gradient boosting classification and regression models. We conducted experiments on a range of synthetic and real datasets and investigated the applicability of ensemble approaches to gradient boosting models that are themselves ensembles of decision trees. Our analysis shows that ensembles of gradient boosting models successfully detect anomalous inputs while having limited ability to improve the predicted total uncertainty. Importantly, we also propose a concept of a virtual ensemble to get the benefits of an ensemble via only one gradient boosting model, which significantly reduces complexity.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/HQ9R5FDF/Malinin et al. - 2021 - Uncertainty in Gradient Boosting via Ensembles.pdf;/Users/lichengk/Zotero/storage/A9GRL8XX/2006.html}
}

@article{markouPracticalConditionalNeural2022,
  title = {Practical {{Conditional Neural Processes Via Tractable Dependent Predictions}}},
  author = {Markou, Stratis and Requeima, James and Bruinsma, Wessel P. and Vaughan, Anna and Turner, Richard E.},
  year = {2022},
  month = mar,
  journal = {arXiv:2203.08775 [cs, stat]},
  eprint = {2203.08775},
  primaryclass = {cs, stat},
  urldate = {2022-04-20},
  abstract = {Conditional Neural Processes (CNPs; Garnelo et al., 2018a) are meta-learning models which leverage the flexibility of deep learning to produce well-calibrated predictions and naturally handle off-the-grid and missing data. CNPs scale to large datasets and train with ease. Due to these features, CNPs appear well-suited to tasks from environmental sciences or healthcare. Unfortunately, CNPs do not produce correlated predictions, making them fundamentally inappropriate for many estimation and decision making tasks. Predicting heat waves or floods, for example, requires modelling dependencies in temperature or precipitation over time and space. Existing approaches which model output dependencies, such as Neural Processes (NPs; Garnelo et al., 2018b) or the FullConvGNP (Bruinsma et al., 2021), are either complicated to train or prohibitively expensive. What is needed is an approach which provides dependent predictions, but is simple to train and computationally tractable. In this work, we present a new class of Neural Process models that make correlated predictions and support exact maximum likelihood training that is simple and scalable. We extend the proposed models by using invertible output transformations, to capture non-Gaussian output distributions. Our models can be used in downstream estimation tasks which require dependent function samples. By accounting for output dependencies, our models show improved predictive performance on a range of experiments with synthetic and real data.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Markou et al_2022_Practical Conditional Neural Processes Via Tractable Dependent Predictions.pdf;/Users/lichengk/Zotero/storage/R2SS7QAF/2203.html}
}

@misc{maronasEfficientTransformedGaussian2022,
  title = {Efficient {{Transformed Gaussian Processes}} for {{Non-Stationary Dependent Multi-class Classification}}},
  author = {Maro{\~n}as, Juan and {Hern{\'a}ndez-Lobato}, Daniel},
  year = {2022},
  month = may,
  number = {arXiv:2205.15008},
  eprint = {2205.15008},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-06-30},
  abstract = {This work introduces the Efficient Transformed Gaussian Process (ETGP), a new way of creating C stochastic processes characterized by: 1) the C processes are non-stationary, 2) the C processes are dependent by construction without needing a mixing matrix, 3) training and making predictions is very efficient since the number of Gaussian Processes (GP) operations (e.g. inverting the inducing point's covariance matrix) do not depend on the number of processes. This makes the ETGP particularly suited for multi-class problems with a very large number of classes, which are the problems studied in this work. ETGPs exploit the recently proposed Transformed Gaussian Process (TGP), a stochastic process specified by transforming a Gaussian Process using an invertible transformation. However, unlike TGPs, ETGPs are constructed by transforming a single sample from a GP using C invertible transformations. We derive an efficient sparse variational inference algorithm for the proposed model and demonstrate its utility in 5 classification tasks which include low/medium/large datasets and a different number of classes, ranging from just a few to hundreds. Our results show that ETGPs, in general, outperform state-of-the-art methods for multi-class classification based on GPs, and have a lower computational cost (around one order of magnitude smaller).},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Maroñas_Hernández-Lobato_2022_Efficient Transformed Gaussian Processes for Non-Stationary Dependent.pdf;/Users/lichengk/Zotero/storage/NA6ZQWJ6/2205.html}
}

@inproceedings{maronasTransformingGaussianProcesses2021,
  title = {Transforming {{Gaussian Processes With Normalizing Flows}}},
  booktitle = {Proceedings of {{The}} 24th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Maro{\~n}as, Juan and Hamelijnck, Oliver and Knoblauch, Jeremias and Damoulas, Theodoros},
  year = {2021},
  month = mar,
  pages = {1081--1089},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-12-12},
  abstract = {Gaussian Processes (GP) can be used as flexible, non-parametric function priors. Inspired by the growing body of work on Normalizing Flows, we enlarge this class of priors through a parametric invertible transformation that can be made input-dependent. Doing so also allows us to encode interpretable prior knowledge (e.g., boundedness constraints). We derive a variational approximation to the resulting Bayesian inference problem, which is as fast as stochastic variational GP regression (Hensman et al., 2013; Dezfouli and Bonilla, 2015). This makes the model a computationally efficient alternative to other hierarchical extensions of GP priors (L\'azaro-Gredilla,2012; Damianou and Lawrence,2013). The resulting algorithm's computational and inferential performance is excellent, and we demonstrate this on a range of data sets. For example, even with only 5 inducing points and an input-dependent flow, our method is consistently competitive with a standard sparse GP fitted using 100 inducing points.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Maroñas et al_2021_Transforming Gaussian Processes With Normalizing Flows.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Maroñas et al_2021_Transforming Gaussian Processes With Normalizing Flows2.pdf}
}

@article{martensNewInsightsPerspectives2020,
  title = {New Insights and Perspectives on the Natural Gradient Method},
  author = {Martens, James},
  year = {2020},
  month = sep,
  journal = {arXiv:1412.1193 [cs, stat]},
  eprint = {1412.1193},
  primaryclass = {cs, stat},
  urldate = {2022-03-18},
  abstract = {Natural gradient descent is an optimization method traditionally motivated from the perspective of information geometry, and works well for many applications as an alternative to stochastic gradient descent. In this paper we critically analyze this method and its properties, and show how it can be viewed as a type of 2nd-order optimization method, with the Fisher information matrix acting as a substitute for the Hessian. In many important cases, the Fisher information matrix is shown to be equivalent to the Generalized Gauss-Newton matrix, which both approximates the Hessian, but also has certain properties that favor its use over the Hessian. This perspective turns out to have significant implications for the design of a practical and robust natural gradient optimizer, as it motivates the use of techniques like trust regions and Tikhonov regularization. Additionally, we make a series of contributions to the understanding of natural gradient and 2nd-order methods, including: a thorough analysis of the convergence speed of stochastic natural gradient descent (and more general stochastic 2nd-order methods) as applied to convex quadratics, a critical examination of the oft-used "empirical" approximation of the Fisher matrix, and an analysis of the (approximate) parameterization invariance property possessed by natural gradient methods (which we show also holds for certain other curvature, but notably not the Hessian).},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Martens_2020_New insights and perspectives on the natural gradient method.pdf;/Users/lichengk/Zotero/storage/3AHSI75V/1412.html}
}

@article{martensOptimizingNeuralNetworks2020,
  title = {Optimizing {{Neural Networks}} with {{Kronecker-factored Approximate Curvature}}},
  author = {Martens, James and Grosse, Roger},
  year = {2020},
  month = jun,
  journal = {arXiv:1503.05671 [cs, stat]},
  eprint = {1503.05671},
  primaryclass = {cs, stat},
  urldate = {2022-03-21},
  abstract = {We propose an efficient method for approximating natural gradient descent in neural networks which we call Kronecker-Factored Approximate Curvature (K-FAC). K-FAC is based on an efficiently invertible approximation of a neural network's Fisher information matrix which is neither diagonal nor low-rank, and in some cases is completely non-sparse. It is derived by approximating various large blocks of the Fisher (corresponding to entire layers) as being the Kronecker product of two much smaller matrices. While only several times more expensive to compute than the plain stochastic gradient, the updates produced by K-FAC make much more progress optimizing the objective, which results in an algorithm that can be much faster than stochastic gradient descent with momentum in practice. And unlike some previously proposed approximate natural-gradient/Newton methods which use high-quality non-diagonal curvature matrices (such as Hessian-free optimization), K-FAC works very well in highly stochastic optimization regimes. This is because the cost of storing and inverting K-FAC's approximation to the curvature matrix does not depend on the amount of data used to estimate it, which is a feature typically associated only with diagonal or low-rank approximations to the curvature matrix.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Martens_Grosse_2020_Optimizing Neural Networks with Kronecker-factored Approximate Curvature.pdf;/Users/lichengk/Zotero/storage/6FTIJGG4/1503.html}
}

@article{martinez-cantinFunneledBayesianOptimization2019,
  title = {Funneled {{Bayesian Optimization}} for {{Design}}, {{Tuning}} and {{Control}} of {{Autonomous Systems}}},
  author = {{Martinez-Cantin}, Ruben},
  year = {2019},
  month = feb,
  journal = {arXiv:1610.00366 [cs, stat]},
  eprint = {1610.00366},
  primaryclass = {cs, stat},
  urldate = {2021-08-11},
  abstract = {Bayesian optimization has become a fundamental global optimization algorithm in many problems where sample efficiency is of paramount importance. Recently, there has been proposed a large number of new applications in fields such as robotics, machine learning, experimental design, simulation, etc. In this paper, we focus on several problems that appear in robotics and autonomous systems: algorithm tuning, automatic control and intelligent design. All those problems can be mapped to global optimization problems. However, they become hard optimization problems. Bayesian optimization internally uses a probabilistic surrogate model (e.g.: Gaussian process) to learn from the process and reduce the number of samples required. In order to generalize to unknown functions in a black-box fashion, the common assumption is that the underlying function can be modeled with a stationary process. Nonstationary Gaussian process regression cannot generalize easily and it typically requires prior knowledge of the function. Some works have designed techniques to generalize Bayesian optimization to nonstationary functions in an indirect way, but using techniques originally designed for regression, where the objective is to improve the quality of the surrogate model everywhere. Instead optimization should focus on improving the surrogate model near the optimum. In this paper, we present a novel kernel function specially designed for Bayesian optimization, that allows nonstationary behavior of the surrogate model in an adaptive local region. In our experiments, we found that this new kernel results in an improved local search (exploitation), without penalizing the global search (exploration). We provide results in well-known benchmarks and real applications. The new method outperforms the state of the art in Bayesian optimization both in stationary and nonstationary problems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Martinez-Cantin_2019_Funneled Bayesian Optimization for Design, Tuning and Control of Autonomous.pdf;/Users/lichengk/Zotero/storage/NNFWRUJI/1610.html}
}

@inproceedings{masegosaLearningModelMisspecification2020,
  title = {Learning under {{Model Misspecification}}: {{Applications}} to {{Variational}} and {{Ensemble}} Methods},
  shorttitle = {Learning under {{Model Misspecification}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Masegosa, Andres},
  year = {2020},
  volume = {33},
  pages = {5479--5491},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-12-12},
  abstract = {Virtually any model we use in machine learning to make predictions does not perfectly represent reality. So, most of the learning happens under model misspecification. In this work, we present a novel analysis of the generalization performance of Bayesian model averaging under model misspecification and i.i.d. data using a new family of second-order PAC-Bayes bounds. This analysis shows, in simple and intuitive terms, that Bayesian model averaging provides suboptimal generalization performance when the model is misspecified. In consequence, we provide strong theoretical arguments showing that Bayesian methods are not optimal for learning predictive models, unless the model class is perfectly specified. Using novel second-order PAC-Bayes bounds, we derive a new family of Bayesian-like algorithms, which can be implemented as variational and ensemble methods. The output of these algorithms is a new posterior distribution, different from the Bayesian posterior, which induces a posterior predictive distribution with better generalization performance. Experiments with Bayesian neural networks illustrate these findings.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Masegosa_2020_Learning under Model Misspecification.pdf}
}

@incollection{mastroianniErrorEstimatesGaussLaguerre1994,
  title = {Error {{Estimates}} for {{Gauss-Laguerre}} and {{Gauss-Hermite Quadrature Formulas}}},
  booktitle = {Approximation and {{Computation}}: {{A Festschrift}} in {{Honor}} of {{Walter Gautschi}}},
  author = {Mastroianni, G. and Monegato, G.},
  editor = {Zahar, R. V. M.},
  year = {1994},
  pages = {421--434},
  publisher = {{Birkh\"auser Boston}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4684-7415-2_28},
  urldate = {2021-10-05},
  abstract = {New error estimates are derived for Gauss-Laguerre and Gauss-Hermite m-point quadrature formulas; they are of the type O(m- r / 2 )lIxr / 2 f(r)x"e- x IILl and O(m-r/2) IIf(r)e- Qx2 I1L " 0 {$<$} q {$<$} 1, respectively, for functions J in suitable function classes.},
  isbn = {978-1-4684-7417-6 978-1-4684-7415-2},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Mastroianni_Monegato_1994_Error Estimates for Gauss-Laguerre and Gauss-Hermite Quadrature Formulas.pdf}
}

@misc{matthewsContinualRepeatedAnnealed2022,
  title = {Continual {{Repeated Annealed Flow Transport Monte Carlo}}},
  author = {Matthews, Alexander G. D. G. and Arbel, Michael and Rezende, Danilo J. and Doucet, Arnaud},
  year = {2022},
  month = jun,
  number = {arXiv:2201.13117},
  eprint = {2201.13117},
  primaryclass = {cond-mat, physics:hep-lat, stat},
  publisher = {{arXiv}},
  urldate = {2022-12-06},
  abstract = {We propose Continual Repeated Annealed Flow Transport Monte Carlo (CRAFT), a method that combines a sequential Monte Carlo (SMC) sampler (itself a generalization of Annealed Importance Sampling) with variational inference using normalizing flows. The normalizing flows are directly trained to transport between annealing temperatures using a KL divergence for each transition. This optimization objective is itself estimated using the normalizing flow/SMC approximation. We show conceptually and using multiple empirical examples that CRAFT improves on Annealed Flow Transport Monte Carlo (Arbel et al., 2021), on which it builds and also on Markov chain Monte Carlo (MCMC) based Stochastic Normalizing Flows (Wu et al., 2020). By incorporating CRAFT within particle MCMC, we show that such learnt samplers can achieve impressively accurate results on a challenging lattice field theory example.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Statistical Mechanics,High Energy Physics - Lattice,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/CH8VMNGB/Matthews et al. - 2022 - Continual Repeated Annealed Flow Transport Monte C.pdf;/Users/lichengk/Zotero/storage/4KCNJ6TH/2201.html}
}

@inproceedings{matthewsSparseVariationalMethods2016,
  title = {On {{Sparse Variational Methods}} and the {{Kullback-Leibler Divergence}} between {{Stochastic Processes}}},
  booktitle = {{{AISTATS}}},
  author = {Matthews, A. G. D. G. and Hensman, J. and Turner, Richard E. and Ghahramani, Zoubin},
  year = {2016},
  doi = {10.17863/CAM.15597},
  abstract = {A substantial generalization of the literature on variational framework for learning inducing variables is given and a new proof of the result for infinite index sets is given which allows inducing points that are not data points and likelihoods that depend on all function values. The variational framework for learning inducing variables (Titsias, 2009a) has had a large impact on the Gaussian process literature. The framework may be interpreted as minimizing a rigorously defined Kullback-Leibler divergence between the approximating and posterior processes. To our knowledge this connection has thus far gone unremarked in the literature. In this paper we give a substantial generalization of the literature on this topic. We give a new proof of the result for infinite index sets which allows inducing points that are not data points and likelihoods that depend on all function values. We then discuss augmented index sets and show that, contrary to previous works, marginal consistency of augmentation is not enough to guarantee consistency of variational inference with the original model. We then characterize an extra condition where such a guarantee is obtainable. Finally we show how our framework sheds light on interdomain sparse approximations and sparse approximations for Cox processes.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Matthews et al_2016_On Sparse Variational Methods and the Kullback-Leibler Divergence between.pdf}
}

@article{mattosArtGaussianProcesses,
  title = {The {{Art}} of {{Gaussian Processes}}: {{Classical}} and {{Contemporary}}},
  author = {Mattos, C{\'e}sar Lincoln C and Tobar, Felipe},
  pages = {216},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/ALCHE2K7/Mattos and Tobar - The Art of Gaussian Processes Classical and Conte.pdf}
}

@misc{MaximumMeanDiscrepancy,
  title = {Maximum {{Mean Discrepancy}} ({{MMD}}) in {{Machine Learning}}},
  urldate = {2023-05-27},
  howpublished = {https://www.onurtunali.com/ml/2019/03/08/maximum-mean-discrepancy-in-machine-learning.html},
  file = {/Users/lichengk/Zotero/storage/LVQDVK65/maximum-mean-discrepancy-in-machine-learning.html}
}

@article{mchutchonDifferentiatingGaussianProcesses,
  title = {Differentiating {{Gaussian Processes}}},
  author = {McHutchon, Andrew},
  pages = {8},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/QWN2MM7X/McHutchon - Diﬀerentiating Gaussian Processes.pdf}
}

@article{mcintireSparseGaussianProcesses,
  title = {Sparse {{Gaussian Processes}} for {{Bayesian Optimization}}},
  author = {McIntire, Mitchell and Ratner, Daniel and Ermon, Stefano},
  pages = {10},
  abstract = {Bayesian optimization schemes often rely on Gaussian processes (GP). GP models are very flexible, but are known to scale poorly with the number of training points. While several efficient sparse GP models are known, they have limitations when applied in optimization settings.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/UKCTKRJH/McIntire et al. - Sparse Gaussian Processes for Bayesian Optimizatio.pdf}
}

@article{mckenneyParallelProgrammingHard,
  title = {Is {{Parallel Programming Hard}}, {{And}}, {{If So}}, {{What Can You Do About It}}?},
  author = {McKenney, Paul E},
  pages = {630},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/McKenney_Is Parallel Programming Hard, And, If So, What Can You Do About It.pdf}
}

@article{melbourneDifferentialEntropyMixtures2020,
  title = {The {{Differential Entropy}} of {{Mixtures}}: {{New Bounds}} and {{Applications}}},
  shorttitle = {The {{Differential Entropy}} of {{Mixtures}}},
  author = {Melbourne, James and Talukdar, Saurav and Bhaban, Shreyas and Madiman, Mokshay and Salapaka, Murti V.},
  year = {2020},
  month = apr,
  journal = {arXiv:1805.11257 [cs, math]},
  eprint = {1805.11257},
  primaryclass = {cs, math},
  urldate = {2021-06-17},
  abstract = {Mixture distributions are extensively used as a modeling tool in diverse areas from machine learning to communications engineering to physics, and obtaining bounds on the entropy of probability distributions is of fundamental importance in many of these applications. This article provides sharp bounds on the entropy concavity deficit, which is the difference between the entropy of the mixture and the weighted sum of entropies of constituent components. Toward establishing lower and upper bounds on the concavity deficit, results that are of importance in their own right are obtained. In order to obtain nontrivial upper bounds, properties of the skew-divergence are developed and notions of "skew" \$f\$-divergences are introduced; a reverse Pinsker inequality and a bound on Jensen-Shannon divergence are obtained along the way. Complementary lower bounds are derived with special attention paid to the case that corresponds to independent summation of a continuous and a discrete random variable. Several applications of the bounds are delineated, including to mutual information of additive noise channels, thermodynamics of computation, and functional inequalities.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Information Theory,Mathematics - Probability},
  annotation = {5 citations (Semantic Scholar/arXiv) [2021-06-17]},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Melbourne et al_2020_The Differential Entropy of Mixtures.pdf;/Users/lichengk/Zotero/storage/AQ46DQXP/1805.html}
}

@misc{midgleyFlowAnnealedImportance2022,
  title = {Flow {{Annealed Importance Sampling Bootstrap}}},
  author = {Midgley, Laurence Illing and Stimper, Vincent and Simm, Gregor N. C. and Sch{\"o}lkopf, Bernhard and {Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel},
  year = {2022},
  month = nov,
  number = {arXiv:2208.01893},
  eprint = {2208.01893},
  primaryclass = {cs, q-bio, stat},
  publisher = {{arXiv}},
  urldate = {2022-12-06},
  abstract = {Normalizing flows are tractable density models that can approximate complicated target distributions, e.g. Boltzmann distributions of physical systems. However, current methods for training flows either suffer from mode-seeking behavior, use samples from the target generated beforehand by expensive MCMC simulations, or use stochastic losses that have high variance. To avoid these problems, we augment flows with annealed importance sampling (AIS) and minimize the mass-covering \$\textbackslash alpha\$-divergence with \$\textbackslash alpha=2\$, which minimizes importance weight variance. Our method, Flow AIS Bootstrap (FAB), uses AIS to generate samples in regions where the flow is a poor approximation of the target, facilitating the discovery of new modes. We apply FAB to complex multimodal targets and show that we can approximate them very accurately where previous methods fail. To the best of our knowledge, we are the first to learn the Boltzmann distribution of the alanine dipeptide molecule using only the unnormalized target density, without access to samples generated via Molecular Dynamics (MD) simulations: FAB produces better results than training via maximum likelihood on MD samples while using 100 times fewer target evaluations. After reweighting samples with importance weights, we obtain unbiased histograms of dihedral angles that are almost identical to the ground truth.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/QI8V9LIK/Midgley et al. - 2022 - Flow Annealed Importance Sampling Bootstrap.pdf;/Users/lichengk/Zotero/storage/FGGNKF5F/2208.html}
}

@article{milgromEnvelopeTheoremsArbitrary2002,
  title = {Envelope {{Theorems}} for {{Arbitrary Choice Sets}}},
  author = {Milgrom, Paul and Segal, Ilya},
  year = {2002},
  journal = {Econometrica},
  volume = {70},
  number = {2},
  pages = {583--601},
  issn = {1468-0262},
  doi = {10.1111/1468-0262.00296},
  urldate = {2021-05-27},
  abstract = {The standard envelope theorems apply to choice sets with convex and topological structure, providing sufficient conditions for the value function to be differentiable in a parameter and characterizing its derivative. This paper studies optimization with arbitrary choice sets and shows that the traditional envelope formula holds at any differentiability point of the value function. We also provide conditions for the value function to be, variously, absolutely continuous, left- and right-differentiable, or fully differentiable. These results are applied to mechanism design, convex programming, continuous optimization problems, saddle-point problems, problems with parameterized constraints, and optimal stopping problems.},
  copyright = {The Econometric Society 2002},
  langid = {english},
  keywords = {differentiable value function,envelope theorem,math programming,mechanism design,sensitivity analysis},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Milgrom_Segal_2002_Envelope Theorems for Arbitrary Choice Sets.pdf;/Users/lichengk/Zotero/storage/FY4YV23N/1468-0262.html}
}

@article{millerMixtureModelsPrior2015,
  title = {Mixture Models with a Prior on the Number of Components},
  author = {Miller, Jeffrey W. and Harrison, Matthew T.},
  year = {2015},
  month = feb,
  journal = {arXiv:1502.06241 [stat]},
  eprint = {1502.06241},
  primaryclass = {stat},
  urldate = {2021-09-22},
  abstract = {A natural Bayesian approach for mixture models with an unknown number of components is to take the usual finite mixture model with Dirichlet weights, and put a prior on the number of components---that is, to use a mixture of finite mixtures (MFM). While inference in MFMs can be done with methods such as reversible jump Markov chain Monte Carlo, it is much more common to use Dirichlet process mixture (DPM) models because of the relative ease and generality with which DPM samplers can be applied. In this paper, we show that, in fact, many of the attractive mathematical properties of DPMs are also exhibited by MFMs---a simple exchangeable partition distribution, restaurant process, random measure representation, and in certain cases, a stick-breaking representation. Consequently, the powerful methods developed for inference in DPMs can be directly applied to MFMs as well. We illustrate with simulated and real data, including high-dimensional gene expression data.},
  archiveprefix = {arxiv},
  keywords = {ObsCite,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Miller_Harrison_2015_Mixture models with a prior on the number of components.pdf;/Users/lichengk/Zotero/storage/EVQKJ42T/1502.html}
}

@inproceedings{millerVariationalBoostingIteratively2017,
  title = {Variational Boosting: {{Iteratively}} Refining Posterior Approximations},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  author = {Miller, Andrew C. and Foti, Nicholas J. and Adams, Ryan P.},
  editor = {Precup, Doina and Teh, Yee Whye},
  year = {2017},
  month = aug,
  series = {Proceedings of Machine Learning Research},
  volume = {70},
  pages = {2420--2429},
  publisher = {{PMLR}},
  abstract = {We propose a black-box variational inference method to approximate intractable distributions with an increasingly rich approximating class. Our method, variational boosting, iteratively refines an existing variational approximation by solving a sequence of optimization problems, allowing a trade-off between computation time and accuracy. We expand the variational approximating class by incorporating additional covariance structure and by introducing new components to form a mixture. We apply variational boosting to synthetic and real statistical models, and show that the resulting posterior inferences compare favorably to existing variational algorithms.},
  pdf = {http://proceedings.mlr.press/v70/miller17a/miller17a.pdf},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Miller et al_2017_Variational boosting.pdf}
}

@article{mingardSGDBayesianSampler2021,
  title = {Is {{SGD}} a Bayesian Sampler? {{Well}}, Almost},
  author = {Mingard, Chris and {Valle-P{\'e}rez}, Guillermo and Skalse, Joar and Louis, Ard A.},
  year = {2021},
  journal = {Journal of Machine Learning Research},
  volume = {22},
  number = {79},
  pages = {1--64},
  file = {/Users/lichengk/Zotero/storage/8LLPQQ75/Mingard et al. - Is SGD a Bayesian sampler Well, almost..pdf}
}

@misc{minhMercerTheoremFeature,
  title = {Mercer's {{Theorem}}, {{Feature Maps}}, and {{Smoothing}}},
  author = {Minh, Ha Quang and Niyogi, Partha and Yao, Yuan},
  abstract = {Abstract. We study Mercer's theorem and feature maps for several positive definite kernels that are widely used in practice. The smoothing properties of these kernels will also be explored. 1},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Minh et al_Mercer’s Theorem, Feature Maps, and Smoothing.pdf;/Users/lichengk/Zotero/storage/SVY5EPMJ/summary.html}
}

@article{minkaComparisonNumericalOptimizers,
  title = {A Comparison of Numerical Optimizers for Logistic Regression},
  author = {Minka, Thomas P},
  abstract = {Logistic regression is a workhorse of statistics and is closely related to methods used in Machine Learning, including the Perceptron and the Support Vector Machine. This note compares eight different algorithms for computing the maximum a-posteriori parameter estimate. A full derivation of each algorithm is given. In particular, a new derivation of Iterative Scaling is given which applies more generally than the conventional one. A new derivation is also given for the Modified Iterative Scaling algorithm of Collins et al. (2002). Most of the algorithms operate in the primal space, but can also work in dual space. All algorithms are compared in terms of computational complexity by experiments on large data sets. The fastest algorithms turn out to be conjugate gradient ascent and quasi-Newton algorithms, which far outstrip Iterative Scaling and its variants.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Minka_A comparison of numerical optimizers for logistic regression.pdf}
}

@techreport{minkaDerivingQuadratureRules2000,
  title = {Deriving Quadrature Rules from Gaussian Processes},
  author = {Minka, Tom},
  year = {2000},
  month = jun,
  abstract = {Quadrature rules are often designed to achieve zero error on a small set of functions, e.g. polynomials of specified degree. A more robust method is to minimize average error over a large class or distribution of functions. If functions are distributed according to a Gaussian process, then designing an average-case quadrature rule reduces to solving a system of 2n equations, where n is the number of nodes in the rule (O'Hagan, 1991). It is shown how this very general technique can be used to design customized quadrature rules, in the style of Yarvin \&amp; Rokhlin (1998), without the need for singular value decomposition and in any number of dimensions. It is also shown how classical Gaussian quadrature rules, trigonometric lattice rules, and spline rules can be extended to the average-case and to multiple dimensions by deriving them from Gaussian processes. In addition to being more robust, multidimensional quadrature rules designed for the average-case are found to be much less ambiguous than those designed for a given polynomial degree.},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Minka_2000_Deriving quadrature rules from gaussian processes.pdf}
}

@misc{mlssafricaNeilLawrenceGaussian2019,
  title = {Neil {{Lawrence}} - {{Gaussian Processes Part}} 1},
  author = {{MLSS Africa}},
  year = {2019},
  month = jan,
  urldate = {2021-06-02},
  abstract = {5,190次观看 \textbullet{} 2019年1月10日 \textbullet{} https://mlssafrica.com/                   收起                   展开}
}

@misc{MonteCarloTheory,
  title = {Monte {{Carlo}} Theory, Methods and Examples},
  urldate = {2021-06-28},
  howpublished = {https://statweb.stanford.edu/\textasciitilde owen/mc/},
  file = {/Users/lichengk/Zotero/storage/AM8K8YKT/mc.html}
}

@inproceedings{morningstarPACmBayesNarrowingEmpirical2022,
  title = {{{PACm-Bayes}}: {{Narrowing}} the {{Empirical Risk Gap}} in the {{Misspecified Bayesian Regime}}},
  shorttitle = {{{PACm-Bayes}}},
  booktitle = {Proceedings of {{The}} 25th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Morningstar, Warren R. and Alemi, Alex and Dillon, Joshua V.},
  year = {2022},
  month = may,
  pages = {8270--8298},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-12-12},
  abstract = {The Bayesian posterior minimizes the "inferential risk" which itself bounds the "predictive risk." This bound is tight when the likelihood and prior are well-specified. How-ever since misspecification induces a gap,the Bayesian posterior predictive distribution may have poor generalization performance. This work develops a multi-sample loss (PAC\$\^m\$) which can close the gap by spanning a trade-off between the two risks. The loss is computationally favorable and offers PAC generalization guarantees. Empirical study demonstrates improvement to the predictive distribution},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Morningstar et al_2022_PACm-Bayes.pdf}
}

@article{muandetKernelMeanEmbedding2017,
  title = {Kernel Mean Embedding of Distributions: {{A}} Review and Beyond},
  author = {Muandet, K. and Fukumizu, K. and Sriperumbudur, B. and Sch{\"o}lkopf, B.},
  year = {2017},
  journal = {Foundations and Trends in Machine Learning},
  volume = {10},
  number = {1-2},
  pages = {1--141},
  doi = {10.1561/2200000060},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Muandet et al_2017_Kernel Mean Embedding of Distributions.pdf}
}

@book{murphyMachineLearningProbabilistic2012,
  title = {Machine Learning: A Probabilistic Perspective},
  shorttitle = {Machine Learning},
  author = {Murphy, Kevin P.},
  year = {2012},
  series = {Adaptive Computation and Machine Learning Series},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA}},
  isbn = {978-0-262-01802-9},
  langid = {english},
  lccn = {Q325.5 .M87 2012},
  keywords = {Machine learning,Probabilities},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Murphy_2012_Machine learning.pdf}
}

@book{murphyProbabilisticMachineLearning2021,
  title = {Probabilistic Machine Learning: {{An}} Introduction},
  author = {Murphy, Kevin P.},
  year = {2021},
  publisher = {{MIT Press}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Murphy_2021_Probabilistic machine learning.pdf}
}

@inproceedings{murrayAddressingBiasActive2022,
  title = {Addressing {{Bias}} in {{Active Learning}} with {{Depth Uncertainty Networks}}... or {{Not}}},
  booktitle = {I ({{Still}}) {{Can}}'t {{Believe It}}'s {{Not Better}}! {{Workshop}} at {{NeurIPS}} 2021},
  author = {Murray, Chelsea and Allingham, James U. and Antor{\'a}n, Javier and {Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel},
  year = {2022},
  month = feb,
  pages = {59--63},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-12-19},
  abstract = {Farquhar et al. [2021] show that correcting for active learning bias with underparameterised models leads to improved downstream performance. For overparameterised models such as NNs, however, correction leads either to decreased or unchanged performance. They suggest that this is due to an ``overfitting bias'' which offsets the active learning bias. We show that depth uncertainty networks operate in a low overfitting regime, much like underparameterised models. They should therefore see an increase in performance with bias correction. Surprisingly, they do not. We propose that this negative result, as well as the results Farquhar et al. [2021], can be explained via the lens of the bias-variance decomposition of generalisation error.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Murray et al_2022_Addressing Bias in Active Learning with Depth Uncertainty Networks.pdf;/Users/lichengk/Zotero/storage/G7I8CPZX/Murray et al. - 2022 - Addressing Bias in Active Learning with Depth Unce.pdf}
}

@misc{murrayDepthUncertaintyNetworks2022,
  title = {Depth {{Uncertainty Networks}} for {{Active Learning}}},
  author = {Murray, Chelsea and Allingham, James U. and Antor{\'a}n, Javier and {Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel},
  year = {2022},
  month = may,
  number = {arXiv:2112.06796},
  eprint = {2112.06796},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-11-09},
  abstract = {In active learning, the size and complexity of the training dataset changes over time. Simple models that are well specified by the amount of data available at the start of active learning might suffer from bias as more points are actively sampled. Flexible models that might be well suited to the full dataset can suffer from overfitting towards the start of active learning. We tackle this problem using Depth Uncertainty Networks (DUNs), a BNN variant in which the depth of the network, and thus its complexity, is inferred. We find that DUNs outperform other BNN variants on several active learning tasks. Importantly, we show that on the tasks in which DUNs perform best they present notably less overfitting than baselines.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Murray et al_2022_Depth Uncertainty Networks for Active Learning.pdf;/Users/lichengk/Zotero/storage/JC4YQNHF/2112.html}
}

@article{murrayPseudoMarginalSliceSampling,
  title = {Pseudo-{{Marginal Slice Sampling}}},
  author = {Murray, Iain and Graham, Matthew M},
  pages = {9},
  abstract = {Markov chain Monte Carlo (MCMC) methods asymptotically sample from complex probability distributions. The pseudo-marginal MCMC framework only requires an unbiased estimator of the unnormalized probability distribution function to construct a Markov chain. However, the resulting chains are harder to tune to a target distribution than conventional MCMC, and the types of updates available are limited. We describe a general way to clamp and update the random numbers used in a pseudo-marginal method's unbiased estimator. In this framework we can use slice sampling and other adaptive methods. We obtain more robust Markov chains, which often mix more quickly.},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/Zotero/storage/8PU3K43C/Murray and Graham - Pseudo-Marginal Slice Sampling.pdf}
}

@inproceedings{mutnyEfficientHighDimensional2018,
  title = {Efficient {{High Dimensional Bayesian Optimization}} with {{Additivity}} and {{Quadrature Fourier Features}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Mutny, Mojmir and Krause, Andreas},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2021-10-04},
  file = {/Users/lichengk/Zotero/storage/Q45LH4CR/Mutny and Krause - 2018 - Efficient High Dimensional Bayesian Optimization w.pdf}
}

@inproceedings{mutnyEfficientHighDimensional2018a,
  title = {Efficient {{High Dimensional Bayesian Optimization}} with {{Additivity}} and {{Quadrature Fourier Features}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Mutny, Mojmir and Krause, Andreas},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-04-11},
  abstract = {We develop an efficient and provably no-regret Bayesian optimization (BO) algorithm for optimization of black-box functions in high dimensions. We assume a generalized additive model with possibly overlapping variable groups. When the groups do not overlap, we are able to provide the first provably no-regret \textbackslash emph\{polynomial time\} (in the number of evaluations of the acquisition function) algorithm for solving high dimensional BO. To make the optimization efficient and feasible, we introduce a novel deterministic Fourier Features approximation based on numerical integration with detailed analysis for the squared exponential kernel. The error of this approximation decreases \textbackslash emph\{exponentially\} with the number of features, and allows for a precise approximation of both posterior mean and variance. In addition, the kernel matrix inversion improves in its complexity from cubic to essentially linear in the number of data points measured in basic arithmetic operations.},
  keywords = {toread},
  file = {/Users/lichengk/Zotero/storage/IAPTUSQ5/Mutny and Krause - 2018 - Efficient High Dimensional Bayesian Optimization w.pdf}
}

@phdthesis{nealBayesianLearningNeural1996,
  title = {Bayesian {{Learning}} for {{Neural Networks}}},
  author = {Neal, Radford M.},
  year = {1996},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4612-0745-0},
  urldate = {2022-02-08},
  abstract = {Two features distinguish the Bayesian approach to learning models from data. First, beliefs derived from background knowledge are used to select a prior probability distribution for the model parameters. Second, predictions of future observations are made by integrating the model's predictions with respect to the posterior parameter distribution obtained by updating this prior to take account of the data. For neural network models, both these aspects present di culties | the prior over network parameters has no obvious relation to our prior knowledge, and integration over the posterior is computationally very demanding.},
  collaborator = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S.},
  langid = {english},
  school = {Springer New York},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Neal_1996_Bayesian Learning for Neural Networks.pdf}
}

@book{nealBayesianLearningNeural1996a,
  title = {Bayesian {{Learning}} for {{Neural Networks}}},
  author = {Neal, Radford M.},
  editor = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S.},
  year = {1996},
  series = {Lecture {{Notes}} in {{Statistics}}},
  volume = {118},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4612-0745-0},
  urldate = {2023-06-02},
  isbn = {978-0-387-94724-2 978-1-4612-0745-0},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Neal_1996_Bayesian Learning for Neural Networks2.pdf}
}

@article{nealMCMCUsingHamiltonian2011,
  title = {{{MCMC}} Using {{Hamiltonian}} Dynamics},
  author = {Neal, Radford M.},
  year = {2011},
  month = may,
  journal = {arXiv:1206.1901 [physics, stat]},
  eprint = {1206.1901},
  primaryclass = {physics, stat},
  doi = {10.1201/b10905},
  urldate = {2021-08-16},
  abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard-to-compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, I discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for deciding on acceptance or rejection, computing trajectories using fast approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories from taking much computation time.},
  archiveprefix = {arxiv},
  keywords = {Physics - Computational Physics,Statistics - Computation},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Neal_2011_MCMC using Hamiltonian dynamics.pdf;/Users/lichengk/Zotero/storage/K3FK3CXD/1206.html}
}

@article{nealSliceSampling2003,
  title = {Slice Sampling},
  author = {Neal, Radford M.},
  year = {2003},
  month = jun,
  journal = {The Annals of Statistics},
  volume = {31},
  number = {3},
  pages = {705--767},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1056562461},
  urldate = {2021-10-26},
  abstract = {Markov chain sampling methods that adapt to characteristics of the distribution being sampled can be constructed using the principle that one can ample from a distribution by sampling uniformly from the region under the plot of its density function. A Markov chain that converges to this uniform distribution can be constructed by alternating uniform sampling in the vertical direction with uniform sampling from the horizontal "slice" defined by the current vertical position, or more generally, with some update that leaves the uniform distribution over this slice invariant. Such "slice sampling" methods are easily implemented for univariate distributions, and can be used to sample from a multivariate distribution by updating each variable in turn. This approach is often easier to implement than Gibbs sampling and more efficient than simple Metropolis updates, due to the ability of slice sampling to adaptively choose the magnitude of changes made. It is therefore attractive for routine and automated use. Slice sampling methods that update all variables simultaneously are also possible. These methods can adaptively choose the magnitudes of changes made to each variable, based on the local properties of the density function. More ambitiously, such methods could potentially adapt to the dependencies between variables by constructing local quadratic approximations. Another approach is to improve sampling efficiency by suppressing random walks. This can be done for univariate slice sampling by "overrelaxation," and for multivariate slice sampling by "reflection" from the edges of the slice.},
  keywords = {65C05,65C60,Adaptive methods,auxiliary variables,dynamical methods,Gibbs sampling,Markov chain Monte Carlo,Metropolis algorithm,overrelaxation},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Neal_2003_Slice sampling.pdf;/Users/lichengk/Zotero/storage/5TWVNXUX/1056562461.html}
}

@article{nguyenKnowingWhatNot,
  title = {Knowing {{The What But Not The Where}} in {{Bayesian Optimization}}},
  author = {Nguyen, Vu and Osborne, Michael A},
  pages = {10},
  langid = {english}
}

@misc{nguyenVariationalContinualLearning2018,
  title = {Variational {{Continual Learning}}},
  author = {Nguyen, Cuong V. and Li, Yingzhen and Bui, Thang D. and Turner, Richard E.},
  year = {2018},
  month = may,
  number = {arXiv:1710.10628},
  eprint = {1710.10628},
  primaryclass = {cs, stat},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.1710.10628},
  urldate = {2022-05-31},
  abstract = {This paper develops variational continual learning (VCL), a simple but general framework for continual learning that fuses online variational inference (VI) and recent advances in Monte Carlo VI for neural networks. The framework can successfully train both deep discriminative models and deep generative models in complex continual learning settings where existing tasks evolve over time and entirely new tasks emerge. Experimental results show that VCL outperforms state-of-the-art continual learning methods on a variety of tasks, avoiding catastrophic forgetting in a fully automatic way.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/ZR76CIVG/Nguyen et al. - 2018 - Variational Continual Learning.pdf;/Users/lichengk/Zotero/storage/CFGGU8MH/1710.html}
}

@book{nielsenQuantumComputationQuantum2010,
  title = {Quantum Computation and Quantum Information},
  author = {Nielsen, Michael A. and Chuang, Isaac L.},
  year = {2010},
  edition = {10th anniversary ed},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge ; New York}},
  isbn = {978-1-107-00217-3},
  langid = {english},
  lccn = {QA76.889 .N54 2010},
  keywords = {Quantum computers},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Nielsen_Chuang_2010_Quantum computation and quantum information.pdf}
}

@book{nocedalNumericalOptimization2006,
  title = {Numerical Optimization},
  author = {Nocedal, Jorge and Wright, Stephen J.},
  year = {2006},
  series = {Springer Series in Operations Research},
  edition = {2nd ed},
  publisher = {{Springer}},
  address = {{New York}},
  isbn = {978-0-387-30303-1},
  langid = {english},
  lccn = {QA402.5 .N62 2006},
  keywords = {Mathematical optimization},
  annotation = {OCLC: ocm68629100},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Nocedal_Wright_2006_Numerical optimization.pdf}
}

@misc{novakNeuralTangentsFast2019,
  title = {Neural {{Tangents}}: {{Fast}} and {{Easy Infinite Neural Networks}} in {{Python}}},
  shorttitle = {Neural {{Tangents}}},
  author = {Novak, Roman and Xiao, Lechao and Hron, Jiri and Lee, Jaehoon and Alemi, Alexander A. and {Sohl-Dickstein}, Jascha and Schoenholz, Samuel S.},
  year = {2019},
  month = dec,
  number = {arXiv:1912.02803},
  eprint = {1912.02803},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-06-05},
  abstract = {Neural Tangents is a library designed to enable research into infinite-width neural networks. It provides a high-level API for specifying complex and hierarchical neural network architectures. These networks can then be trained and evaluated either at finite-width as usual or in their infinite-width limit. Infinite-width networks can be trained analytically using exact Bayesian inference or using gradient descent via the Neural Tangent Kernel. Additionally, Neural Tangents provides tools to study gradient descent training dynamics of wide but finite networks in either function space or weight space. The entire library runs out-of-the-box on CPU, GPU, or TPU. All computations can be automatically distributed over multiple accelerators with near-linear scaling in the number of devices. Neural Tangents is available at www.github.com/google/neural-tangents. We also provide an accompanying interactive Colab notebook.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Novak et al_2019_Neural Tangents.pdf;/Users/lichengk/Zotero/storage/WAWEA5U9/1912.html}
}

@misc{NuancesProbabilityTheory,
  title = {Nuances of Probability Theory},
  urldate = {2023-04-24},
  howpublished = {https://tminka.github.io/papers/nuances.html},
  file = {/Users/lichengk/Zotero/storage/ZHGGRVC8/nuances.html}
}

@article{oatesModernRetrospectiveProbabilistic2019,
  title = {A Modern Retrospective on Probabilistic Numerics},
  author = {Oates, C. J. and Sullivan, T. J.},
  year = {2019},
  month = nov,
  journal = {Statistics and Computing},
  volume = {29},
  number = {6},
  pages = {1335--1351},
  issn = {1573-1375},
  doi = {10.1007/s11222-019-09902-z},
  urldate = {2021-10-06},
  abstract = {This article attempts to place the emergence of probabilistic numerics as a mathematical\textendash statistical research field within its historical context and to explore how its gradual development can be related both to applications and to a modern formal treatment. We highlight in particular the parallel contributions of Sul\$\$'\$\$din and Larkin in the 1960s and how their pioneering early ideas have reached a degree of maturity in the intervening period, mediated by paradigms such as average-case analysis and information-based complexity. We provide a subjective assessment of the state of research in probabilistic numerics and highlight some difficulties to be addressed by future works.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Oates_Sullivan_2019_A modern retrospective on probabilistic numerics.pdf}
}

@misc{oberPromisesPitfallsDeep2021,
  title = {The {{Promises}} and {{Pitfalls}} of {{Deep Kernel Learning}}},
  author = {Ober, Sebastian W. and Rasmussen, Carl E. and {van der Wilk}, Mark},
  year = {2021},
  month = jul,
  number = {arXiv:2102.12108},
  eprint = {2102.12108},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-10-28},
  abstract = {Deep kernel learning (DKL) and related techniques aim to combine the representational power of neural networks with the reliable uncertainty estimates of Gaussian processes. One crucial aspect of these models is an expectation that, because they are treated as Gaussian process models optimized using the marginal likelihood, they are protected from overfitting. However, we identify situations where this is not the case. We explore this behavior, explain its origins and consider how it applies to real datasets. Through careful experimentation on the UCI, CIFAR-10, and the UTKFace datasets, we find that the overfitting from overparameterized maximum marginal likelihood, in which the model is "somewhat Bayesian", can in certain scenarios be worse than that from not being Bayesian at all. We explain how and when DKL can still be successful by investigating optimization dynamics. We also find that failures of DKL can be rectified by a fully Bayesian treatment, which leads to the desired performance improvements over standard neural networks and Gaussian processes.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/Z8WL45G8/Ober et al. - 2021 - The Promises and Pitfalls of Deep Kernel Learning.pdf;/Users/lichengk/Zotero/storage/8H6IK3KR/2102.html}
}

@article{ohaganBayesHermiteQuadrature1991,
  title = {Bayes\textendash{{Hermite}} Quadrature},
  author = {O'Hagan, A.},
  year = {1991},
  month = nov,
  journal = {Journal of Statistical Planning and Inference},
  volume = {29},
  number = {3},
  pages = {245--260},
  issn = {03783758},
  doi = {10.1016/0378-3758(91)90002-V},
  urldate = {2021-09-23},
  abstract = {Bayesian quadrature treats the problem of numerical integration as one of statistical inference. A prior Gaussian process distribution is assumed for the integrand, observations arise from evaluating the integrand at selected points, and a posterior distribution is derived for the integrand and the integral. Methods are developed for quadrature in IRP. A particular application is integrating the posterior density arising from some other Bayesian analysis. Simulation results are presented, to show that the resulting Bayes-Hermite quadrature rules may perform better than the conventional Gauss-Hermite rules for this application. A key result is derived for product designs, which makes Bayesian quadrature practically useful for integrating in several dimensions. Although the method does not at present provide a solution to the more difficult problem of quadrature in high dimensions, it does seem to offer real improvements over existing methods in relatively low dimensions.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/YCW3GP2E/O'Hagan - 1991 - Bayes–Hermite quadrature.pdf}
}

@article{olivaBayesianNonparametricKernelLearning2016,
  title = {Bayesian {{Nonparametric Kernel-Learning}}},
  author = {Oliva, Junier B and Dubey, Avinava and Wilson, Andrew G and Poczos, Barnabas and Schneider, Jeff and Xing, Eric P},
  year = {2016},
  pages = {9},
  abstract = {Kernel methods are ubiquitous tools in machine learning. However, there is often little reason for the common practice of selecting a kernel a priori. Even if a universal approximating kernel is selected, the quality of the finite sample estimator may be greatly affected by the choice of kernel. Furthermore, when directly applying kernel methods, one typically needs to compute a N \texttimes N Gram matrix of pairwise kernel evaluations to work with a dataset of N instances. The computation of this Gram matrix precludes the direct application of kernel methods on large datasets, and makes kernel learning especially difficult. In this paper we introduce Bayesian nonparmetric kernel-learning (BaNK), a generic, data-driven framework for scalable learning of kernels. BaNK places a nonparametric prior on the spectral distribution of random frequencies allowing it to both learn kernels and scale to large datasets. We show that this framework can be used for large scale regression and classification tasks. Furthermore, we show that BaNK outperforms several other scalable approaches for kernel learning on a variety of real world datasets.},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Oliva et al_2016_Bayesian Nonparametric Kernel-Learning.pdf}
}

@inproceedings{oliveiraNoregretApproximateInference2021,
  title = {No-Regret Approximate Inference via {{Bayesian}} Optimisation},
  booktitle = {Proceedings of the {{Thirty-Seventh Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  author = {Oliveira, Rafael and Ott, Lionel and Ramos, Fabio},
  year = {2021},
  month = dec,
  pages = {2082--2092},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-04-12},
  abstract = {We consider Bayesian inference problems where the likelihood function is either expensive to evaluate or only available via noisy estimates. This setting encompasses application scenarios involving, for example, large datasets or models whose likelihood evaluations require expensive simulations. We formulate this problem within a Bayesian optimisation framework over a space of probability distributions and derive an upper confidence bound (UCB) algorithm to propose non-parametric distribution candidates. The algorithm is designed to minimise regret, which is defined as the Kullback-Leibler divergence with respect to the true posterior in this case. Equipped with a Gaussian process surrogate model, we show that the resulting UCB algorithm achieves asymptotically no regret. The method can be easily implemented as a batch Bayesian optimisation algorithm whose point evaluations are selected via Markov chain Monte Carlo. Experimental results demonstrate the method's performance on inference problems.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/Zotero/storage/GV5DIHCX/Oliveira et al. - 2021 - No-regret approximate inference via Bayesian optim.pdf;/Users/lichengk/Zotero/storage/SL4M53KA/Oliveira et al. - 2021 - No-regret approximate inference via Bayesian optim.pdf}
}

@article{oneillExchangeabilityCorrelationBayes2009,
  title = {Exchangeability, {{Correlation}}, and {{Bayes}}' {{Effect}}},
  author = {O'Neill, Ben},
  year = {2009},
  journal = {International Statistical Review},
  volume = {77},
  number = {2},
  pages = {241--250},
  issn = {1751-5823},
  doi = {10.1111/j.1751-5823.2008.00059.x},
  urldate = {2023-05-26},
  abstract = {We examine the difference between Bayesian and frequentist statistics in making statements about the relationship between observable values. We show how standard models under both paradigms can be based on an assumption of exchangeability and we derive useful covariance and correlation results for values from an exchangeable sequence. We find that such values are never negatively correlated, and are generally positively correlated under the models used in Bayesian statistics. We discuss the significance of this result as well as a phenomenon which often follows from the differing methodologies and practical applications of these paradigms \textendash{} a phenomenon we call Bayes' effect.},
  langid = {english},
  keywords = {Bayes' effect,Bayesian statistics,correlation,exchangeability,frequentist statistics,independence,pseudo-correlation},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/O'Neill_2009_Exchangeability, Correlation, and Bayes' Effect.pdf;/Users/lichengk/Zotero/storage/SX7VEGAC/j.1751-5823.2008.00059.html}
}

@article{opheusdenUnbiasedEfficientLoglikelihood2020,
  title = {Unbiased and Efficient Log-Likelihood Estimation with Inverse Binomial Sampling},
  author = {van Opheusden, Bas and Acerbi, Luigi and Ma, Wei Ji},
  year = {2020年12月23日},
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {12},
  pages = {e1008483},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008483},
  urldate = {2022-08-18},
  abstract = {The fate of scientific hypotheses often relies on the ability of a computational model to explain the data, quantified in modern statistical approaches by the likelihood function. The log-likelihood is the key element for parameter estimation and model evaluation. However, the log-likelihood of complex models in fields such as computational biology and neuroscience is often intractable to compute analytically or numerically. In those cases, researchers can often only estimate the log-likelihood by comparing observed data with synthetic observations generated by model simulations. Standard techniques to approximate the likelihood via simulation either use summary statistics of the data or are at risk of producing substantial biases in the estimate. Here, we explore another method, inverse binomial sampling (IBS), which can estimate the log-likelihood of an entire data set efficiently and without bias. For each observation, IBS draws samples from the simulator model until one matches the observation. The log-likelihood estimate is then a function of the number of samples drawn. The variance of this estimator is uniformly bounded, achieves the minimum variance for an unbiased estimator, and we can compute calibrated estimates of the variance. We provide theoretical arguments in favor of IBS and an empirical assessment of the method for maximum-likelihood estimation with simulation-based models. As case studies, we take three model-fitting problems of increasing complexity from computational and cognitive neuroscience. In all problems, IBS generally produces lower error in the estimated parameters and maximum log-likelihood values than alternative sampling methods with the same average number of samples. Our results demonstrate the potential of IBS as a practical, robust, and easy to implement method for log-likelihood evaluation when exact techniques are not available.},
  langid = {english},
  keywords = {Algorithms,Decision making,Maximum likelihood estimation,Normal distribution,Probability distribution,Sensory perception,Simulation and modeling,Statistical models},
  file = {/Users/lichengk/Zotero/storage/5IWLD976/Opheusden et al. - 2020 - Unbiased and efficient log-likelihood estimation w.pdf;/Users/lichengk/Zotero/storage/MTNWFJKX/article.html}
}

@article{opheusdenUnbiasedEfficientLoglikelihood2020a,
  title = {Unbiased and Efficient Log-Likelihood Estimation with Inverse Binomial Sampling},
  author = {van Opheusden, Bas and Acerbi, Luigi and Ma, Wei Ji},
  year = {2020},
  month = dec,
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {12},
  pages = {e1008483},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008483},
  urldate = {2022-10-20},
  abstract = {The fate of scientific hypotheses often relies on the ability of a computational model to explain the data, quantified in modern statistical approaches by the likelihood function. The log-likelihood is the key element for parameter estimation and model evaluation. However, the log-likelihood of complex models in fields such as computational biology and neuroscience is often intractable to compute analytically or numerically. In those cases, researchers can often only estimate the log-likelihood by comparing observed data with synthetic observations generated by model simulations. Standard techniques to approximate the likelihood via simulation either use summary statistics of the data or are at risk of producing substantial biases in the estimate. Here, we explore another method, inverse binomial sampling (IBS), which can estimate the log-likelihood of an entire data set efficiently and without bias. For each observation, IBS draws samples from the simulator model until one matches the observation. The log-likelihood estimate is then a function of the number of samples drawn. The variance of this estimator is uniformly bounded, achieves the minimum variance for an unbiased estimator, and we can compute calibrated estimates of the variance. We provide theoretical arguments in favor of IBS and an empirical assessment of the method for maximum-likelihood estimation with simulation-based models. As case studies, we take three model-fitting problems of increasing complexity from computational and cognitive neuroscience. In all problems, IBS generally produces lower error in the estimated parameters and maximum log-likelihood values than alternative sampling methods with the same average number of samples. Our results demonstrate the potential of IBS as a practical, robust, and easy to implement method for log-likelihood evaluation when exact techniques are not available.},
  langid = {english},
  keywords = {Algorithms,Decision making,Maximum likelihood estimation,Normal distribution,Probability distribution,Sensory perception,Simulation and modeling,Statistical models},
  file = {/Users/lichengk/Zotero/storage/UMVDVGYS/Opheusden et al. - 2020 - Unbiased and efficient log-likelihood estimation w.pdf;/Users/lichengk/Zotero/storage/7T59JY2L/article.html}
}

@article{opperVariationalGaussianApproximation2009,
  title = {The {{Variational Gaussian Approximation Revisited}}},
  author = {Opper, Manfred and Archambeau, C{\'e}dric},
  year = {2009},
  month = mar,
  journal = {Neural Computation},
  volume = {21},
  number = {3},
  pages = {786--792},
  issn = {0899-7667},
  doi = {10.1162/neco.2008.08-07-592},
  urldate = {2022-02-08},
  abstract = {The variational approximation of posterior distributions by multivariate gaussians has been much less popular in the machine learning community compared to the corresponding approximation by factorizing distributions. This is for a good reason: the gaussian approximation is in general plagued by an  number of variational parameters to be optimized, N being the number of random variables. In this letter, we discuss the relationship between the Laplace and the variational approximation, and we show that for models with gaussian priors and factorizing likelihoods, the number of variational parameters is actually . The approach is applied to gaussian process regression with nongaussian likelihoods.},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Opper_Archambeau_2009_The Variational Gaussian Approximation Revisited.pdf;/Users/lichengk/Zotero/storage/BAZ4P52T/The-Variational-Gaussian-Approximation-Revisited.html}
}

@inproceedings{osborneActiveLearningModel2012,
  title = {Active Learning of Model Evidence Using Bayesian Quadrature},
  booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
  author = {Osborne, Michael A. and Duvenaud, David and Garnett, Roman and Rasmussen, Carl E. and Roberts, Stephen J. and Ghahramani, Zoubin},
  year = {2012},
  series = {{{NIPS}}'12},
  pages = {46--54},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  abstract = {Numerical integration is a key component of many problems in scientific computing, statistical modelling, and machine learning. Bayesian Quadrature is a modelbased method for numerical integration which, relative to standard Monte Carlo methods, offers increased sample efficiency and a more robust estimate of the uncertainty in the estimated integral. We propose a novel Bayesian Quadrature approach for numerical integration when the integrand is non-negative, such as the case of computing the marginal likelihood, predictive distribution, or normalising constant of a probabilistic model. Our approach approximately marginalises the quadrature model's hyperparameters in closed form, and introduces an active learning scheme to optimally select function evaluations, as opposed to using Monte Carlo samples. We demonstrate our method on both a number of synthetic benchmarks and a real scientific problem from astronomy.},
  keywords = {bayesian quadrature,ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Osborne et al_2012_Active learning of model evidence using bayesian quadrature.pdf}
}

@book{osborneCourseGameTheory1994,
  title = {A Course in Game Theory},
  author = {Osborne, Martin J. and Rubinstein, Ariel},
  year = {1994},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-15041-5 978-0-262-65040-3},
  langid = {english},
  lccn = {HB144 .O733 1994},
  keywords = {Game theory},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Osborne_Rubinstein_1994_A course in game theory.pdf}
}

@misc{ottBayesianNumericalIntegration2023,
  title = {Bayesian {{Numerical Integration}} with {{Neural Networks}}},
  author = {Ott, Katharina and Tiemann, Michael and Hennig, Philipp and Briol, Fran{\c c}ois-Xavier},
  year = {2023},
  month = may,
  number = {arXiv:2305.13248},
  eprint = {2305.13248},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-05-25},
  abstract = {Bayesian probabilistic numerical methods for numerical integration offer significant advantages over their non-Bayesian counterparts: they can encode prior information about the integrand, and can quantify uncertainty over estimates of an integral. However, the most popular algorithm in this class, Bayesian quadrature, is based on Gaussian process models and is therefore associated with a high computational cost. To improve scalability, we propose an alternative approach based on Bayesian neural networks which we call Bayesian Stein networks. The key ingredients are a neural network architecture based on Stein operators, and an approximation of the Bayesian posterior based on the Laplace approximation. We show that this leads to orders of magnitude speed-ups on the popular Genz functions benchmark, and on challenging problems arising in the Bayesian analysis of dynamical systems, and the prediction of energy production for a large-scale wind farm.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Ott et al_2023_Bayesian Numerical Integration with Neural Networks.pdf;/Users/lichengk/Zotero/storage/64Z6BUCH/2305.html}
}

@article{pacchiardiScoreMatchedNeural,
  title = {Score {{Matched Neural Exponential Families}} for {{Likelihood-Free Inference}}},
  author = {Pacchiardi, Lorenzo and Dutta, Ritabrata},
  pages = {71},
  abstract = {Bayesian Likelihood-Free Inference (LFI) approaches allow to obtain posterior distributions for stochastic models with intractable likelihood, by relying on model simulations. In Approximate Bayesian Computation (ABC), a popular LFI method, summary statistics are used to reduce data dimensionality. ABC algorithms adaptively tailor simulations to the observation in order to sample from an approximate posterior, whose form depends on the chosen statistics. In this work, we introduce a new way to learn ABC statistics: we first generate parameter-simulation pairs from the model independently on the observation; then, we use Score Matching to train a neural conditional exponential family to approximate the likelihood. The exponential family is the largest class of distributions with fixed-size sufficient statistics; thus, we use them in ABC, which is intuitively appealing and has state-of-the-art performance. In parallel, we insert our likelihood approximation in an MCMC for doubly intractable distributions to draw posterior samples. We can repeat that for any number of observations with no additional model simulations, with performance comparable to related approaches. We validate our methods on toy models with known likelihood and a large-dimensional time-series model.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/YCDBV4S3/Pacchiardi and Dutta - Score Matched Neural Exponential Families for Like.pdf}
}

@article{padidarScalingGaussianProcesses,
  title = {Scaling {{Gaussian Processes}} with {{Derivative Information Using Variational Inference}}},
  author = {Padidar, Misha and Zhu, Xinran and Huang, Leo},
  pages = {12},
  abstract = {Gaussian processes with derivative information are useful in many settings where derivative information is available, including numerous Bayesian optimization and regression tasks that arise in the natural sciences. Incorporating derivative observations, however, comes with a dominating O(N 3D3) computational cost when training on N points in D input dimensions. This is intractable for even moderately sized problems. While recent work has addressed this intractability in the low-D setting, the high-N , high-D setting is still unexplored and of great value, particularly as machine learning problems increasingly become high dimensional. In this paper, we introduce methods to achieve fully scalable Gaussian process regression with derivatives using variational inference. Analogous to the use of inducing values to sparsify the labels of a training set, we introduce the concept of inducing directional derivatives to sparsify the partial derivative information of a training set. This enables us to construct a variational posterior that incorporates derivative information but whose size depends neither on the full dataset size N nor the full dimensionality D. We demonstrate the full scalability of our approach on a variety of tasks, ranging from a high dimensional stellarator fusion regression task to training graph convolutional neural networks on Pubmed using Bayesian optimization. Surprisingly, we find that our approach can improve regression performance even in settings where only label data is available.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Padidar et al_Scaling Gaussian Processes with Derivative Information Using Variational.pdf}
}

@misc{papamakariosMaskedAutoregressiveFlow2018,
  title = {Masked {{Autoregressive Flow}} for {{Density Estimation}}},
  author = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
  year = {2018},
  month = jun,
  number = {arXiv:1705.07057},
  eprint = {1705.07057},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1705.07057},
  urldate = {2023-01-23},
  abstract = {Autoregressive models are among the best performing neural density estimators. We describe an approach for increasing the flexibility of an autoregressive model, based on modelling the random numbers that the model uses internally when generating data. By constructing a stack of autoregressive models, each modelling the random numbers of the next model in the stack, we obtain a type of normalizing flow suitable for density estimation, which we call Masked Autoregressive Flow. This type of flow is closely related to Inverse Autoregressive Flow and is a generalization of Real NVP. Masked Autoregressive Flow achieves state-of-the-art performance in a range of general-purpose density estimation tasks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Papamakarios et al_2018_Masked Autoregressive Flow for Density Estimation.pdf;/Users/lichengk/Zotero/storage/9MNU5ZS8/1705.html}
}

@phdthesis{papamakariosNeuralDensityEstimation2019,
  title = {Neural {{Density Estimation}} and {{Likelihood-free Inference}}},
  author = {Papamakarios, George},
  year = {2019},
  month = oct,
  eprint = {1910.13233},
  primaryclass = {cs, stat},
  urldate = {2023-01-16},
  abstract = {I consider two problems in machine learning and statistics: the problem of estimating the joint probability density of a collection of random variables, known as density estimation, and the problem of inferring model parameters when their likelihood is intractable, known as likelihood-free inference. The contribution of the thesis is a set of new methods for addressing these problems that are based on recent advances in neural networks and deep learning.},
  archiveprefix = {arxiv},
  school = {arXiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/F7J66PKB/Papamakarios - 2019 - Neural Density Estimation and Likelihood-free Infe.pdf;/Users/lichengk/Zotero/storage/R48C9IDS/1910.html}
}

@article{papamakariosNormalizingFlowsProbabilistic,
  title = {Normalizing {{Flows}} for {{Probabilistic Modeling}} and {{Inference}}},
  author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  pages = {64},
  abstract = {Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Papamakarios et al_Normalizing Flows for Probabilistic Modeling and Inference.pdf}
}

@inproceedings{papamakariosSequentialNeuralLikelihood2019,
  title = {Sequential {{Neural Likelihood}}: {{Fast Likelihood-free Inference}} with {{Autoregressive Flows}}},
  shorttitle = {Sequential {{Neural Likelihood}}},
  booktitle = {Proceedings of the {{Twenty-Second International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Papamakarios, George and Sterratt, David and Murray, Iain},
  year = {2019},
  month = apr,
  pages = {837--848},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-01-16},
  abstract = {We present Sequential Neural Likelihood (SNL), a new method for Bayesian inference in simulator models, where the likelihood is intractable but simulating data from the model is possible. SNL trains an autoregressive flow on simulated data in order to learn a model of the likelihood in the region of high posterior density. A sequential training procedure guides simulations and reduces simulation cost by orders of magnitude. We show that SNL is more robust, more accurate and requires less tuning than related neural-based methods, and we discuss diagnostics for assessing calibration, convergence and goodness-of-fit.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/K5ZSIGNV/Papamakarios et al. - 2019 - Sequential Neural Likelihood Fast Likelihood-free.pdf}
}

@book{papoulisProbabilityRandomVariables2009,
  title = {Probability, Random Variables, and Stochastic Processes},
  author = {Papoulis, Athanasios and Pillai, S. Unnikrishna},
  year = {2009},
  edition = {4. ed., internat. ed., Nachdr},
  publisher = {{McGraw-Hill}},
  address = {{Boston, Mass.}},
  isbn = {978-0-07-122661-5 978-0-07-112256-6},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Papoulis_Pillai_2009_Probability, random variables, and stochastic processes.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Papoulis_Pillai_2009_Probability, random variables, and stochastic processes2.pdf}
}

@article{paszkePyTorchImperativeStyle,
  title = {{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  pages = {12},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Paszke et al_PyTorch.pdf}
}

@article{patelReviewWearableSensors2012,
  title = {A Review of Wearable Sensors and Systems with Application in Rehabilitation},
  author = {Patel, Shyamal and Park, Hyung and Bonato, Paolo and Chan, Leighton and Rodgers, Mary},
  year = {2012},
  month = apr,
  journal = {Journal of NeuroEngineering and Rehabilitation},
  volume = {9},
  number = {1},
  pages = {21},
  issn = {1743-0003},
  doi = {10.1186/1743-0003-9-21},
  urldate = {2023-04-04},
  abstract = {The aim of this review paper is to summarize recent developments in the field of wearable sensors and systems that are relevant to the field of rehabilitation. The growing body of work focused on the application of wearable technology to monitor older adults and subjects with chronic conditions in the home and community settings justifies the emphasis of this review paper on summarizing clinical applications of wearable technology currently undergoing assessment rather than describing the development of new wearable sensors and systems. A short description of key enabling technologies (i.e. sensor technology, communication technology, and data analysis techniques) that have allowed researchers to implement wearable systems is followed by a detailed description of major areas of application of wearable technology. Applications described in this review paper include those that focus on health and wellness, safety, home rehabilitation, assessment of treatment efficacy, and early detection of disorders. The integration of wearable and ambient sensors is discussed in the context of achieving home monitoring of older adults and subjects with chronic conditions. Future work required to advance the field toward clinical deployment of wearable sensors and systems is discussed.},
  keywords = {可穿戴传感器和系统,家庭监控,智能家居,远程医疗},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Patel et al_2012_A review of wearable sensors and systems with application in rehabilitation.pdf;/Users/lichengk/Zotero/storage/RSKKFKUC/1743-0003-9-21.html}
}

@misc{PatternDiscoveryGaussian,
  title = {Pattern {{Discovery}} with {{Gaussian Processes}}},
  urldate = {2021-11-25},
  howpublished = {https://cims.nyu.edu/\textasciitilde andrewgw/pattern/\#Kronecker},
  file = {/Users/lichengk/Zotero/storage/ACXDJSVG/pattern.html}
}

@article{paulRobustReinforcementLearning2020,
  title = {Robust {{Reinforcement Learning}} with {{Bayesian Optimisation}} and {{Quadrature}}},
  author = {Paul, Supratik and Chatzilygeroudis, Konstantinos and Ciosek, Kamil and Mouret, Jean-Baptiste and Osborne, Michael and Whiteson, Shimon},
  year = {2020},
  journal = {Journal of Machine Learning Research},
  volume = {21},
  pages = {1--31},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Paul et al_2020_Robust Reinforcement Learning with Bayesian Optimisation and Quadrature.pdf}
}

@book{paulsenIntroductionTheoryReproducing2016,
  title = {An {{Introduction}} to the {{Theory}} of {{Reproducing Kernel Hilbert Spaces}}},
  author = {Paulsen, Vern I. and Raghupathi, Mrinal},
  year = {2016},
  month = apr,
  edition = {First},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9781316219232},
  urldate = {2023-03-31},
  abstract = {Reproducing kernel Hilbert spaces have developed into an important tool in many areas, especially statistics and machine learning, and they play a valuable role in complex analysis, probability, group representation theory, and the theory of integral operators. This unique text offers a unified overview of the topic, providing detailed examples of applications, as well as covering the fundamental underlying theory, including chapters on interpolation and approximation, Cholesky and Schur operations on kernels, and vector-valued spaces. Self-contained and accessibly written, with exercises at the end of each chapter, this unrivalled treatment of the topic serves as an ideal introduction for graduate students across mathematics, computer science, and engineering, as well as a useful reference for researchers working in functional analysis or its applications.},
  isbn = {978-1-107-10409-9 978-1-316-21923-2},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Paulsen_Raghupathi_2016_An Introduction to the Theory of Reproducing Kernel Hilbert Spaces.pdf}
}

@book{petersenMatrixCookbook,
  title = {The Matrix Cookbook},
  author = {Petersen, Kaare Brandt and Pedersen, Michael Syskind},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Petersen_Pedersen_The matrix cookbook.pdf}
}

@misc{petitRelaxedGaussianProcess2022,
  title = {Relaxed {{Gaussian}} Process Interpolation: A Goal-Oriented Approach to {{Bayesian}} Optimization},
  shorttitle = {Relaxed {{Gaussian}} Process Interpolation},
  author = {Petit, S{\'e}bastien and Bect, Julien and Vazquez, Emmanuel},
  year = {2022},
  month = jun,
  number = {arXiv:2206.03034},
  eprint = {2206.03034},
  primaryclass = {stat},
  institution = {{arXiv}},
  urldate = {2022-06-15},
  abstract = {This work presents a new procedure for obtaining predictive distributions in the context of Gaussian process (GP) modeling, with a relaxation of the interpolation constraints outside some ranges of interest: the mean of the predictive distributions no longer necessarily interpolates the observed values when they are outside ranges of interest, but are simply constrained to remain outside. This method called relaxed Gaussian process (reGP) interpolation provides better predictive distributions in ranges of interest, especially in cases where a stationarity assumption for the GP model is not appropriate. It can be viewed as a goal-oriented method and becomes particularly interesting in Bayesian optimization, for example, for the minimization of an objective function, where good predictive distributions for low function values are important. When the expected improvement criterion and reGP are used for sequentially choosing evaluation points, the convergence of the resulting optimization algorithm is theoretically guaranteed (provided that the function to be optimized lies in the reproducing kernel Hilbert spaces attached to the known covariance of the underlying Gaussian process). Experiments indicate that using reGP instead of stationary GP models in Bayesian optimization is beneficial.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology,toread},
  file = {/Users/lichengk/Zotero/storage/P8I6GBHK/Petit et al. - 2022 - Relaxed Gaussian process interpolation a goal-ori.pdf;/Users/lichengk/Zotero/storage/GSWWXFRE/2206.html}
}

@article{peyreComputationalOptimalTransport2020,
  title = {Computational {{Optimal Transport}}},
  author = {Peyr{\'e}, Gabriel and Cuturi, Marco},
  year = {2020},
  month = mar,
  journal = {arXiv:1803.00567 [stat]},
  eprint = {1803.00567},
  primaryclass = {stat},
  urldate = {2022-01-31},
  abstract = {Optimal transport (OT) theory can be informally described using the words of the French mathematician Gaspard Monge (1746-1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in OT cast that problem as that of comparing two probability distributions, two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a "global" cost to every such transport, using the "local" consideration of how much it costs to move a grain of sand from one place to another. Recent years have witnessed the spread of OT in several fields, thanks to the emergence of approximate solvers that can scale to sizes and dimensions that are relevant to data sciences. Thanks to this newfound scalability, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), computer vision and graphics (for shape manipulation) or machine learning (for regression, classification and density fitting). This short book reviews OT with a bias toward numerical methods and their applications in data sciences, and sheds lights on the theoretical properties of OT that make it particularly useful for some of these applications.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/LTDK5469/Peyré and Cuturi - 2020 - Computational Optimal Transport.pdf;/Users/lichengk/Zotero/storage/8TYDJ2NW/1803.html}
}

@inproceedings{pinslerBayesianBatchActive2019,
  title = {Bayesian {{Batch Active Learning}} as {{Sparse Subset Approximation}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Pinsler, Robert and Gordon, Jonathan and Nalisnick, Eric and {Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel},
  year = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-10-24},
  abstract = {Leveraging the wealth of unlabeled data produced in recent years provides great potential for improving supervised models. When the cost of acquiring labels is high, probabilistic active learning methods can be used to greedily select the most informative data points to be labeled. However, for many large-scale problems standard greedy procedures become computationally infeasible and suffer from negligible model change. In this paper, we introduce a novel Bayesian batch active learning approach that mitigates these issues. Our approach is motivated by approximating the complete data posterior of the model parameters. While naive batch construction methods result in correlated queries, our algorithm produces diverse batches that enable efficient active learning at scale. We derive interpretable closed-form solutions akin to existing active learning procedures for linear models, and generalize to arbitrary models using random projections. We demonstrate the benefits of our approach on several large-scale regression and classification tasks.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Pinsler et al_2019_Bayesian Batch Active Learning as Sparse Subset Approximation.pdf}
}

@book{plataniotisGaussianMixturesTheir2000,
  title = {Gaussian Mixtures and Their Applications to Signal Processing},
  author = {Plataniotis, Konstantinos and Hatzinakos, D.},
  year = {2000},
  month = jan,
  abstract = {There are a number of engineering applications in which a function should be estimated from data. Mixtures of distributions, especially Gaussian mixtures, have been used extensively as models in such problems where data can be viewed as arising from two or more populations mixed in varying proportions. 1-3 The objective of this chapter is to highlight the use of mixture models as a way to provide efficient and accurate solutions to problems of important engineering significance. Using the Gaussian mixture formulation, problems are treated from a global viewpoint that readily yields and unifies previous, seemingly unrelated results. This chapter reviews the existing methodologies, examines current trends, provides connections with other methodologies and practices, and discusses application areas.},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Plataniotis_Hatzinakos_2000_Gaussian mixtures and their applications to signal processing.pdf}
}

@book{pml2Book,
  title = {Probabilistic Machine Learning: {{Advanced}} Topics},
  author = {Murphy, Kevin P.},
  year = {2023},
  publisher = {{MIT Press}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Murphy_2023_Probabilistic machine learning.pdf}
}

@book{pollardUserGuideMeasure2001,
  title = {A {{User}}'s {{Guide}} to {{Measure Theoretic Probability}}},
  author = {Pollard, David},
  year = {2001},
  month = dec,
  edition = {First},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9780511811555},
  urldate = {2022-07-25},
  isbn = {978-0-521-00289-9 978-0-521-80242-0 978-0-511-81155-5},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Pollard_2001_A User's Guide to Measure Theoretic Probability.pdf}
}

@inproceedings{poloczekMultiinformationSourceOptimization2017,
  title = {Multi-Information Source Optimization},
  booktitle = {Proceedings of the 31st {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Poloczek, Matthias and Wang, Jialei and Frazier, Peter I.},
  year = {2017},
  month = dec,
  series = {{{NIPS}}'17},
  pages = {4291--4301},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  urldate = {2021-06-01},
  abstract = {We consider Bayesian methods for multi-information source optimization (MISO), in which we seek to optimize an expensive-to-evaluate black-box objective function while also accessing cheaper but biased and noisy approximations ("information sources"). We present a novel algorithm that outperforms the state of the art for this problem by using a Gaussian process covariance kernel better suited to MISO than those used by previous approaches, and an acquisition function based on a one-step optimality analysis supported by efficient parallelization. We also provide a novel technique to guarantee the asymptotic quality of the solution provided by this algorithm. Experimental evaluations demonstrate that this algorithm consistently finds designs of higher value at less cost than previous approaches.},
  isbn = {978-1-5108-6096-4},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Poloczek et al_2017_Multi-information source optimization.pdf}
}

@misc{PrincipledBayesianWorkflow,
  title = {Towards {{A Principled Bayesian Workflow}}},
  urldate = {2023-05-03},
  howpublished = {https://betanalpha.github.io/assets/case\_studies/principled\_bayesian\_workflow.html\#113\_Prior\_Predictive\_Checks},
  keywords = {toread},
  file = {/Users/lichengk/Zotero/storage/229GMSRV/principled_bayesian_workflow.html}
}

@book{ProbabilityStatisticsCookbook2011,
  title = {Probability and {{Statistics Cookbook}}},
  year = {2011},
  urldate = {2021-07-08},
  file = {/Users/lichengk/Zotero/storage/6QS3QCQ3/cookbook-en.pdf}
}

@article{quinonero-candelaUnifyingViewSparse2005,
  title = {A Unifying View of Sparse Approximate Gaussian Process Regression},
  author = {{Qui{\~n}onero-Candela}, Joaquin and Rasmussen, Carl Edward},
  year = {2005},
  journal = {Journal of Machine Learning Research},
  volume = {6},
  number = {65},
  pages = {1939--1959},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Quiñonero-Candela_Rasmussen_2005_A unifying view of sparse approximate gaussian process regression.pdf}
}

@article{rabinowitzTablesAbscissasWeights,
  title = {Tables of {{Abscissas}} and {{Weights}} for {{Numerical}}},
  author = {Rabinowitz, Philip and Weiss, George},
  pages = {10},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Rabinowitz_Weiss_Tables of Abscissas and Weights for Numerical.pdf}
}

@misc{radevBayesFlowLearningComplex2020,
  title = {{{BayesFlow}}: {{Learning}} Complex Stochastic Models with Invertible Neural Networks},
  shorttitle = {{{BayesFlow}}},
  author = {Radev, Stefan T. and Mertens, Ulf K. and Voss, Andreass and Ardizzone, Lynton and K{\"o}the, Ullrich},
  year = {2020},
  month = dec,
  number = {arXiv:2003.06281},
  eprint = {2003.06281},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-20},
  abstract = {Estimating the parameters of mathematical models is a common problem in almost all branches of science. However, this problem can prove notably difficult when processes and model descriptions become increasingly complex and an explicit likelihood function is not available. With this work, we propose a novel method for globally amortized Bayesian inference based on invertible neural networks which we call BayesFlow. The method uses simulation to learn a global estimator for the probabilistic mapping from observed data to underlying model parameters. A neural network pre-trained in this way can then, without additional training or optimization, infer full posteriors on arbitrary many real datasets involving the same model family. In addition, our method incorporates a summary network trained to embed the observed data into maximally informative summary statistics. Learning summary statistics from data makes the method applicable to modeling scenarios where standard inference techniques with hand-crafted summary statistics fail. We demonstrate the utility of BayesFlow on challenging intractable models from population dynamics, epidemiology, cognitive science and ecology. We argue that BayesFlow provides a general framework for building amortized Bayesian parameter estimation machines for any forward model from which data can be simulated.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Radev et al_2020_BayesFlow.pdf;/Users/lichengk/Zotero/storage/756JRC6J/2003.html}
}

@inproceedings{rahimiRandomFeaturesLargeScale2008,
  title = {Random {{Features}} for {{Large-Scale Kernel Machines}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Rahimi, Ali and Recht, Benjamin},
  year = {2008},
  volume = {20},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2021-08-16},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Rahimi_Recht_2008_Random Features for Large-Scale Kernel Machines.pdf}
}

@misc{RandomFourierFeatures,
  title = {Random {{Fourier Features}}},
  urldate = {2021-10-25},
  howpublished = {https://gregorygundersen.com/blog/2019/12/23/random-fourier-features/\#sutherland2015error},
  file = {/Users/lichengk/Zotero/storage/GQFVULVH/random-fourier-features.html}
}

@inproceedings{rasmussenBayesianMonteCarlo2002,
  title = {Bayesian {{Monte Carlo}}},
  booktitle = {Proceedings of the 15th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Rasmussen, Carl Edward and Ghahramani, Zoubin},
  year = {2002},
  month = jan,
  series = {{{NIPS}}'02},
  pages = {505--512},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  urldate = {2021-06-09},
  abstract = {We investigate Bayesian alternatives to classical Monte Carlo methods for evaluating integrals. Bayesian Monte Carlo (BMC) allows the incorporation of prior knowledge, such as smoothness of the integrand, into the estimation. In a simple problem we show that this outperforms any classical importance sampling method. We also attempt more challenging multidimensional integrals involved in computing marginal likelihoods of statistical models (a.k.a. partition functions and model evidences). We find that Bayesian Monte Carlo outperformed Annealed Importance Sampling, although for very high dimensional problems or problems with massive multimodality BMC may be less adequate. One advantage of the Bayesian approach to Monte Carlo is that samples can be drawn from any distribution. This allows for the possibility of active design of sample points so as to maximise information gain.},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Rasmussen_Ghahramani_2002_Bayesian Monte Carlo.pdf}
}

@book{rasmussenGaussianProcessesMachine2006,
  title = {Gaussian Processes for Machine Learning},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
  year = {2006},
  series = {Adaptive Computation and Machine Learning},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-18253-9},
  langid = {english},
  lccn = {QA274.4 .R37 2006},
  keywords = {Data processing,Gaussian processes,Machine learning,Mathematical models,ObsCite},
  annotation = {OCLC: ocm61285753},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Rasmussen_Williams_2006_Gaussian processes for machine learning.pdf}
}

@misc{ReferenceRequestDoes,
  title = {Reference Request - {{Does MCMC}} Overcome the Curse of Dimensionality?},
  journal = {MathOverflow},
  urldate = {2021-06-14},
  howpublished = {https://mathoverflow.net/questions/277623/does-mcmc-overcome-the-curse-of-dimensionality},
  file = {/Users/lichengk/Zotero/storage/W5KVAR8K/does-mcmc-overcome-the-curse-of-dimensionality.html}
}

@article{reidInformationDivergenceRisk,
  title = {Information, {{Divergence}} and {{Risk}} for {{Binary Experiments}}},
  author = {Reid, Mark D and Williamson, Robert C and Reid, Mark and Williamson, Bob},
  abstract = {We unify f -divergences, Bregman divergences, surrogate regret bounds, proper scoring rules, cost curves, ROC-curves and statistical information. We do this by systematically studying integral and variational representations of these objects and in so doing identify their representation primitives which all are related to cost-sensitive binary classification. As well as developing relationships between generative and discriminative views of learning, the new machinery leads to tight and more general surrogate regret bounds and generalised Pinsker inequalities relating f -divergences to variational divergence. The new viewpoint also illuminates existing algorithms: it provides a new derivation of Support Vector Machines in terms of divergences and relates maximum mean discrepancy to Fisher linear discriminants.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Reid et al_Information, Divergence and Risk for Binary Experiments.pdf}
}

@article{remesNeuralNonStationarySpectral2018,
  title = {Neural {{Non-Stationary Spectral Kernel}}},
  author = {Remes, Sami and Heinonen, Markus and Kaski, Samuel},
  year = {2018},
  month = nov,
  journal = {arXiv:1811.10978 [cs, stat]},
  eprint = {1811.10978},
  primaryclass = {cs, stat},
  urldate = {2022-01-17},
  abstract = {Standard kernels such as Mat\textbackslash 'ern or RBF kernels only encode simple monotonic dependencies within the input space. Spectral mixture kernels have been proposed as general-purpose, flexible kernels for learning and discovering more complicated patterns in the data. Spectral mixture kernels have recently been generalized into non-stationary kernels by replacing the mixture weights, frequency means and variances by input-dependent functions. These functions have also been modelled as Gaussian processes on their own. In this paper we propose modelling the hyperparameter functions with neural networks, and provide an experimental comparison between the stationary spectral mixture and the two non-stationary spectral mixtures. Scalable Gaussian process inference is implemented within the sparse variational framework for all the kernels considered. We show that the neural variant of the kernel is able to achieve the best performance, among alternatives, on several benchmark datasets.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Remes et al_2018_Neural Non-Stationary Spectral Kernel.pdf;/Users/lichengk/Zotero/storage/X3F99IXW/1811.html}
}

@inproceedings{remesNonStationarySpectralKernels2017,
  title = {Non-{{Stationary Spectral Kernels}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Remes, Sami and Heinonen, Markus and Kaski, Samuel},
  year = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2021-08-08},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Remes et al_2017_Non-Stationary Spectral Kernels.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Remes et al_2017_Non-Stationary Spectral Kernels2.pdf}
}

@article{renshawStatisticalAnalysisFinite1987,
  title = {Statistical {{Analysis}} of {{Finite Mixture Distributions}}},
  author = {Renshaw, Arthur E.},
  year = {1987},
  journal = {Journal of the Royal Statistical Society: Series A (General)},
  volume = {150},
  number = {3},
  pages = {283--283},
  issn = {2397-2327},
  doi = {10.2307/2981482},
  urldate = {2021-09-22},
  abstract = {4. Statistical Analysis of Finite Mixture Distributions. By D. M. Titterington, A. F. M. Smith and H. E. Makov. ISBN 0 471 90763 4. Wiley, 1985. 243p. \textsterling 22.50.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/LEVB3DMV/2981482.html}
}

@unpublished{RequeimaSpectralMethods2018,
  title = {Requeima, {{Spectral Methods}} in {{Gaussian Modelling}}.Pdf},
  year = {2018},
  urldate = {2021-08-16},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/2018_Requeima, Spectral Methods in Gaussian Modelling.pdf}
}

@inproceedings{rezendeVariationalInferenceNormalizing2015,
  title = {Variational Inference with Normalizing Flows},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{International Conference}} on {{Machine Learning}} - {{Volume}} 37},
  author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
  year = {2015},
  month = jul,
  series = {{{ICML}}'15},
  pages = {1530--1538},
  publisher = {{JMLR.org}},
  address = {{Lille, France}},
  urldate = {2021-09-03},
  abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Rezende_Mohamed_2016_Variational Inference with Normalizing Flows.pdf}
}

@article{riisBayesianActiveLearning,
  title = {Bayesian {{Active Learning}} with {{Fully Bayesian Gaussian Processes}}},
  author = {Riis, Christoffer and Antunes, Francisco and H{\"u}ttel, Frederik Boe and Azevedo, Carlos Lima and Pereira, Francisco C{\^a}mara},
  pages = {20},
  abstract = {The bias-variance trade-off is a well-known problem in machine learning that only gets more pronounced the less available data there is. In active learning, where labeled data is scarce or difficult to obtain, neglecting this trade-off can cause inefficient and non-optimal querying, leading to unnecessary data labeling. In this paper, we focus on active learning with Gaussian Processes (GPs). For the GP, the bias-variance trade-off is made by optimization of the two hyperparameters: the length scale and noise-term. Considering that the optimal mode of the joint posterior of the hyperparameters is equivalent to the optimal bias-variance trade-off, we approximate this joint posterior and utilize it to design two new acquisition functions. The first one is a Bayesian variant of Query-by-Committee (B-QBC), and the second is an extension that explicitly minimizes the predictive variance through a Query by Mixture of Gaussian Processes (QB-MGP) formulation. Across six simulators, we empirically show that B-QBC, on average, achieves the best marginal likelihood, whereas QB-MGP achieves the best predictive performance. We show that incorporating the bias-variance trade-off in the acquisition functions mitigates unnecessary and expensive data labeling.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/BDRV5WZR/Riis et al. - Bayesian Active Learning with Fully Bayesian Gauss.pdf}
}

@article{riosDerivativefreeOptimizationReview2013,
  title = {Derivative-Free Optimization: A Review of Algorithms and Comparison of Software Implementations},
  shorttitle = {Derivative-Free Optimization},
  author = {Rios, Luis Miguel and Sahinidis, Nikolaos V.},
  year = {2013},
  month = jul,
  journal = {Journal of Global Optimization},
  volume = {56},
  number = {3},
  pages = {1247--1293},
  issn = {0925-5001, 1573-2916},
  doi = {10.1007/s10898-012-9951-y},
  urldate = {2021-11-01},
  abstract = {This paper addresses the solution of bound-constrained optimization problems using algorithms that require only the availability of objective function values but no derivative information. We refer to these algorithms as derivative-free algorithms. Fueled by a growing number of applications in science and engineering, the development of derivative-free optimization algorithms has long been studied, and it has found renewed interest in recent time. Along with many derivative-free algorithms, many software implementations have also appeared. The paper presents a review of derivative-free algorithms, followed by a systematic comparison of 22 related implementations using a test set of 502 problems. The test bed includes convex and nonconvex problems, smooth as well as nonsmooth problems. The algorithms were tested under the same conditions and ranked under several criteria, including their ability to find near-global solutions for nonconvex problems, improve a given starting point, and refine a near-optimal solution. A total of 112,448 problem instances were solved. We find that the ability of all these solvers to obtain good solutions diminishes with increasing problem size. For the problems used in this study, TOMLAB/MULTIMIN, TOMLAB/GLCCLUSTER, MCS and TOMLAB/LGO are better, on average, than other derivative-free solvers in terms of solution quality within 2500 function evaluations. These global solvers outperform local solvers even for convex problems. Finally, TOMLAB/OQNLP, NEWUOA, and TOMLAB/MULTIMIN show superior performance in terms of refining a near-optimal solution.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/Zotero/storage/MK4FWX3L/Rios and Sahinidis - 2013 - Derivative-free optimization a review of algorith.pdf}
}

@book{robertBayesianChoiceDecisiontheoretic2007,
  title = {The {{Bayesian}} Choice: From Decision-Theoretic Foundations to Computational Implementation},
  shorttitle = {The {{Bayesian}} Choice},
  author = {Robert, Christian P.},
  year = {2007},
  series = {Springer Texts in Statistics},
  edition = {2nd ed},
  publisher = {{Springer}},
  address = {{New York}},
  isbn = {978-0-387-71598-8},
  langid = {english},
  lccn = {QA279.5 .R6313 2007},
  keywords = {Bayesian statistical decision theory,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Robert_2007_The Bayesian choice.pdf}
}

@article{robertComputationalMethodsBayesian2009,
  title = {Computational Methods for {{Bayesian}} Model Choice},
  author = {Robert, C. P. and Wraith, D.},
  year = {2009},
  month = dec,
  journal = {AIP Conference Proceedings},
  volume = {1193},
  number = {1},
  pages = {251--262},
  publisher = {{American Institute of Physics}},
  issn = {0094-243X},
  doi = {10.1063/1.3275622},
  urldate = {2023-02-13},
  file = {/Users/lichengk/Zotero/storage/AM6TI44W/Robert and Wraith - 2009 - Computational methods for Bayesian model choice.pdf}
}

@book{robertMonteCarloStatistical2004,
  title = {Monte {{Carlo Statistical Methods}}},
  author = {Robert, Christian and Casella, George},
  year = {2004},
  series = {Springer {{Texts}} in {{Statistics}}},
  edition = {Second},
  publisher = {{Springer-Verlag}},
  address = {{New York}},
  doi = {10.1007/978-1-4757-4145-2},
  urldate = {2021-08-10},
  abstract = {Monte Carlo statistical methods, particularly those based on Markov chains, are now an essential component of the standard set of techniques used by statisticians. This new edition has been revised towards a coherent and flowing coverage of these simulation techniques, with incorporation of the most recent developments in the field. In particular, the introductory coverage of random variable generation has been totally revised, with many concepts being unified through a fundamental theorem of simulation There are five completely new chapters that cover Monte Carlo control, reversible jump, slice sampling, sequential Monte Carlo, and perfect sampling. There is a more in-depth coverage of Gibbs sampling, which is now contained in three consecutive chapters. The development of Gibbs sampling starts with slice sampling and its connection with the fundamental theorem of simulation, and builds up to two-stage Gibbs sampling and its theoretical properties. A third chapter covers the multi-stage Gibbs sampler and its variety of applications. Lastly, chapters from the previous edition have been revised towards easier access, with the examples getting more detailed coverage. This textbook is intended for a second year graduate course, but will also be useful to someone who either wants to apply simulation techniques for the resolution of practical problems or wishes to grasp the fundamental principles behind those methods. The authors do not assume familiarity with Monte Carlo techniques (such as random variable generation), with computer programming, or with any Markov chain theory (the necessary concepts are developed in Chapter 6). A solutions manual, which covers approximately 40\% of the problems, is available for instructors who require the book for a course. Christian P. Robert is Professor of Statistics in the Applied Mathematics Department at Universit\'e Paris Dauphine, France. He is also Head of the Statistics Laboratory at the Center for Research in Economics and Statistics (CREST) of the National Institute for Statistics and Economic Studies (INSEE) in Paris, and Adjunct Professor at Ecole Polytechnique. He has written three other books and won the 2004 DeGroot Prize for The Bayesian Choice, Second Edition, Springer 2001. He also edited Discretization and MCMC Convergence Assessment, Springer 1998. He has served as associate editor for the Annals of Statistics, Statistical Science and the Journal of the American Statistical Association. He is a fellow of the Institute of Mathematical Statistics, and a winner of the Young Statistician Award of the Soci\'et\'e de Statistique de Paris in 1995. George Casella is Distinguished Professor and Chair, Department of Statistics, University of Florida. He has served as the Theory and Methods Editor of the Journal of the American Statistical Association and Executive Editor of Statistical Science. He has authored three other textbooks: Statistical Inference, Second Edition, 2001, with Roger L. Berger; Theory of Point Estimation, 1998, with Erich Lehmann; and Variance Components, 1992, with Shayle R. Searle and Charles E. McCulloch. He is a fellow of the Institute of Mathematical Statistics and the American Statistical Association, and an elected fellow of the International Statistical Institute.},
  isbn = {978-0-387-21239-5},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Robert_Casella_2004_Monte Carlo Statistical Methods2.pdf;/Users/lichengk/Zotero/storage/KH6Y2FGB/9780387212395.html}
}

@article{robertShortHistoryMarkov2011,
  title = {A {{Short History}} of {{Markov Chain Monte Carlo}}: {{Subjective Recollections}} from {{Incomplete Data}}},
  shorttitle = {A {{Short History}} of {{Markov Chain Monte Carlo}}},
  author = {Robert, Christian and Casella, George},
  year = {2011},
  month = feb,
  journal = {Statistical Science},
  volume = {26},
  number = {1},
  eprint = {0808.2902},
  issn = {0883-4237},
  doi = {10.1214/10-STS351},
  urldate = {2021-06-13},
  abstract = {We attempt to trace the history and development of Markov chain Monte Carlo (MCMC) from its early inception in the late 1940s through its use today. We see how the earlier stages of Monte Carlo (MC, not MCMC) research have led to the algorithms currently in use. More importantly, we see how the development of this methodology has not only changed our solutions to problems, but has changed the way we think about problems.},
  archiveprefix = {arxiv},
  keywords = {bounds of mixture,Statistics - Computation,Statistics - Methodology,toread},
  annotation = {194 citations (Semantic Scholar/arXiv) [2021-06-13] 194 citations (Semantic Scholar/DOI) [2021-06-13]},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Robert_Casella_2011_A Short History of Markov Chain Monte Carlo.pdf;/Users/lichengk/Zotero/storage/IJ5SUII6/0808.html}
}

@article{robertSpecialIssueBayesian2023,
  title = {A Special Issue on {{Bayesian}} Inference: Challenges, Perspectives and Prospects},
  shorttitle = {A Special Issue on {{Bayesian}} Inference},
  author = {Robert, Christian P. and Rousseau, Judith},
  year = {2023},
  month = may,
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {381},
  number = {2247},
  pages = {20220155},
  issn = {1364-503X, 1471-2962},
  doi = {10.1098/rsta.2022.0155},
  urldate = {2023-05-19},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/CS9LLFAM/Robert and Rousseau - 2023 - A special issue on Bayesian inference challenges,.pdf}
}

@inproceedings{roederStickingLandingSimple2017,
  title = {Sticking the {{Landing}}: {{Simple}}, {{Lower-Variance Gradient Estimators}} for {{Variational Inference}}},
  shorttitle = {Sticking the {{Landing}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Roeder, Geoffrey and Wu, Yuhuai and Duvenaud, David K},
  year = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-12-16},
  abstract = {We propose a simple and general variant of the standard reparameterized gradient estimator for the variational evidence lower bound. Specifically, we remove a part of the total derivative with respect to the variational parameters that corresponds to the score function. Removing this term produces an unbiased gradient estimator whose variance approaches zero as the approximate posterior approaches the exact posterior. We analyze the behavior of this gradient estimator theoretically and empirically, and generalize it to more complex variational distributions such as mixtures and importance-weighted posteriors.},
  file = {/Users/lichengk/Zotero/storage/LQEMIPX6/Roeder et al. - 2017 - Sticking the Landing Simple, Lower-Variance Gradi.pdf}
}

@misc{rombachHighResolutionImageSynthesis2022,
  title = {High-{{Resolution Image Synthesis}} with {{Latent Diffusion Models}}},
  author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  year = {2022},
  month = apr,
  number = {arXiv:2112.10752},
  eprint = {2112.10752},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-11-06},
  abstract = {By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs. Code is available at https://github.com/CompVis/latent-diffusion .},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Rombach et al_2022_High-Resolution Image Synthesis with Latent Diffusion Models.pdf;/Users/lichengk/Zotero/storage/YE92A8Y5/2112.html}
}

@inproceedings{roosHighDimensionalGaussianProcess2021,
  title = {High-{{Dimensional Gaussian Process Inference}} with {{Derivatives}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {de Roos, Filip and Gessner, Alexandra and Hennig, Philipp},
  year = {2021},
  month = jul,
  pages = {2535--2545},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-09-13},
  abstract = {Although it is widely known that Gaussian processes can be conditioned on observations of the gradient, this functionality is of limited use due to the prohibitive computational cost of \$\textbackslash mathcal\{O\}(N\^3 D\^3)\$ in data points \$N\$ and dimension \$D\$. The dilemma of gradient observations is that a single one of them comes at the same cost as \$D\$ independent function evaluations, so the latter are often preferred. Careful scrutiny reveals, however, that derivative observations give rise to highly structured kernel Gram matrices for very general classes of kernels (inter alia, stationary kernels). We show that in the \textbackslash emph\{low-data\} regime \$N {$<$} D\$, the Gram matrix can be decomposed in a manner that reduces the cost of inference to \$\textbackslash mathcal\{O\}(N\^2D + (N\^2)\^3)\$ (i.e.,~linear in the number of dimensions) and, in special cases, to \$\textbackslash mathcal\{O\}(N\^2D + N\^3)\$. This reduction in complexity opens up new use-cases for inference with gradients especially in the high-dimensional regime, where the information-to-cost ratio of gradient observations significantly increases. We demonstrate this potential in a variety of tasks relevant for machine learning, such as optimization and Hamiltonian Monte Carlo with predictive gradients.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Roos et al_2021_High-Dimensional Gaussian Process Inference with Derivatives.pdf;/Users/lichengk/Zotero/storage/2SU5JTJK/Roos et al. - 2021 - High-Dimensional Gaussian Process Inference with D.pdf}
}

@article{rossiSparseGaussianProcesses2021,
  title = {Sparse {{Gaussian Processes Revisited}}: {{Bayesian Approaches}} to {{Inducing-Variable Approximations}}},
  shorttitle = {Sparse {{Gaussian Processes Revisited}}},
  author = {Rossi, Simone and Heinonen, Markus and Bonilla, Edwin V. and Shen, Zheyang and Filippone, Maurizio},
  year = {2021},
  month = feb,
  journal = {arXiv:2003.03080 [cs, stat]},
  eprint = {2003.03080},
  primaryclass = {cs, stat},
  urldate = {2022-02-16},
  abstract = {Variational inference techniques based on inducing variables provide an elegant framework for scalable posterior estimation in Gaussian process (GP) models. Besides enabling scalability, one of their main advantages over sparse approximations using direct marginal likelihood maximization is that they provide a robust alternative for point estimation of the inducing inputs, i.e. the location of the inducing variables. In this work we challenge the common wisdom that optimizing the inducing inputs in the variational framework yields optimal performance. We show that, by revisiting old model approximations such as the fully-independent training conditionals endowed with powerful sampling-based inference methods, treating both inducing locations and GP hyper-parameters in a Bayesian way can improve performance significantly. Based on stochastic gradient Hamiltonian Monte Carlo, we develop a fully Bayesian approach to scalable GP and deep GP models, and demonstrate its state-of-the-art performance through an extensive experimental campaign across several regression and classification problems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Rossi et al_2021_Sparse Gaussian Processes Revisited.pdf;/Users/lichengk/Zotero/storage/IMXHVRVK/2003.html}
}

@book{rudinFunctionalAnalysis1991,
  title = {Functional Analysis},
  author = {Rudin, Walter},
  year = {1991},
  series = {International Series in Pure and Applied Mathematics},
  edition = {2nd ed},
  publisher = {{McGraw-Hill}},
  address = {{New York}},
  isbn = {978-0-07-054236-5},
  langid = {english},
  lccn = {QA320 .R83 1991},
  keywords = {Functional analysis},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Rudin_1991_Functional analysis.pdf}
}

@article{ruFastInformationtheoreticBayesian2018,
  title = {Fast {{Information-theoretic Bayesian Optimisation}}},
  author = {Ru, Binxin and McLeod, Mark and Granziol, Diego and Osborne, Michael A.},
  year = {2018},
  month = jun,
  journal = {arXiv:1711.00673 [stat]},
  eprint = {1711.00673},
  primaryclass = {stat},
  urldate = {2021-08-08},
  abstract = {Information-theoretic Bayesian optimisation techniques have demonstrated state-of-the-art performance in tackling important global optimisation problems. However, current information-theoretic approaches require many approximations in implementation, introduce often-prohibitive computational overhead and limit the choice of kernels available to model the objective. We develop a fast information-theoretic Bayesian Optimisation method, FITBO, that avoids the need for sampling the global minimiser, thus significantly reducing computational overhead. Moreover, in comparison with existing approaches, our method faces fewer constraints on kernel choice and enjoys the merits of dealing with the output space. We demonstrate empirically that FITBO inherits the performance associated with information-theoretic Bayesian optimisation, while being even faster than simpler Bayesian optimisation approaches, such as Expected Improvement.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Ru et al_2018_Fast Information-theoretic Bayesian Optimisation.pdf;/Users/lichengk/Zotero/storage/JRJ5CPH3/1711.html}
}

@inproceedings{ruizContrastiveDivergenceCombining2019,
  title = {A {{Contrastive Divergence}} for {{Combining Variational Inference}} and {{MCMC}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Ruiz, Francisco and Titsias, Michalis},
  year = {2019},
  month = may,
  pages = {5537--5545},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-09-20},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Ruiz_Titsias_2019_A Contrastive Divergence for Combining Variational Inference and MCMC.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Ruiz_Titsias_2019_A Contrastive Divergence for Combining Variational Inference and MCMC2.pdf}
}

@inproceedings{ruizContrastiveDivergenceCombining2019a,
  title = {A {{Contrastive Divergence}} for {{Combining Variational Inference}} and {{MCMC}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Ruiz, Francisco and Titsias, Michalis},
  year = {2019},
  month = may,
  pages = {5537--5545},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-01-11},
  abstract = {We develop a method to combine Markov chain Monte Carlo (MCMC) and variational inference (VI), leveraging the advantages of both inference approaches. Specifically, we improve the variational distribution by running a few MCMC steps. To make inference tractable, we introduce the variational contrastive divergence (VCD), a new divergence that replaces the standard Kullback-Leibler (KL) divergence used in VI. The VCD captures a notion of discrepancy between the initial variational distribution and its improved version (obtained after running the MCMC steps), and it converges asymptotically to the symmetrized KL divergence between the variational distribution and the posterior of interest. The VCD objective can be optimized efficiently with respect to the variational parameters via stochastic optimization. We show experimentally that optimizing the VCD leads to better predictive performance on two latent variable models: logistic matrix factorization and variational autoencoders (VAEs).},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Ruiz_Titsias_2019_A Contrastive Divergence for Combining Variational Inference and MCMC3.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Ruiz_Titsias_2019_A Contrastive Divergence for Combining Variational Inference and MCMC4.pdf}
}

@book{rundeTasteTopology2005,
  title = {A Taste of Topology},
  author = {Runde, Volker},
  year = {2005},
  series = {Universitext},
  publisher = {{Springer}},
  address = {{New York}},
  isbn = {978-0-387-25790-7},
  langid = {english},
  lccn = {QA611 .R85 2005},
  keywords = {Topology},
  annotation = {OCLC: ocm60320111},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Runde_2005_A taste of topology.pdf}
}

@inproceedings{ryanFastKernelTransform2022,
  title = {The {{Fast Kernel Transform}}},
  booktitle = {Proceedings of {{The}} 25th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Ryan, John P. and Ament, Sebastian E. and Gomes, Carla P. and Damle, Anil},
  year = {2022},
  month = may,
  pages = {11669--11690},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-10-17},
  abstract = {Kernel methods are a highly effective and widely used collection of modern machine learning algorithms. A fundamental limitation of virtually all such methods are computations involving the kernel matrix that naively scale quadratically (e.g., matrix-vector multiplication) or cubically (solving linear systems) with the size of the dataset N. We propose the Fast Kernel Transform (FKT), a general algorithm to compute matrix-vector multiplications (MVMs) for datasets in moderate dimensions with quasilinear complexity. Typically, analytically grounded fast multiplication methods require specialized development for specific kernels. In contrast, our scheme is based on auto-differentiation and automated symbolic computations that leverage the analytical structure of the underlying kernel. This allows the FKT to be easily applied to a broad class of kernels, including Gaussian, Matern, and Rational Quadratic covariance functions and Green's functions, including those of the Laplace and Helmholtz equations. Furthermore, the FKT maintains a high, quantifiable, and controllable level of accuracy\textemdash properties that many acceleration methods lack. We illustrate the efficacy and versatility of the FKT by providing timing and accuracy benchmarks with comparisons to adjacent methods, and by applying it to scale the stochastic neighborhood embedding (t-SNE) and Gaussian processes to large real-world datasets.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/P5LBLX9T/Ryan et al. - 2022 - The Fast Kernel Transform.pdf}
}

@inproceedings{salimbeniDoublyStochasticVariational2017,
  title = {Doubly Stochastic Variational Inference for Deep Gaussian Processes},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Salimbeni, Hugh and Deisenroth, Marc},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Salimbeni_Deisenroth_2017_Doubly Stochastic Variational Inference for Deep Gaussian Processes.pdf;/Users/lichengk/Zotero/storage/32UG34FZ/NIPS-2002-bayesian-monte-carlo-Paper.pdf}
}

@inproceedings{salimbeniNaturalGradientsPractice2018,
  title = {Natural {{Gradients}} in {{Practice}}: {{Non-Conjugate Variational Inference}} in {{Gaussian Process Models}}},
  shorttitle = {Natural {{Gradients}} in {{Practice}}},
  booktitle = {{{AISTATS}}},
  author = {Salimbeni, Hugh and Eleftheriadis, Stefanos and Hensman, J.},
  year = {2018},
  abstract = {The natural gradient method has been used effectively in conjugate Gaussian process models, but the non-conjugate case has been largely unexplored. We examine how natural gradients can be used in non-conjugate stochastic settings, together with hyperparameter learning. We conclude that the natural gradient can significantly improve performance in terms of wall-clock time. For ill-conditioned posteriors the benefit of the natural gradient method is especially pronounced, and we demonstrate a practical setting where ordinary gradients are unusable. We show how natural gradients can be computed efficiently and automatically in any parameterization, using automatic differentiation. Our code is integrated into the GPflow package.},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Salimbeni et al_2018_Natural Gradients in Practice.pdf}
}

@phdthesis{samoAdvancesKernelMethods2017,
  type = {{{http://purl.org/dc/dcmitype/Text}}},
  title = {Advances in Kernel Methods: Towards General-Purpose and Scalable Models},
  shorttitle = {Advances in Kernel Methods},
  author = {Samo, Yves-Laurent Kom},
  year = {2017},
  urldate = {2021-08-08},
  abstract = {{$<$}p{$>$}A wide range of statistical and machine learning problems involve learning one or multiple latent functions, or properties thereof, from datasets. Examples include regression, classification, principal component analysis, optimisation, learning intensity functions of point processes and reinforcement learning to name but a few. For all these problems, positive semi-definite kernels (or simply kernels) provide a powerful tool for postulating flexible nonparametric hypothesis spaces over functions. Despite recent work on such kernel methods, parametric alternatives, such as deep neural networks, have been at the core of most artificial intelligence breakthroughs in recent years. In this thesis, both theoretical and methodological foundations are presented for constructing {$<$}em{$>$}fully automated{$<$}/em{$>$}, {$<$}em{$>$}scalable{$<$}/em{$>$}, and {$<$}em{$>$}general-purpose{$<$}/em{$>$} kernel machines that perform very well over a wide range of input dimensions and sample sizes. This thesis aims to contribute towards bridging the gap between kernel methods and deep learning and to propose methods that have the advantage over deep learning in performing well on both small and large scale problems.{$<$}/p{$>$} {$<$}p{$>$}In Part I we provide a gentle introduction to kernel methods, review recent work, identify remaining gaps and outline our contributions.{$<$}/p{$>$} {$<$}p{$>$}In Part II we develop {$<$}em{$>$}flexible{$<$}/em{$>$} and {$<$}em{$>$}scalable{$<$}/em{$>$} Bayesian kernel methods in order to address gaps in methods capable of dealing with the special case of datasets exhibiting locally homogeneous patterns. We begin with two motivating applications. First we consider inferring the intensity function of an inhomogeneous point process in Chapter 2. This application is used to illustrate that often, by carefully adding some mild asymmetry in the dependency structure in Bayesian kernel methods, one may considerably scale-up inference while improving flexibility and accuracy. In Chapter 3 we propose a scalable scheme for online forecasting of time series and {$<$}em{$>$}fully-online{$<$}/em{$>$} learning of related model parameters, under a kernel-based generative model that is provably sufficiently flexible. This application illustrates that, for one-dimensional input spaces, restricting the degree of differentiability of the latent function of interest may considerably speed-up inference without resorting to approximations and without any adverse effect on flexibility or accuracy. Chapter 4 generalizes these approaches and proposes a novel class of stochastic processes we refer to as string Gaussian processes (string GPs) that, when used as functional prior in a Bayesian nonparametric framework, allow for inference in linear time complexity and linear memory requirement, without resorting to approximations. More importantly, the corresponding inference scheme, which we derive in Chapter 5, also allows flexible learning of locally homogeneous patterns and automated learning of model complexity - that is automated learning of whether there are local patterns in the data in the first place, {$<$}em{$>$}how much{$<$}/em{$>$} local patterns are present, and where they are located.{$<$}/p{$>$} {$<$}p{$>$}In Part III we provide a broader discussion covering all types of patterns (homogeneous, locally homogeneous or heterogeneous patterns) and both Bayesian or frequentist kernel methods. In Chapter 6 we begin by discussing what properties a family of kernels should possess to enable fully automated kernel methods that are applicable to any type of datasets. In this chapter, we discuss a novel mathematical formalism for the notion of `general-purpose' families of kernels, and we argue that existing families of kernels are not general-purpose. In Chapter 7 we derive weak sufficient conditions for families of kernels to be general-purpose, and we exhibit tractable such families that enjoy a suitable parametrisation, that we refer to as {$<$}em{$>$}generalized spectral kernels{$<$}/em{$>$} (GSKs). In Chapter 8 we provide a {$<$}em{$>$}scalable{$<$}/em{$>$} inference scheme for automated kernel learning using {$<$}em{$>$}general-purpose{$<$}/em{$>$} families of kernels. The proposed inference scheme {$<$}em{$>$}scales linearly{$<$}/em{$>$} with the sample size and enables {$<$}em{$>$}automated learning of nonstationarity{$<$}/em{$>$} and model complexity from the data, in virtually any kernel method. Finally, we conclude with a discussion in Chapter 9 where we show that deep learning can be regarded as a particular type of kernel learning method, and we discuss possible extensions in Chapter 10.{$<$}/p{$>$}},
  langid = {english},
  school = {University of Oxford},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Samo_2017_Advances in kernel methods.pdf;/Users/lichengk/Zotero/storage/DS8LRWK2/uuide0ff5f8c-bc28-4d96-8ddb-2d49152b2eee.html}
}

@article{samoGeneralizedSpectralKernels2015,
  title = {Generalized {{Spectral Kernels}}},
  author = {Samo, Yves-Laurent Kom and Roberts, Stephen},
  year = {2015},
  month = oct,
  journal = {arXiv:1506.02236 [stat]},
  eprint = {1506.02236},
  primaryclass = {stat},
  urldate = {2021-08-11},
  abstract = {In this paper we propose a family of tractable kernels that is dense in the family of bounded positive semi-definite functions (i.e. can approximate any bounded kernel with arbitrary precision). We start by discussing the case of stationary kernels, and propose a family of spectral kernels that extends existing approaches such as spectral mixture kernels and sparse spectrum kernels. Our extension has two primary advantages. Firstly, unlike existing spectral approaches that yield infinite differentiability, the kernels we introduce allow learning the degree of differentiability of the latent function in Gaussian process (GP) models and functions in the reproducing kernel Hilbert space (RKHS) in other kernel methods. Secondly, we show that some of the kernels we propose require fewer parameters than existing spectral kernels for the same accuracy, thereby leading to faster and more robust inference. Finally, we generalize our approach and propose a flexible and tractable family of spectral kernels that we prove can approximate any continuous bounded nonstationary kernel.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Samo_Roberts_2015_Generalized Spectral Kernels.pdf;/Users/lichengk/Zotero/storage/LTKBZDED/1506.html}
}

@book{sarkkaAppliedStochasticDifferential2019,
  title = {Applied {{Stochastic Differential Equations}}},
  author = {S{\"a}rkk{\"a}, Simo and Solin, Arno},
  year = {2019},
  month = apr,
  edition = {First},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108186735},
  urldate = {2021-09-16},
  isbn = {978-1-108-18673-5 978-1-316-51008-7 978-1-316-64946-6},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Särkkä_Solin_2019_Applied Stochastic Differential Equations.pdf}
}

@incollection{sarkkaLinearOperatorsStochastic2011,
  title = {Linear {{Operators}} and {{Stochastic Partial Differential Equations}} in {{Gaussian Process Regression}}},
  booktitle = {Artificial {{Neural Networks}} and {{Machine Learning}} \textendash{} {{ICANN}} 2011},
  author = {S{\"a}rkk{\"a}, Simo},
  editor = {Honkela, Timo and Duch, W{\l}odzis{\l}aw and Girolami, Mark and Kaski, Samuel},
  year = {2011},
  volume = {6792},
  pages = {151--158},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-21738-8_20},
  urldate = {2023-06-07},
  abstract = {In this paper we shall discuss an extension to Gaussian process (GP) regression models, where the measurements are modeled as linear functionals of the underlying GP and the estimation objective is a general linear operator of the process. We shall show how this framework can be used for modeling physical processes involved in measurement of the GP and for encoding physical prior information into regression models in form of stochastic partial differential equations (SPDE). We shall also illustrate the practical applicability of the theory in a simulated application.},
  isbn = {978-3-642-21737-1 978-3-642-21738-8},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/Zotero/storage/DXJL6JDC/Särkkä - 2011 - Linear Operators and Stochastic Partial Differenti.pdf}
}

@misc{schmittDetectingModelMisspecification2022,
  title = {Detecting {{Model Misspecification}} in {{Amortized Bayesian Inference}} with {{Neural Networks}}},
  author = {Schmitt, Marvin and B{\"u}rkner, Paul-Christian and K{\"o}the, Ullrich and Radev, Stefan T.},
  year = {2022},
  month = nov,
  number = {arXiv:2112.08866},
  eprint = {2112.08866},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-20},
  abstract = {Neural density estimators have proven remarkably powerful in performing efficient simulation-based Bayesian inference in various research domains. In particular, the BayesFlow framework uses a two-step approach to enable amortized parameter estimation in settings where the likelihood function is implicitly defined by a simulation program. But how faithful is such inference when simulations are poor representations of reality? In this paper, we conceptualize the types of model misspecification arising in simulation-based inference and systematically investigate the performance of the BayesFlow framework under these misspecifications. We propose an augmented optimization objective which imposes a probabilistic structure on the latent data space and utilize maximum mean discrepancy (MMD) to detect potentially catastrophic misspecifications during inference undermining the validity of the obtained results. We verify our detection criterion on a number of artificial and realistic misspecifications, ranging from toy conjugate models to complex models of decision making and disease outbreak dynamics applied to real data. Further, we show that posterior inference errors increase as a function of the distance between the true data-generating distribution and the typical set of simulations in the latent summary space. Thus, we demonstrate the dual utility of MMD as a method for detecting model misspecification and as a proxy for verifying the faithfulness of amortized Bayesian inference.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Schmitt et al_2022_Detecting Model Misspecification in Amortized Bayesian Inference with Neural.pdf;/Users/lichengk/Zotero/storage/SRSW9H7J/2112.html}
}

@incollection{scholkopfCausalityMachineLearning2022,
  title = {Causality for {{Machine Learning}}},
  author = {Sch{\"o}lkopf, Bernhard},
  year = {2022},
  month = feb,
  eprint = {1911.10500},
  primaryclass = {cs, stat},
  pages = {765--804},
  doi = {10.1145/3501714.3501755},
  urldate = {2023-01-13},
  abstract = {Graphical causal inference as pioneered by Judea Pearl arose from research on artificial intelligence (AI), and for a long time had little connection to the field of machine learning. This article discusses where links have been and should be established, introducing key concepts along the way. It argues that the hard open problems of machine learning and AI are intrinsically related to causality, and explains how the field is beginning to understand them.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,I.2,{I.2, I.5, K.4},I.5,K.4,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/XKCL8DNB/Schölkopf - 2022 - Causality for Machine Learning.pdf;/Users/lichengk/Zotero/storage/BLG3WMXS/1911.html}
}

@incollection{scholkopfGeneralizedRepresenterTheorem2001,
  title = {A {{Generalized Representer Theorem}}},
  booktitle = {Computational {{Learning Theory}}},
  author = {Sch{\"o}lkopf, Bernhard and Herbrich, Ralf and Smola, Alex J.},
  editor = {Goos, G. and Hartmanis, J. and {van Leeuwen}, J. and Helmbold, David and Williamson, Bob},
  year = {2001},
  volume = {2111},
  pages = {416--426},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-44581-1_27},
  urldate = {2021-10-25},
  abstract = {Wahba's classical representer theorem states that the solutions of certain risk minimization problems involving an empirical risk term and a quadratic regularizer can be written as expansions in terms of the training examples. We generalize the theorem to a larger class of regularizers and empirical risk terms, and give a self-contained proof utilizing the feature space associated with a kernel. The result shows that a wide range of problems have optimal solutions that live in the finite dimensional span of the training examples mapped into feature space, thus enabling us to carry out kernel algorithms independent of the (potentially infinite) dimensionality of the feature space.},
  isbn = {978-3-540-42343-0 978-3-540-44581-4},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/AAL2EPUW/Schölkopf et al. - 2001 - A Generalized Representer Theorem.pdf}
}

@article{schweidtmannGlobalOptimizationGaussian2020,
  title = {Global {{Optimization}} of {{Gaussian}} Processes},
  author = {Schweidtmann, Artur M. and Bongartz, Dominik and Grothe, Daniel and Kerkenhoff, Tim and Lin, Xiaopeng and Najman, Jaromil and Mitsos, Alexander},
  year = {2020},
  month = may,
  journal = {arXiv:2005.10902 [cs, math, stat]},
  eprint = {2005.10902},
  primaryclass = {cs, math, stat},
  urldate = {2022-01-18},
  abstract = {Gaussian processes\textasciitilde (Kriging) are interpolating data-driven models that are frequently applied in various disciplines. Often, Gaussian processes are trained on datasets and are subsequently embedded as surrogate models in optimization problems. These optimization problems are nonconvex and global optimization is desired. However, previous literature observed computational burdens limiting deterministic global optimization to Gaussian processes trained on few data points. We propose a reduced-space formulation for deterministic global optimization with trained Gaussian processes embedded. For optimization, the branch-and-bound solver branches only on the degrees of freedom and McCormick relaxations are propagated through explicit Gaussian process models. The approach also leads to significantly smaller and computationally cheaper subproblems for lower and upper bounding. To further accelerate convergence, we derive envelopes of common covariance functions for GPs and tight relaxations of acquisition functions used in Bayesian optimization including expected improvement, probability of improvement, and lower confidence bound. In total, we reduce computational time by orders of magnitude compared to state-of-the-art methods, thus overcoming previous computational burdens. We demonstrate the performance and scaling of the proposed method and apply it to Bayesian optimization with global optimization of the acquisition function and chance-constrained programming. The Gaussian process models, acquisition functions, and training scripts are available open-source within the "MeLOn - Machine Learning Models for Optimization" toolbox\textasciitilde (https://git.rwth-aachen.de/avt.svt/public/MeLOn).},
  archiveprefix = {arxiv},
  keywords = {{90C26, 90C30, 90C90, 68T01, 60-04},Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Schweidtmann et al_2020_Global Optimization of Gaussian processes.pdf;/Users/lichengk/Zotero/storage/L3VM5R9G/2005.html}
}

@article{seegerLowRankUpdates,
  title = {Low {{Rank Updates}} for the {{Cholesky Decomposition}}},
  author = {Seeger, Matthias},
  pages = {7},
  abstract = {Usage of the Sherman-Morrison-Woodbury formula to update linear systems after low rank modifications of the system matrix is widespread in machine learning. However, it is well known that this formula can lead to serious instabilities in the presence of roundoff error. If the system matrix is symmetric positive definite, it is almost always possible to use a representation based on the Cholesky decomposition which renders the same results (in exact arithmetic) at the same or less operational cost, but typically is much more numerically stable. In this note, we show how the Cholesky decomposition can be updated to incorporate low rank additions or downdated for low rank subtractions. We also discuss a special case of an indefinite update of rank two. The methods discussed here are well-known in the numerical mathematics literature, and code for most of them can be found in the LINPACK suite.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Seeger_Low Rank Updates for the Cholesky Decomposition.pdf}
}

@article{shahriariTakingHumanOut2016,
  title = {Taking the {{Human Out}} of the {{Loop}}: {{A Review}} of {{Bayesian Optimization}}},
  shorttitle = {Taking the {{Human Out}} of the {{Loop}}},
  author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and {de Freitas}, Nando},
  year = {2016},
  month = jan,
  journal = {Proceedings of the IEEE},
  volume = {104},
  number = {1},
  pages = {148--175},
  issn = {0018-9219, 1558-2256},
  doi = {10.1109/JPROC.2015.2494218},
  urldate = {2021-10-07},
  abstract = {Big data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involves many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Shahriari et al_2016_Taking the Human Out of the Loop2.pdf}
}

@article{shahStudenttProcessesAlternatives,
  title = {Student-t {{Processes}} as {{Alternatives}} to {{Gaussian Processes}}},
  author = {Shah, Amar and Wilson, Andrew Gordon and Ghahramani, Zoubin},
  pages = {9},
  abstract = {We investigate the Student-t process as an alternative to the Gaussian process as a nonparametric prior over functions. We derive closed form expressions for the marginal likelihood and predictive distribution of a Student-t process, by integrating away an inverse Wishart process prior over the covariance kernel of a Gaussian process model. We show surprising equivalences between different hierarchical Gaussian process models leading to Student-t processes, and derive a new sampling scheme for the inverse Wishart process, which helps elucidate these equivalences. Overall, we show that a Studentt process can retain the attractive properties of a Gaussian process \textendash{} a nonparametric representation, analytic marginal and predictive distributions, and easy model selection through covariance kernels \textendash{} but has enhanced flexibility, and predictive covariances that, unlike a Gaussian process, explicitly depend on the values of training observations. We verify empirically that a Student-t process is especially useful in situations where there are changes in covariance structure, or in applications such as Bayesian optimization, where accurate predictive covariances are critical for good performance. These advantages come at no additional computational cost over Gaussian processes.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/NFFXFNYS/Shah et al. - Student-t Processes as Alternatives to Gaussian Pr.pdf}
}

@article{shenComputationallyEfficientHighDimensional2021,
  title = {Computationally {{Efficient High-Dimensional Bayesian Optimization}} via {{Variable Selection}}},
  author = {Shen, Yihang and Kingsford, Carl},
  year = {2021},
  month = sep,
  journal = {arXiv:2109.09264 [cs, stat]},
  eprint = {2109.09264},
  primaryclass = {cs, stat},
  urldate = {2021-10-04},
  abstract = {Bayesian Optimization (BO) is a method for globally optimizing black-box functions. While BO has been successfully applied to many scenarios, developing effective BO algorithms that scale to functions with high-dimensional domains is still a challenge. Optimizing such functions by vanilla BO is extremely time-consuming. Alternative strategies for high-dimensional BO that are based on the idea of embedding the high-dimensional space to the one with low dimension are sensitive to the choice of the embedding dimension, which needs to be pre-specified. We develop a new computationally efficient high-dimensional BO method that exploits variable selection. Our method is able to automatically learn axis-aligned sub-spaces, i.e. spaces containing selected variables, without the demand of any pre-specified hyperparameters. We theoretically analyze the computational complexity of our algorithm and derive the regret bound. We empirically show the efficacy of our method on several synthetic and real problems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/D3AZGFT5/Shen and Kingsford - 2021 - Computationally Efficient High-Dimensional Bayesia.pdf;/Users/lichengk/Zotero/storage/NIUJLRU8/2109.html}
}

@inproceedings{shenHarmonizableMixtureKernels2019,
  title = {Harmonizable Mixture Kernels with Variational {{Fourier}} Features},
  booktitle = {The 22nd {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Shen, Zheyang and Heinonen, Markus and Kaski, Samuel},
  year = {2019},
  month = apr,
  pages = {3273--3282},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-08-10},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Shen et al_2019_Harmonizable mixture kernels with variational Fourier features.pdf;/Users/lichengk/Zotero/storage/ALHE9AB3/Shen et al. - 2019 - Harmonizable mixture kernels with variational Four.pdf}
}

@phdthesis{shenSpectralKernelsGaussian2019,
  title = {Spectral Kernels for {{Gaussian}} Processes},
  author = {Shen, Zheyang},
  year = {2019},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Shen_2019_Spectral kernels for Gaussian processes.pdf}
}

@misc{shettyDistributionCompressionNearlinear2022,
  title = {Distribution {{Compression}} in {{Near-linear Time}}},
  author = {Shetty, Abhishek and Dwivedi, Raaz and Mackey, Lester},
  year = {2022},
  month = oct,
  number = {arXiv:2111.07941},
  eprint = {2111.07941},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  urldate = {2023-03-06},
  abstract = {In distribution compression, one aims to accurately summarize a probability distribution \$\textbackslash mathbb\{P\}\$ using a small number of representative points. Near-optimal thinning procedures achieve this goal by sampling \$n\$ points from a Markov chain and identifying \$\textbackslash sqrt\{n\}\$ points with \$\textbackslash widetilde\{\textbackslash mathcal\{O\}\}(1/\textbackslash sqrt\{n\})\$ discrepancy to \$\textbackslash mathbb\{P\}\$. Unfortunately, these algorithms suffer from quadratic or super-quadratic runtime in the sample size \$n\$. To address this deficiency, we introduce Compress++, a simple meta-procedure for speeding up any thinning algorithm while suffering at most a factor of \$4\$ in error. When combined with the quadratic-time kernel halving and kernel thinning algorithms of Dwivedi and Mackey (2021), Compress++ delivers \$\textbackslash sqrt\{n\}\$ points with \$\textbackslash mathcal\{O\}(\textbackslash sqrt\{\textbackslash log n/n\})\$ integration error and better-than-Monte-Carlo maximum mean discrepancy in \$\textbackslash mathcal\{O\}(n \textbackslash log\^3 n)\$ time and \$\textbackslash mathcal\{O\}( \textbackslash sqrt\{n\} \textbackslash log\^2 n )\$ space. Moreover, Compress++ enjoys the same near-linear runtime given any quadratic-time input and reduces the runtime of super-quadratic algorithms by a square-root factor. In our benchmarks with high-dimensional Monte Carlo samples and Markov chains targeting challenging differential equation posteriors, Compress++ matches or nearly matches the accuracy of its input algorithm in orders of magnitude less time.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/Zotero/storage/DEFY4RFP/Shetty et al. - 2022 - Distribution Compression in Near-linear Time.pdf;/Users/lichengk/Zotero/storage/GIFYMFQK/2111.html}
}

@article{siAUTOREGRESSIVEQUANTILEFLOWS,
  title = {{{AUTOREGRESSIVE QUANTILE FLOWS FOR PREDICTIVE UNCERTAINTY ESTIMATION}}},
  author = {Si, Phillip and Bishop, Allan and Kuleshov, Volodymyr},
  abstract = {Numerous applications of machine learning involve representing probability distributions over high-dimensional data. We propose autoregressive quantile flows, a flexible class of normalizing flow models trained using a novel objective based on proper scoring rules. Our objective does not require calculating computationally expensive determinants of Jacobians during training and supports new types of neural architectures, such as neural autoregressive flows from which it is easy to sample.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/ITMYEDC2/Si et al. - AUTOREGRESSIVE QUANTILE FLOWS FOR PREDICTIVE UNCER.pdf}
}

@misc{siEnergyFlowsDeterminantFree2022,
  title = {Energy {{Flows}}: {{Towards Determinant-Free Training}} of {{Normalizing Flows}}},
  shorttitle = {Energy {{Flows}}},
  author = {Si, Phillip and Kuleshov, Volodymyr},
  year = {2022},
  month = jun,
  number = {arXiv:2206.06672},
  eprint = {2206.06672},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-25},
  abstract = {Normalizing flows are a popular approach for constructing probabilistic and generative models. However, maximum likelihood training of flows is challenging due to the need to calculate computationally expensive determinants of Jacobians. This paper takes steps towards addressing this challenge by introducing an approach for determinant-free training of flows inspired by two-sample testing. Central to our framework is the energy objective, a multidimensional extension of proper scoring rules that admits efficient estimators based on random projections and that outperforms a range of alternative two-sample objectives that can be derived in our framework. Crucially, the energy objective and its alternatives do not require calculating determinants and therefore support general flow architectures that are not well-suited to maximum likelihood training (e.g., densely connected networks). We empirically demonstrate that energy flows achieve competitive generative modeling performance while maintaining fast generation and posterior inference.},
  archiveprefix = {arxiv},
  keywords = {68T37 (Primary) 68T07 (Secondary),Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Si_Kuleshov_2022_Energy Flows.pdf;/Users/lichengk/Zotero/storage/4WALVDZ8/2206.html}
}

@article{siivolaGoodPracticesBayesian2021,
  title = {Good Practices for {{Bayesian}} Optimization of High Dimensional Structured Spaces},
  author = {Siivola, Eero and Paleyes, Andrei and Gonz{\'a}lez, Javier and Vehtari, Aki},
  year = {2021},
  journal = {Applied AI Letters},
  volume = {2},
  number = {2},
  pages = {e24},
  issn = {2689-5595},
  doi = {10.1002/ail2.24},
  urldate = {2021-09-15},
  abstract = {The increasing availability of structured but high dimensional data has opened new opportunities for optimization. One emerging and promising avenue is the exploration of unsupervised methods for projecting structured high dimensional data into low dimensional continuous representations, simplifying the optimization problem and enabling the application of traditional optimization methods. However, this line of research has been purely methodological with little connection to the needs of practitioners so far. In this article, we study the effect of different search space design choices for performing Bayesian optimization in high dimensional structured datasets. In particular, we analyses the influence of the dimensionality of the latent space, the role of the acquisition function and evaluate new methods to automatically define the optimization bounds in the latent space. Finally, based on experimental results using synthetic and real datasets, we provide recommendations for the practitioners.},
  langid = {english},
  keywords = {Bayesian optimization,Gaussian processes,variational autoencoders},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Siivola et al_2021_Good practices for Bayesian optimization of high dimensional structured spaces.pdf;/Users/lichengk/Zotero/storage/X4C622UQ/ail2.html}
}

@article{siivolaGoodPracticesBayesian2021a,
  title = {Good Practices for {{Bayesian}} Optimization of High Dimensional Structured Spaces},
  author = {Siivola, Eero and Paleyes, Andrei and Gonz{\'a}lez, Javier and Vehtari, Aki},
  year = {2021},
  journal = {Applied AI Letters},
  volume = {2},
  number = {2},
  pages = {e24},
  issn = {2689-5595},
  doi = {10.1002/ail2.24},
  urldate = {2022-04-11},
  abstract = {The increasing availability of structured but high dimensional data has opened new opportunities for optimization. One emerging and promising avenue is the exploration of unsupervised methods for projecting structured high dimensional data into low dimensional continuous representations, simplifying the optimization problem and enabling the application of traditional optimization methods. However, this line of research has been purely methodological with little connection to the needs of practitioners so far. In this article, we study the effect of different search space design choices for performing Bayesian optimization in high dimensional structured datasets. In particular, we analyses the influence of the dimensionality of the latent space, the role of the acquisition function and evaluate new methods to automatically define the optimization bounds in the latent space. Finally, based on experimental results using synthetic and real datasets, we provide recommendations for the practitioners.},
  langid = {english},
  keywords = {Bayesian optimization,Gaussian processes,variational autoencoders}
}

@inproceedings{siMemoryEfficientKernel2014,
  title = {Memory {{Efficient Kernel Approximation}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Si, Si and Hsieh, Cho-Jui and Dhillon, Inderjit},
  year = {2014},
  month = jan,
  pages = {701--709},
  publisher = {{PMLR}},
  issn = {1938-7228},
  urldate = {2021-08-16},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Si et al_2014_Memory Efficient Kernel Approximation.pdf}
}

@inproceedings{simpsonKernelIdentificationTransformers2021,
  title = {Kernel {{Identification Through Transformers}}},
  booktitle = {Thirty-{{Fifth Conference}} on {{Neural Information Processing Systems}}},
  author = {Simpson, Fergus and Davies, Ian and Lalchand, Vidhi and Vullo, Alessandro and Durrande, Nicolas and Rasmussen, Carl Edward},
  year = {2021},
  month = may,
  urldate = {2021-12-08},
  abstract = {Rapid selection of kernels for Gaussian processes with a transformer-based architecture},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Simpson et al_2021_Kernel Identification Through Transformers.pdf;/Users/lichengk/Zotero/storage/XWVS27DN/forum.html}
}

@inproceedings{simpsonMarginalisedGaussianProcesses2021,
  title = {Marginalised {{Gaussian Processes}} with {{Nested Sampling}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Simpson, Fergus and Lalchand, Vidhi and Rasmussen, Carl Edward},
  year = {2021},
  month = may,
  urldate = {2021-12-28},
  abstract = {We propose nested sampling as a promising means of marginalising kernel hyperparameters.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Simpson et al_2021_Marginalised Gaussian Processes with Nested Sampling.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Simpson et al_2021_Marginalised Gaussian Processes with Nested Sampling2.pdf;/Users/lichengk/Zotero/storage/FT5395TH/forum.html}
}

@inproceedings{sinhaLearningKernelsRandom2016,
  title = {Learning {{Kernels}} with {{Random Features}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Sinha, Aman and Duchi, John C},
  year = {2016},
  volume = {29},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-01-18},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Sinha_Duchi_2016_Learning Kernels with Random Features.pdf}
}

@article{skillingNestedSamplingGeneral2006,
  title = {Nested Sampling for General {{Bayesian}} Computation},
  author = {Skilling, John},
  year = {2006},
  month = dec,
  journal = {Bayesian Analysis},
  volume = {1},
  number = {4},
  pages = {833--859},
  publisher = {{International Society for Bayesian Analysis}},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/06-BA127},
  urldate = {2021-08-09},
  abstract = {Nested sampling estimates directly how the likelihood function relates to prior mass. The evidence (alternatively the marginal likelihood, marginal density of the data, or the prior predictive) is immediately obtained by summation. It is the prime result of the computation, and is accompanied by an estimate of numerical uncertainty. Samples from the posterior distribution are an optional by-product, obtainable for any temperature. The method relies on sampling within a hard constraint on likelihood value, as opposed to the softened likelihood of annealing methods. Progress depends only on the shape of the "nested" contours of likelihood, and not on the likelihood values. This invariance (over monotonic re-labelling) allows the method to deal with a class of phase-change problems which effectively defeat thermal annealing.},
  keywords = {algorithm,annealing,Bayesian computation,evidence,marginal likelihood,Model selection,nest,ObsCite,phase change},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Skilling_2006_Nested sampling for general Bayesian computation.pdf;/Users/lichengk/Zotero/storage/CQ6JFYUU/06-BA127.html}
}

@article{skillingNestedSamplingGeneral2006a,
  title = {Nested Sampling for General {{Bayesian}} Computation},
  author = {Skilling, John},
  year = {2006},
  month = dec,
  journal = {Bayesian Analysis},
  volume = {1},
  number = {4},
  issn = {1936-0975},
  doi = {10.1214/06-BA127},
  urldate = {2022-01-04},
  abstract = {Nested sampling estimates directly how the likelihood function relates to prior mass. The evidence (alternatively the marginal likelihood, marginal density of the data, or the prior predictive) is immediately obtained by summation. It is the prime result of the computation, and is accompanied by an estimate of numerical uncertainty. Samples from the posterior distribution are an optional byproduct, obtainable for any temperature. The method relies on sampling within a hard constraint on likelihood value, as opposed to the softened likelihood of annealing methods. Progress depends only on the shape of the ``nested'' contours of likelihood, and not on the likelihood values. This invariance (over monotonic relabelling) allows the method to deal with a class of phase-change problems which effectively defeat thermal annealing.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Skilling_2006_Nested sampling for general Bayesian computation2.pdf}
}

@article{skillingNestedSamplingGeneral2006b,
  title = {Nested Sampling for General {{Bayesian}} Computation},
  author = {Skilling, John},
  year = {2006},
  month = dec,
  journal = {Bayesian Analysis},
  volume = {1},
  number = {4},
  pages = {833--859},
  publisher = {{International Society for Bayesian Analysis}},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/06-BA127},
  urldate = {2023-06-05},
  abstract = {Nested sampling estimates directly how the likelihood function relates to prior mass. The evidence (alternatively the marginal likelihood, marginal density of the data, or the prior predictive) is immediately obtained by summation. It is the prime result of the computation, and is accompanied by an estimate of numerical uncertainty. Samples from the posterior distribution are an optional by-product, obtainable for any temperature. The method relies on sampling within a hard constraint on likelihood value, as opposed to the softened likelihood of annealing methods. Progress depends only on the shape of the "nested" contours of likelihood, and not on the likelihood values. This invariance (over monotonic re-labelling) allows the method to deal with a class of phase-change problems which effectively defeat thermal annealing.},
  keywords = {algorithm,annealing,Bayesian computation,evidence,marginal likelihood,Model selection,nest,phase change},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Skilling_2006_Nested sampling for general Bayesian computation3.pdf}
}

@article{snelsonWarpedGaussianProcesses,
  title = {Warped {{Gaussian Processes}}},
  author = {Snelson, Edward and Rasmussen, Carl Edward and Ghahramani, Zoubin},
  abstract = {We generalise the Gaussian process (GP) framework for regression by learning a nonlinear transformation of the GP outputs. This allows for non-Gaussian processes and non-Gaussian noise. The learning algorithm chooses a nonlinear transformation such that transformed data is well-modelled by a GP. This can be seen as including a preprocessing transformation as an integral part of the probabilistic modelling problem, rather than as an ad-hoc step. We demonstrate on several real regression problems that learning the transformation can lead to significantly better performance than using a regular GP, or a GP with a fixed transformation.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Snelson et al_Warped Gaussian Processes.pdf}
}

@inproceedings{snoekInputWarpingBayesian2014,
  title = {Input Warping for Bayesian Optimization of Non-Stationary Functions},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning},
  author = {Snoek, Jasper and Swersky, Kevin and Zemel, Rich and Adams, Ryan},
  editor = {Xing, Eric P. and Jebara, Tony},
  year = {2014},
  month = jun,
  series = {Proceedings of Machine Learning Research},
  volume = {32},
  pages = {1674--1682},
  publisher = {{PMLR}},
  address = {{Bejing, China}},
  abstract = {Bayesian optimization has proven to be a highly effective methodology for the global optimization of unknown, expensive and multimodal functions. The ability to accurately model distributions over functions is critical to the effectiveness of Bayesian optimization. Although Gaussian processes provide a flexible prior over functions, there are various classes of functions that remain difficult to model. One of the most frequently occurring of these is the class of non-stationary functions. The optimization of the hyperparameters of machine learning algorithms is a problem domain in which parameters are often manually transformed a priori, for example by optimizing in "log-space", to mitigate the effects of spatially-varying length scale. We develop a methodology for automatically learning a wide family of bijective transformations or warpings of the input space using the Beta cumulative distribution function. We further extend the warping framework to multi-task Bayesian optimization so that multiple tasks can be warped into a jointly stationary space. On a set of challenging benchmark optimization tasks, we observe that the inclusion of warping greatly improves on the state-of-the-art, producing better results faster and more reliably.},
  pdf = {http://proceedings.mlr.press/v32/snoek14.pdf},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Snoek et al_2014_Input Warping for Bayesian Optimization of Non-stationary Functions.pdf}
}

@misc{snoekInputWarpingBayesian2014a,
  title = {Input {{Warping}} for {{Bayesian Optimization}} of {{Non-stationary Functions}}},
  author = {Snoek, Jasper and Swersky, Kevin and Zemel, Richard S. and Adams, Ryan P.},
  year = {2014},
  month = jun,
  number = {arXiv:1402.0929},
  eprint = {1402.0929},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-08-10},
  abstract = {Bayesian optimization has proven to be a highly effective methodology for the global optimization of unknown, expensive and multimodal functions. The ability to accurately model distributions over functions is critical to the effectiveness of Bayesian optimization. Although Gaussian processes provide a flexible prior over functions which can be queried efficiently, there are various classes of functions that remain difficult to model. One of the most frequently occurring of these is the class of non-stationary functions. The optimization of the hyperparameters of machine learning algorithms is a problem domain in which parameters are often manually transformed a priori, for example by optimizing in "log-space," to mitigate the effects of spatially-varying length scale. We develop a methodology for automatically learning a wide family of bijective transformations or warpings of the input space using the Beta cumulative distribution function. We further extend the warping framework to multi-task Bayesian optimization so that multiple tasks can be warped into a jointly stationary space. On a set of challenging benchmark optimization tasks, we observe that the inclusion of warping greatly improves on the state-of-the-art, producing better results faster and more reliably.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/WUZN2KL9/Snoek et al. - 2014 - Input Warping for Bayesian Optimization of Non-sta.pdf;/Users/lichengk/Zotero/storage/H8MAWGF2/1402.html}
}

@inproceedings{snoekPracticalBayesianOptimization2012,
  title = {Practical {{Bayesian Optimization}} of {{Machine Learning Algorithms}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
  year = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2021-08-24},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Snoek et al_2012_Practical Bayesian Optimization of Machine Learning Algorithms.pdf}
}

@article{snoekScalableBayesianOptimization2015,
  title = {Scalable {{Bayesian Optimization Using Deep Neural Networks}}},
  author = {Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Md Mostofa Ali and Prabhat and Adams, Ryan P.},
  year = {2015},
  month = jul,
  journal = {arXiv:1502.05700 [stat]},
  eprint = {1502.05700},
  primaryclass = {stat},
  urldate = {2021-05-27},
  abstract = {Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.},
  archiveprefix = {arxiv},
  keywords = {ObsCite,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Snoek et al_2015_Scalable Bayesian Optimization Using Deep Neural Networks.pdf;/Users/lichengk/Zotero/storage/W2PN7T6W/1502.html}
}

@inproceedings{solinGaussianQuadraturesState2014,
  title = {Gaussian Quadratures for State Space Approximation of Scale Mixtures of Squared Exponential Covariance Functions},
  booktitle = {2014 {{IEEE International Workshop}} on {{Machine Learning}} for {{Signal Processing}} ({{MLSP}})},
  author = {Solin, Arno and Sarkka, Simo},
  year = {2014},
  month = sep,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Reims, France}},
  doi = {10.1109/MLSP.2014.6958899},
  urldate = {2021-09-26},
  abstract = {Stationary one-dimensional Gaussian process models in machine learning can be reformulated as state space equations. This reduces the cubic computational complexity of the naive full GP solution to linear with respect to the number of training data points. For infinitely differentiable covariance functions the representation is an approximation. In this paper, we study a class of covariance functions that can be represented as a scale mixture of squared exponentials. We show how the generalized Gauss\textendash Laguerre quadrature rule can be employed in a state space approximation in this class. The explicit form of the rational quadratic covariance function approximation is written out, and we demonstrate the results in a regression and log-Gaussian Cox process study.},
  isbn = {978-1-4799-3694-6},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/3ENV4QG7/Solin and Sarkka - 2014 - Gaussian quadratures for state space approximation.pdf}
}

@inproceedings{songScoreBasedGenerativeModeling2020,
  title = {Score-{{Based Generative Modeling}} through {{Stochastic Differential Equations}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Song, Yang and {Sohl-Dickstein}, Jascha and Kingma, Diederik P. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  year = {2020},
  month = sep,
  urldate = {2022-06-20},
  abstract = {Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a...},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Song et al_2020_Score-Based Generative Modeling through Stochastic Differential Equations.pdf;/Users/lichengk/Zotero/storage/QB3679E9/forum.html}
}

@article{sorkine-hornungLeastSquaresRigidMotion,
  title = {Least-{{Squares Rigid Motion Using SVD}}},
  author = {{Sorkine-Hornung}, Olga and Rabinovich, Michael},
  pages = {5},
  abstract = {This note summarizes the steps to computing the best-fitting rigid transformation that aligns two sets of corresponding points.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Sorkine-Hornung_Rabinovich_Least-Squares Rigid Motion Using SVD.pdf}
}

@article{SparseGaussianProcess,
  title = {Sparse {{Gaussian Process Approximations}} and {{Applications}}},
  pages = {188},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/9JLAWYT5/Sparse Gaussian Process Approximations and Applica.pdf}
}

@article{speagleDynestyDynamicNested2020,
  title = {Dynesty: {{A Dynamic Nested Sampling Package}} for {{Estimating Bayesian Posteriors}} and {{Evidences}}},
  shorttitle = {Dynesty},
  author = {Speagle, Joshua S.},
  year = {2020},
  month = apr,
  journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {493},
  number = {3},
  eprint = {1904.02180},
  pages = {3132--3158},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/staa278},
  urldate = {2021-08-09},
  abstract = {We present dynesty, a public, open-source, Python package to estimate Bayesian posteriors and evidences (marginal likelihoods) using Dynamic Nested Sampling. By adaptively allocating samples based on posterior structure, Dynamic Nested Sampling has the benefits of Markov Chain Monte Carlo algorithms that focus exclusively on posterior estimation while retaining Nested Sampling's ability to estimate evidences and sample from complex, multi-modal distributions. We provide an overview of Nested Sampling, its extension to Dynamic Nested Sampling, the algorithmic challenges involved, and the various approaches taken to solve them. We then examine dynesty's performance on a variety of toy problems along with several astronomical applications. We find in particular problems dynesty can provide substantial improvements in sampling efficiency compared to popular MCMC approaches in the astronomical literature. More detailed statistical results related to Nested Sampling are also included in the Appendix.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics,Statistics - Computation},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Speagle_2020_dynesty.pdf;/Users/lichengk/Zotero/storage/9KH66BNW/1904.html}
}

@misc{SpectralAnalysisNonuniformly,
  title = {Spectral Analysis of Nonuniformly Sampled Data \textendash{} a Review | {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.dsp.2009.06.019},
  urldate = {2021-12-05},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S1051200409001298?token=FADB79F3063C3379A564492C01131EE407575497909A14887E83058876AF082666CC632CE691ED1417D4B5562C50DE63\&originRegion=eu-west-1\&originCreation=20211205215532},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/3G6K2R7G/S1051200409001298.html}
}

@misc{SpectralMethodsMachine,
  title = {Spectral Methods in Machine Learning and New Strategies for Very Large Datasets},
  doi = {10.1073/pnas.0810600105},
  urldate = {2022-06-01},
  howpublished = {https://www.pnas.org/doi/10.1073/pnas.0810600105},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/TWNI9TV7/Spectral methods in machine learning and new strat.pdf;/Users/lichengk/Zotero/storage/VJ3988CU/pnas.html}
}

@article{srinivasGaussianProcessOptimization2012,
  title = {Gaussian {{Process Optimization}} in the {{Bandit Setting}}: {{No Regret}} and {{Experimental Design}}},
  shorttitle = {Gaussian {{Process Optimization}} in the {{Bandit Setting}}},
  author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M. and Seeger, Matthias},
  year = {2012},
  month = may,
  journal = {IEEE Transactions on Information Theory},
  volume = {58},
  number = {5},
  eprint = {0912.3995},
  pages = {3250--3265},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/TIT.2011.2182033},
  urldate = {2021-10-07},
  abstract = {Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Srinivas et al_2012_Gaussian Process Optimization in the Bandit Setting.pdf;/Users/lichengk/Zotero/storage/BNLDTRWK/0912.html}
}

@inproceedings{stantonKernelInterpolationScalable2021,
  title = {Kernel {{Interpolation}} for {{Scalable Online Gaussian Processes}}},
  booktitle = {Proceedings of {{The}} 24th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Stanton, Samuel and Maddox, Wesley and Delbridge, Ian and Wilson, Andrew Gordon},
  year = {2021},
  month = mar,
  pages = {3133--3141},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2021-11-12},
  abstract = {Gaussian processes (GPs) provide a gold standard for performance in online settings, such as sample-efficient control and black box optimization, where we need to update a posterior distribution as we acquire data in a sequential online setting. However, updating a GP posterior to accommodate even a single new observation after having observed \$n\$ points incurs at least \$\textbackslash mathcal\{O\}(n)\$ computations in the exact setting. We show how to use structured kernel interpolation to efficiently reuse computations for constant-time \$\textbackslash mathcal\{O\}(1)\$ online updates with respect to the number of points \$n\$, while retaining exact inference. We demonstrate the promise of our approach in a range of online regression and classification settings, Bayesian optimization, and active sampling to reduce error in malaria incidence forecasting.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Stanton et al_2021_Kernel Interpolation for Scalable Online Gaussian Processes.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Stanton et al_2021_Kernel Interpolation for Scalable Online Gaussian Processes2.pdf}
}

@book{steinInterpolationSpatialData1999,
  title = {Interpolation of Spatial Data: Some Theory for Kriging},
  shorttitle = {Interpolation of Spatial Data},
  author = {Stein, Michael Leonard and Stein, Michael L.},
  year = {1999},
  series = {Springer Series in Statistics},
  publisher = {{Springer}},
  address = {{New York Berlin Heidelberg}},
  isbn = {978-1-4612-7166-6 978-0-387-98629-6},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Stein_Stein_1999_Interpolation of spatial data2.pdf}
}

@misc{SteinMethod,
  title = {{Stein's method}},
  urldate = {2022-11-07},
  abstract = {Stein's method of approximate computation of expectations was introduced by Stanford statistician Charles Stein in  the early 1970s.  In a nutshell the method advocates to estimate certain classes of expectations in terms of properties of a family of probability-characterising linear operators.},
  howpublished = {https://sites.google.com/site/steinsmethod/home},
  langid = {chinese},
  file = {/Users/lichengk/Zotero/storage/CT3H4DDP/home.html}
}

@book{steinwartSupportVectorMachines2008,
  title = {Support {{Vector Machines}}},
  author = {Steinwart, Ingo and Christmann, Andreas},
  year = {2008},
  series = {Information {{Science}} and {{Statistics}}},
  publisher = {{Springer-Verlag}},
  address = {{New York}},
  doi = {10.1007/978-0-387-77242-4},
  urldate = {2021-08-31},
  abstract = {This book explains the principles that make support vector machines (SVMs) a successful modelling and prediction tool for a variety of applications. The authors present the basic ideas of SVMs together with the latest developments and current research questions in a unified style. They identify three reasons for the success of SVMs: their ability to learn well with only a very small number of free parameters, their robustness against several types of model violations and outliers, and their computational efficiency compared to several other methods. Since their appearance in the early nineties, support vector machines and related kernel-based methods have been successfully applied in diverse fields of application such as bioinformatics, fraud detection, construction of insurance tariffs, direct marketing, and data and text mining. As a consequence, SVMs now play an important role in statistical machine learning and are used not only by statisticians, mathematicians, and computer scientists, but also by engineers and data analysts. The book provides a unique in-depth treatment of both fundamental and recent material on SVMs that so far has been scattered in the literature. The book can thus serve as both a basis for graduate courses and an introduction for statisticians, mathematicians, and computer scientists. It further provides a valuable reference for researchers working in the field. The book covers all important topics concerning support vector machines such as: loss functions and their role in the learning process; reproducing kernel Hilbert spaces and their properties; a thorough statistical analysis that uses both traditional uniform bounds and more advanced localized techniques based on Rademacher averages and Talagrand's inequality; a detailed treatment of classification and regression; a detailed robustness analysis; and a description of some of the most recent implementation techniques. To make the book self-contained, an extensive appendix is added which provides the reader with the necessary background from statistics, probability theory, functional analysis, convex analysis, and topology. Ingo Steinwart is a researcher in the machine learning group at the Los Alamos National Laboratory. He works on support vector machines and related methods. Andreas Christmann is Professor of Stochastics in the Department of Mathematics at the University of Bayreuth. He works in particular on support vector machines and robust statistics.},
  isbn = {978-0-387-77241-7},
  langid = {english}
}

@article{stephensonMeasuringSensitivityGaussian2021,
  title = {Measuring the Sensitivity of {{Gaussian}} Processes to Kernel Choice},
  author = {Stephenson, William T. and Ghosh, Soumya and Nguyen, Tin D. and Yurochkin, Mikhail and Deshpande, Sameer K. and Broderick, Tamara},
  year = {2021},
  month = jun,
  journal = {arXiv:2106.06510 [cs, stat]},
  eprint = {2106.06510},
  primaryclass = {cs, stat},
  urldate = {2021-12-26},
  abstract = {Gaussian processes (GPs) are used to make medical and scientific decisions, including in cardiac care and monitoring of carbon dioxide emissions. But the choice of GP kernel is often somewhat arbitrary. In particular, uncountably many kernels typically align with qualitative prior knowledge (e.g. function smoothness or stationarity). But in practice, data analysts choose among a handful of convenient standard kernels (e.g. squared exponential). In the present work, we ask: Would decisions made with a GP differ under other, qualitatively interchangeable kernels? We show how to formulate this sensitivity analysis as a constrained optimization problem over a finite-dimensional space. We can then use standard optimizers to identify substantive changes in relevant decisions made with a GP. We demonstrate in both synthetic and real-world examples that decisions made with a GP can exhibit substantial sensitivity to kernel choice, even when prior draws are qualitatively interchangeable to a user.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Computation,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Stephenson et al_2021_Measuring the sensitivity of Gaussian processes to kernel choice.pdf;/Users/lichengk/Zotero/storage/HK92CFDQ/2106.html}
}

@article{stiglerEpicStoryMaximum2007,
  title = {The {{Epic Story}} of {{Maximum Likelihood}}},
  author = {Stigler, Stephen M.},
  year = {2007},
  month = nov,
  journal = {Statistical Science},
  volume = {22},
  number = {4},
  eprint = {0804.2996},
  primaryclass = {stat},
  issn = {0883-4237},
  doi = {10.1214/07-STS249},
  urldate = {2023-01-31},
  abstract = {At a superficial level, the idea of maximum likelihood must be prehistoric: early hunters and gatherers may not have used the words ``method of maximum likelihood'' to describe their choice of where and how to hunt and gather, but it is hard to believe they would have been surprised if their method had been described in those terms. It seems a simple, even unassailable idea: Who would rise to argue in favor of a method of minimum likelihood, or even mediocre likelihood? And yet the mathematical history of the topic shows this ``simple idea'' is really anything but simple. Joseph Louis Lagrange, Daniel Bernoulli, Leonard Euler, Pierre Simon Laplace and Carl Friedrich Gauss are only some of those who explored the topic, not always in ways we would sanction today. In this article, that history is reviewed from back well before Fisher to the time of Lucien Le Cam's dissertation. In the process Fisher's unpublished 1930 characterization of conditions for the consistency and efficiency of maximum likelihood estimates is presented, and the mathematical basis of his three proofs discussed. In particular, Fisher's derivation of the information inequality is seen to be derived from his work on the analysis of variance, and his later approach via estimating functions was derived from Euler's Relation for homogeneous functions. The reaction to Fisher's work is reviewed, and some lessons drawn.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Methodology},
  file = {/Users/lichengk/Zotero/storage/HV4XB4GG/Stigler - 2007 - The Epic Story of Maximum Likelihood.pdf;/Users/lichengk/Zotero/storage/7WPYXL9E/0804.html}
}

@inproceedings{stimperResamplingBaseDistributions2022,
  title = {Resampling {{Base Distributions}} of {{Normalizing Flows}}},
  booktitle = {Proceedings of {{The}} 25th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Stimper, Vincent and Sch{\"o}lkopf, Bernhard and {Hernandez-Lobato}, Jose Miguel},
  year = {2022},
  month = may,
  pages = {4915--4936},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-11-23},
  abstract = {Normalizing flows are a popular class of models for approximating probability distributions. However, their invertible nature limits their ability to model target distributions whose support have a complex topological structure, such as Boltzmann distributions. Several procedures have been proposed to solve this problem but many of them sacrifice invertibility and, thereby, tractability of the log-likelihood as well as other desirable properties. To address these limitations, we introduce a base distribution for normalizing flows based on learned rejection sampling, allowing the resulting normalizing flow to model complicated distributions without giving up bijectivity. Furthermore, we develop suitable learning algorithms using both maximizing the log-likelihood and the optimization of the Kullback-Leibler divergence, and apply them to various sample problems, i.e. approximating 2D densities, density estimation of tabular data, image generation, and modeling Boltzmann distributions. In these experiments our method is competitive with or outperforms the baselines.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Stimper et al_2022_Resampling Base Distributions of Normalizing Flows.pdf}
}

@book{stoicaSpectralAnalysisSignals2005,
  title = {Spectral Analysis of Signals},
  author = {Stoica, Petre and Moses, Randolph L.},
  year = {2005},
  publisher = {{Pearson/Prentice Hall}},
  address = {{Upper Saddle River, N.J}},
  isbn = {978-0-13-113956-5},
  langid = {english},
  lccn = {QA320 .S864 2005},
  keywords = {Spectral theory (Mathematics)},
  file = {/Users/lichengk/Zotero/storage/5ZUYH2ZV/Stoica and Moses - 2005 - Spectral analysis of signals.pdf}
}

@book{StructureInterpretationComputer1997,
  title = {Structure and Interpretation of Computer Programs, (Second Edition)},
  year = {1997},
  month = feb,
  volume = {33},
  urldate = {2022-02-03},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/1997_Structure and interpretation of computer programs, (second edition).pdf}
}

@article{stuartPosteriorConsistencyGaussian2017,
  title = {Posterior Consistency for {{Gaussian}} Process Approximations of {{Bayesian}} Posterior Distributions},
  author = {Stuart, Andrew M. and Teckentrup, Aretha L.},
  year = {2017},
  month = aug,
  journal = {Mathematics of Computation},
  volume = {87},
  number = {310},
  pages = {721--753},
  issn = {0025-5718, 1088-6842},
  doi = {10.1090/mcom/3244},
  urldate = {2022-07-03},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Stuart_Teckentrup_2017_Posterior consistency for Gaussian process approximations of Bayesian posterior.pdf}
}

@misc{StudentDistribution,
  title = {Student's t Distribution},
  urldate = {2021-10-11},
  howpublished = {https://www.statlect.com/probability-distributions/student-t-distribution},
  file = {/Users/lichengk/Zotero/storage/FBVS2WEH/student-t-distribution.html}
}

@misc{SubmissionFastPostprocess,
  title = {Submission] {{Fast}} Post-Process {{Bayesian}} Inference with {{Sparse Variational Bayesian Monte Carlo}}},
  urldate = {2022-10-11},
  abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
  howpublished = {https://www.overleaf.com/project/623b3c6cbfd8b095e177fa03},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/YYK3QSCH/623b3c6cbfd8b095e177fa03.html}
}

@article{submissionWhatAreBayesian,
  title = {What {{Are Bayesian Neural Network Posteriors Really Like}}?},
  author = {Submission, Anonymous},
  pages = {20},
  abstract = {The posterior over Bayesian neural network (BNN) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as meanfield variational inference or stochastic-gradient Markov chain Monte Carlo (SGMCMC). To investigate foundational questions in Bayesian deep learning, we instead use full-batch Hamiltonian Monte Carlo (HMC) on modern architectures. We show that (1) BNNs can achieve significant performance gains over standard training; (2) a single long HMC chain can provide a comparable representation of the posterior to multiple shorter chains; (3) in contrast to recent studies, we find posterior tempering is not needed for near-optimal performance, with little evidence for a ``cold posterior'' effect; (4) BMA performance is robust to the choice of prior variance scale; (5) Bayesian neural networks show surprisingly poor generalization under domain shift; (6) while cheaper alternatives such as deep ensembles and SGMCMC methods can provide strong performance, they fail to match the predictive distributions attained by HMC.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/PA24D6K5/Submission - What Are Bayesian Neural Network Posteriors Really.pdf}
}

@inproceedings{subrQNETNetworkLowdimensional2021,
  title = {Q-{{NET}}: {{A Network}} for {{Low-dimensional Integrals}} of {{Neural Proxies}}},
  shorttitle = {Q-{{NET}}},
  booktitle = {Computer {{Graphics Forum}}},
  author = {Subr, Kartic},
  year = {2021},
  volume = {40},
  pages = {61--71},
  publisher = {{Wiley Online Library}},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Subr_2021_Q-NET.pdf;/Users/lichengk/Zotero/storage/7EJ487GD/cgf.html}
}

@article{suiSafeExplorationOptimization,
  title = {Safe {{Exploration}} for {{Optimization}} with {{Gaussian Processes}}(Extended Version with Supplementary Material)},
  author = {Sui, Yanan and Gotovos, Alkis and Burdick, Joel W and Krause, Andreas},
  pages = {12},
  abstract = {We consider sequential decision problems under uncertainty, where we seek to optimize an unknown function from noisy samples. This requires balancing exploration (learning about the objective) and exploitation (localizing the maximum), a problem well-studied in the multiarmed bandit literature. In many applications, however, we require that the sampled function values exceed some prespecified ``safety'' threshold, a requirement that existing algorithms fail to meet. Examples include medical applications where patient comfort must be guaranteed, recommender systems aiming to avoid user dissatisfaction, and robotic control, where one seeks to avoid controls causing physical harm to the platform. We tackle this novel, yet rich, set of problems under the assumption that the unknown function satisfies regularity conditions expressed via a Gaussian process prior. We develop an efficient algorithm called SAFEOPT, and theoretically guarantee its convergence to a natural notion of optimum reachable under safety constraints. We evaluate SAFEOPT on synthetic data, as well as two real applications: movie recommendation, and therapeutic spinal cord stimulation.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/B6VE8FR9/Sui et al. - Safe Exploration for Optimization with Gaussian Pr.pdf}
}

@article{sunScalableVariationalGaussian2021,
  title = {Scalable {{Variational Gaussian Processes}} via {{Harmonic Kernel Decomposition}}},
  author = {Sun, Shengyang and Shi, Jiaxin and Wilson, Andrew Gordon and Grosse, Roger},
  year = {2021},
  month = jun,
  journal = {arXiv:2106.05992 [cs, stat]},
  eprint = {2106.05992},
  primaryclass = {cs, stat},
  urldate = {2021-12-26},
  abstract = {We introduce a new scalable variational Gaussian process approximation which provides a high fidelity approximation while retaining general applicability. We propose the harmonic kernel decomposition (HKD), which uses Fourier series to decompose a kernel as a sum of orthogonal kernels. Our variational approximation exploits this orthogonality to enable a large number of inducing points at a low computational cost. We demonstrate that, on a range of regression and classification problems, our approach can exploit input space symmetries such as translations and reflections, and it significantly outperforms standard variational methods in scalability and accuracy. Notably, our approach achieves state-of-the-art results on CIFAR-10 among pure GP models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Sun et al_2021_Scalable Variational Gaussian Processes via Harmonic Kernel Decomposition.pdf;/Users/lichengk/Zotero/storage/RMJDWB4V/2106.html}
}

@misc{sunScalableVariationalGaussian2021a,
  title = {Scalable {{Variational Gaussian Processes}} via {{Harmonic Kernel Decomposition}}},
  author = {Sun, Shengyang and Shi, Jiaxin and Wilson, Andrew Gordon and Grosse, Roger},
  year = {2021},
  month = jun,
  number = {arXiv:2106.05992},
  eprint = {2106.05992},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-11-09},
  abstract = {We introduce a new scalable variational Gaussian process approximation which provides a high fidelity approximation while retaining general applicability. We propose the harmonic kernel decomposition (HKD), which uses Fourier series to decompose a kernel as a sum of orthogonal kernels. Our variational approximation exploits this orthogonality to enable a large number of inducing points at a low computational cost. We demonstrate that, on a range of regression and classification problems, our approach can exploit input space symmetries such as translations and reflections, and it significantly outperforms standard variational methods in scalability and accuracy. Notably, our approach achieves state-of-the-art results on CIFAR-10 among pure GP models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/A8HAS8TJ/Sun et al. - 2021 - Scalable Variational Gaussian Processes via Harmon.pdf;/Users/lichengk/Zotero/storage/LMUYWDPG/2106.html}
}

@article{sutherlandErrorRandomFourier,
  title = {On the {{Error}} of {{Random Fourier Features}}},
  author = {Sutherland, Dougal J and Schneider, Jeff},
  pages = {18},
  abstract = {Kernel methods give powerful, flexible, and theoretically grounded approaches to solving many problems in machine learning. The standard approach, however, requires pairwise evaluations of a kernel function, which can lead to scalability issues for very large datasets. Rahimi and Recht (2007) suggested a popular approach to handling this problem, known as random Fourier features. The quality of this approximation, however, is not well understood. We improve the uniform error bound of that paper, as well as giving novel understandings of the embedding's variance, approximation error, and use in some machine learning methods. We also point out that surprisingly, of the two main variants of those features, the more widely used is strictly highervariance for the Gaussian kernel and has worse bounds.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/I9ZZZBND/Sutherland and Schneider - On the Error of Random Fourier Features.pdf}
}

@article{tanExplicitNaturalGradient2022,
  title = {Explicit Natural Gradient Updates for {{Cholesky}} Factor in {{Gaussian}} Variational Approximation},
  author = {Tan, Linda S. L.},
  year = {2022},
  month = feb,
  journal = {arXiv:2109.00375 [stat]},
  eprint = {2109.00375},
  primaryclass = {stat},
  urldate = {2022-03-22},
  abstract = {Stochastic gradient methods have enabled variational inference for high-dimensional models and large data. However, the steepest ascent direction in the parameter space of a statistical model is given not by the commonly used Euclidean gradient, but the natural gradient which premultiplies the Euclidean gradient by the inverted Fisher information matrix. Use of natural gradients can improve convergence significantly, but inverting the Fisher information matrix is daunting in high-dimensions. In Gaussian variational approximation, natural gradient updates of the natural parameters (expressed in terms of the mean and precision matrix) of the Gaussian distribution can be derived analytically, but do not ensure the precision matrix remains positive definite. To tackle this issue, we consider Cholesky decomposition of the covariance or precision matrix and derive explicit natural gradient updates of the Cholesky factor, which depend only on the first instead of the second derivative of the log posterior density, by finding the inverse of the Fisher information matrix analytically. Efficient natural gradient updates of the Cholesky factor are also derived under sparsity constraints incorporating different posterior independence structures.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Computation},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Tan_2022_Explicit natural gradient updates for Cholesky factor in Gaussian variational.pdf;/Users/lichengk/Zotero/storage/E4P6I25H/2109.html}
}

@misc{tangNoteMonteCarlo2022,
  title = {A {{Note}} on {{Monte Carlo Integration}} in {{High Dimensions}}},
  author = {Tang, Yanbo},
  year = {2022},
  month = jun,
  number = {arXiv:2206.09036},
  eprint = {2206.09036},
  primaryclass = {stat},
  publisher = {{arXiv}},
  urldate = {2022-11-21},
  abstract = {Monte Carlo integration is a commonly used technique to compute intractable integrals. However, it is typically thought to perform poorly for very high-dimensional integrals. Therefore, we examine Monte Carlo integration using techniques from high-dimensional statistics in which we allow the dimension of the integral to increase. In doing so, we derive non-asymptotic bounds for the relative and absolute error of the approximation for some general functions through concentration inequalities. We demonstrate that the scaling in the number of points sampled to guarantee a consistent estimate can vary between polynomial to exponential, depending on the function being integrated, demonstrating that the behaviour of Monte Carlo integration in high dimensions is not uniform. Through our methods we also obtain non-asymptotic confidence intervals for the Monte Carlo estimate which are valid regardless of the number of points sampled.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Methodology},
  file = {/Users/lichengk/Zotero/storage/DVGLJ9GX/Tang - 2022 - A Note on Monte Carlo Integration in High Dimensio.pdf;/Users/lichengk/Zotero/storage/9Q4SB86G/2206.html}
}

@article{tebbuttCombiningPseudoPointState2021,
  title = {Combining {{Pseudo-Point}} and {{State Space Approximations}} for {{Sum-Separable Gaussian Processes}}},
  author = {Tebbutt, Will and Solin, Arno and Turner, Richard E.},
  year = {2021},
  month = jun,
  journal = {arXiv:2106.10210 [cs, stat]},
  eprint = {2106.10210},
  primaryclass = {cs, stat},
  urldate = {2021-08-18},
  abstract = {Gaussian processes (GPs) are important probabilistic tools for inference and learning in spatio-temporal modelling problems such as those in climate science and epidemiology. However, existing GP approximations do not simultaneously support large numbers of off-the-grid spatial data-points and long time-series which is a hallmark of many applications. Pseudo-point approximations, one of the gold-standard methods for scaling GPs to large data sets, are well suited for handling off-the-grid spatial data. However, they cannot handle long temporal observation horizons effectively reverting to cubic computational scaling in the time dimension. State space GP approximations are well suited to handling temporal data, if the temporal GP prior admits a Markov form, leading to linear complexity in the number of temporal observations, but have a cubic spatial cost and cannot handle off-the-grid spatial data. In this work we show that there is a simple and elegant way to combine pseudo-point methods with the state space GP approximation framework to get the best of both worlds. The approach hinges on a surprising conditional independence property which applies to space--time separable GPs. We demonstrate empirically that the combined approach is more scalable and applicable to a greater range of spatio-temporal problems than either method on its own.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Tebbutt et al_2021_Combining Pseudo-Point and State Space Approximations for Sum-Separable.pdf;/Users/lichengk/Zotero/storage/TTXIFL9M/2106.html}
}

@misc{tebbuttCombiningPseudoPointState2021a,
  title = {Combining {{Pseudo-Point}} and {{State Space Approximations}} for {{Sum-Separable Gaussian Processes}}},
  author = {Tebbutt, Will and Solin, Arno and Turner, Richard E.},
  year = {2021},
  month = jun,
  number = {arXiv:2106.10210},
  eprint = {2106.10210},
  primaryclass = {cs, stat},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.2106.10210},
  urldate = {2022-05-20},
  abstract = {Gaussian processes (GPs) are important probabilistic tools for inference and learning in spatio-temporal modelling problems such as those in climate science and epidemiology. However, existing GP approximations do not simultaneously support large numbers of off-the-grid spatial data-points and long time-series which is a hallmark of many applications. Pseudo-point approximations, one of the gold-standard methods for scaling GPs to large data sets, are well suited for handling off-the-grid spatial data. However, they cannot handle long temporal observation horizons effectively reverting to cubic computational scaling in the time dimension. State space GP approximations are well suited to handling temporal data, if the temporal GP prior admits a Markov form, leading to linear complexity in the number of temporal observations, but have a cubic spatial cost and cannot handle off-the-grid spatial data. In this work we show that there is a simple and elegant way to combine pseudo-point methods with the state space GP approximation framework to get the best of both worlds. The approach hinges on a surprising conditional independence property which applies to space--time separable GPs. We demonstrate empirically that the combined approach is more scalable and applicable to a greater range of spatio-temporal problems than either method on its own.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/PUJT5PEP/Tebbutt et al. - 2021 - Combining Pseudo-Point and State Space Approximati.pdf;/Users/lichengk/Zotero/storage/G6CGZE2E/2106.html}
}

@article{teymurBlackBoxProbabilistic2021,
  title = {Black {{Box Probabilistic Numerics}}},
  author = {Teymur, Onur and Foley, Christopher N. and Breen, Philip G. and Karvonen, Toni and Oates, Chris},
  year = {2021},
  journal = {arXiv preprint arXiv:2106.13718},
  eprint = {2106.13718},
  archiveprefix = {arxiv},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Teymur et al_2021_Black Box Probabilistic Numerics.pdf;/Users/lichengk/Zotero/storage/ZLBT5V2R/2106.html}
}

@article{titsiasFunctionalRegularisationContinual2020,
  title = {Functional {{Regularisation}} for {{Continual Learning}} with {{Gaussian Processes}}},
  author = {Titsias, Michalis K. and Schwarz, Jonathan and Matthews, Alexander G. de G. and Pascanu, Razvan and Teh, Yee Whye},
  year = {2020},
  month = feb,
  journal = {arXiv:1901.11356 [cs, stat]},
  eprint = {1901.11356},
  primaryclass = {cs, stat},
  urldate = {2022-04-11},
  abstract = {We introduce a framework for Continual Learning (CL) based on Bayesian inference over the function space rather than the parameters of a deep neural network. This method, referred to as functional regularisation for Continual Learning, avoids forgetting a previous task by constructing and memorising an approximate posterior belief over the underlying task-specific function. To achieve this we rely on a Gaussian process obtained by treating the weights of the last layer of a neural network as random and Gaussian distributed. Then, the training algorithm sequentially encounters tasks and constructs posterior beliefs over the task-specific functions by using inducing point sparse Gaussian process methods. At each step a new task is first learnt and then a summary is constructed consisting of (i) inducing inputs -- a fixed-size subset of the task inputs selected such that it optimally represents the task -- and (ii) a posterior distribution over the function values at these inputs. This summary then regularises learning of future tasks, through Kullback-Leibler regularisation terms. Our method thus unites approaches focused on (pseudo-)rehearsal with those derived from a sequential Bayesian inference perspective in a principled way, leading to strong results on accepted benchmarks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/A7CPN5Y4/Titsias et al. - 2020 - Functional Regularisation for Continual Learning w.pdf;/Users/lichengk/Zotero/storage/RG6HQSUX/1901.html}
}

@inproceedings{titsiasVariationalLearningInducing2009,
  title = {Variational {{Learning}} of {{Inducing Variables}} in {{Sparse Gaussian Processes}}},
  booktitle = {Artificial {{Intelligence}} and {{Statistics}}},
  author = {Titsias, Michalis},
  year = {2009},
  month = apr,
  pages = {567--574},
  publisher = {{PMLR}},
  issn = {1938-7228},
  urldate = {2021-08-18},
  langid = {english},
  keywords = {ObsCite,seminal},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Titsias_2009_Variational Learning of Inducing Variables in Sparse Gaussian Processes.pdf}
}

@article{titsiasVariationalModelSelection,
  title = {Variational {{Model Selection}} for {{Sparse Gaussian Process Regression}}},
  author = {Titsias, Michalis K},
  pages = {20},
  abstract = {Sparse Gaussian process methods that use inducing variables require the selection of the inducing inputs and the kernel hyperparameters. We introduce a variational formulation for sparse approximations that jointly infers the inducing inputs and the kernel hyperparameters by maximizing a lower bound of the true log marginal likelihood. The key property of this formulation is that the inducing inputs are defined to be variational parameters which are selected by minimizing the Kullback-Leibler divergence between the variational distribution and the exact posterior distribution over the latent function values. We apply this technique to regression and we compare it with other approaches in the literature.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Titsias_Variational Model Selection for Sparse Gaussian Process Regression.pdf}
}

@misc{tranAllYouNeed2022,
  title = {All {{You Need}} Is a {{Good Functional Prior}} for {{Bayesian Deep Learning}}},
  author = {Tran, Ba-Hien and Rossi, Simone and Milios, Dimitrios and Filippone, Maurizio},
  year = {2022},
  month = apr,
  number = {arXiv:2011.12829},
  eprint = {2011.12829},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2011.12829},
  urldate = {2022-12-01},
  abstract = {The Bayesian treatment of neural networks dictates that a prior distribution is specified over their weight and bias parameters. This poses a challenge because modern neural networks are characterized by a large number of parameters, and the choice of these priors has an uncontrolled effect on the induced functional prior, which is the distribution of the functions obtained by sampling the parameters from their prior distribution. We argue that this is a hugely limiting aspect of Bayesian deep learning, and this work tackles this limitation in a practical and effective way. Our proposal is to reason in terms of functional priors, which are easier to elicit, and to "tune" the priors of neural network parameters in a way that they reflect such functional priors. Gaussian processes offer a rigorous framework to define prior distributions over functions, and we propose a novel and robust framework to match their prior with the functional prior of neural networks based on the minimization of their Wasserstein distance. We provide vast experimental evidence that coupling these priors with scalable Markov chain Monte Carlo sampling offers systematically large performance improvements over alternative choices of priors and state-of-the-art approximate Bayesian deep learning approaches. We consider this work a considerable step in the direction of making the long-standing challenge of carrying out a fully Bayesian treatment of neural networks, including convolutional neural networks, a concrete possibility.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/Zotero/storage/T23RKWMY/Tran et al. - 2022 - All You Need is a Good Functional Prior for Bayesi.pdf;/Users/lichengk/Zotero/storage/Y6S3HRSJ/2011.html}
}

@article{tranFunctionalPriorsBayesian,
  title = {Functional {{Priors}} for {{Bayesian Neural Networks}} through {{Wasserstein Distance Minimization}} to {{Gaussian Processes}}},
  author = {Tran, Ba-Hien and Milios, Dimitrios and Rossi, Simone and Filippone, Maurizio},
  abstract = {The Bayesian treatment of neural networks dictates that a prior distribution is considered over the weight and bias parameters of the network. The non-linear nature of the model implies that any distribution of the parameters has an unpredictable effect on the distribution of the function output. Gaussian processes offer a rigorous framework to define prior distributions over the space of functions. Our proposal is to impose such functional priors on well-established architectures of neural networks by means of minimising the Wasserstein distance between samples of stochastic processes. Early experimental results demonstrate the potential of functional priors for Bayesian neural networks.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Tran et al_Functional Priors for Bayesian Neural Networks through Wasserstein Distance.pdf}
}

@article{tranVariationalGaussianProcess2016a,
  title = {The {{Variational Gaussian Process}}},
  author = {Tran, Dustin and Ranganath, Rajesh and Blei, David M.},
  year = {2016},
  month = apr,
  journal = {arXiv:1511.06499 [cs, stat]},
  eprint = {1511.06499},
  primaryclass = {cs, stat},
  urldate = {2021-08-23},
  abstract = {Variational inference is a powerful tool for approximate inference, and it has been recently applied for representation learning with deep generative models. We develop the variational Gaussian process (VGP), a Bayesian nonparametric variational family, which adapts its shape to match complex posterior distributions. The VGP generates approximate posterior samples by generating latent inputs and warping them through random non-linear mappings; the distribution over random mappings is learned during inference, enabling the transformed outputs to adapt to varying complexity. We prove a universal approximation theorem for the VGP, demonstrating its representative power for learning any model. For inference we present a variational objective inspired by auto-encoders and perform black box inference over a wide class of models. The VGP achieves new state-of-the-art results for unsupervised learning, inferring models such as the deep latent Gaussian model and the recently proposed DRAW.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Computation,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Tran et al_2016_The Variational Gaussian Process.pdf;/Users/lichengk/Zotero/storage/2R2KHF6I/1511.html}
}

@article{trefethenExactnessQuadratureFormulas2021,
  title = {Exactness of Quadrature Formulas},
  author = {Trefethen, Lloyd N.},
  year = {2021},
  month = jan,
  journal = {arXiv:2101.09501 [cs, math]},
  eprint = {2101.09501},
  primaryclass = {cs, math},
  urldate = {2021-10-05},
  abstract = {The standard design principle for quadrature formulas is that they should be exact for integrands of a given class, such as polynomials of a fixed degree. We show how this principle fails to predict the actual behavior in four cases: Newton-Cotes, Clenshaw-Curtis, Gauss-Legendre, and Gauss-Hermite quadrature. Three further examples are mentioned more briefly.},
  archiveprefix = {arxiv},
  keywords = {{41A55, 65D32},Mathematics - Numerical Analysis},
  file = {/Users/lichengk/Zotero/storage/UP72TU9E/Trefethen - 2021 - Exactness of quadrature formulas.pdf;/Users/lichengk/Zotero/storage/2B25RGXA/2101.html}
}

@inproceedings{tronarpMixtureRepresentationMatern2018,
  title = {Mixture {{Representation}} of the {{Mat\'ern Class}} with {{Applications}} in {{State Space Approximations}} and {{Bayesian Quadrature}}},
  booktitle = {2018 {{IEEE}} 28th {{International Workshop}} on {{Machine Learning}} for {{Signal Processing}} ({{MLSP}})},
  author = {Tronarp, Filip and Karvonen, Toni and Sarkka, Simo},
  year = {2018},
  month = sep,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Aalborg}},
  doi = {10.1109/MLSP.2018.8516992},
  urldate = {2021-09-23},
  abstract = {In this paper, the connection between the Mat\'ern kernel and scale mixtures of squared exponential kernels is explored. It is shown that the Mat\'ern kernel can be approximated by a finite scale mixture of squared exponential kernels through a quadrature approximation which in turn allows for (i) state space approximations of the Mat\'ern kernel for arbitrary smoothness parameters using established state space approximations of the squared exponential kernel and (ii) exact calculation of the Bayesian quadrature weights for the approximate kernel under a Gaussian measure. The method is demonstrated in inference in a log-Gaussian Cox process as well as in approximating a Gaussian integral arising from a financial problem using Bayesian quadrature.},
  isbn = {978-1-5386-5477-4},
  langid = {english},
  keywords = {ObsCite,相关性高},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Tronarp et al_2018_MIXTURE REPRESENTATION OF THE MATÉRN CLASS WITH APPLICATIONS IN STATE SPACE.pdf}
}

@misc{turnerIntroductionTransformers2023,
  title = {An {{Introduction}} to {{Transformers}}},
  author = {Turner, Richard E.},
  year = {2023},
  month = apr,
  number = {arXiv:2304.10557},
  eprint = {2304.10557},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-05-25},
  abstract = {The transformer is a neural network component that can be used to learn useful representations of sequences or sets of datapoints. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Turner_2023_An Introduction to Transformers.pdf;/Users/lichengk/Zotero/storage/K9IKQBDY/2304.html}
}

@incollection{turnerTwoProblemsVariational2011,
  title = {Two Problems with Variational Expectation Maximisation for Time Series Models},
  booktitle = {Bayesian {{Time Series Models}}},
  author = {Turner, Richard Eric and Sahani, Maneesh},
  editor = {Barber, David and Cemgil, A. Taylan and Chiappa, Silvia},
  year = {2011},
  pages = {104--124},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511984679.006},
  urldate = {2021-08-24},
  isbn = {978-0-511-98467-9},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Turner_Sahani_2011_Two problems with variational expectation maximisation for time series models.pdf}
}

@article{ubaruFastEstimationTr2017,
  title = {Fast {{Estimation}} of \$tr(f({{A}}))\$ via {{Stochastic Lanczos Quadrature}}},
  author = {Ubaru, Shashanka and Chen, Jie and Saad, Yousef},
  year = {2017},
  month = jan,
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {38},
  number = {4},
  pages = {1075--1099},
  issn = {0895-4798, 1095-7162},
  doi = {10.1137/16M1104974},
  urldate = {2021-10-18},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/MHTUS2SS/Ubaru et al. - 2017 - Fast Estimation of $tr(f(A))$ via Stochastic Lancz.pdf}
}

@article{ubaruFastMethodsEstimating,
  title = {Fast Methods for Estimating the {{Numerical}} Rank of Large Matrices},
  author = {Ubaru, Shashanka and Saad, Yousef},
  pages = {15},
  abstract = {We present two computationally inexpensive techniques for estimating the numerical rank of a matrix, combining powerful tools from computational linear algebra. These techniques exploit three key ingredients. The first is to approximate the projector on the non-null invariant subspace of the matrix by using a polynomial filter. Two types of filters are discussed, one based on Hermite interpolation and the other based on Chebyshev expansions. The second ingredient employs stochastic trace estimators to compute the rank of this wanted eigen-projector, which yields the desired rank of the matrix. In order to obtain a good filter, it is necessary to detect a gap between the eigenvalues that correspond to noise and the relevant eigenvalues that correspond to the non-null invariant subspace. The third ingredient of the proposed approaches exploits the idea of spectral density, popular in physics, and the Lanczos spectroscopic method to locate this gap.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/SBF8HHL8/Ubaru and Saad - Fast methods for estimating the Numerical rank of .pdf}
}

@misc{uclcentreforartificialintelligenceGaussianProcessesFun2020,
  title = {Gaussian Processes for Fun and Profit: {{Probabilistic}} Machine Learning in Industry},
  shorttitle = {Gaussian Processes for Fun and Profit},
  author = {{UCL Centre for Artificial Intelligence}},
  year = {2020},
  month = nov,
  urldate = {2022-03-04},
  abstract = {Seminar by S.T. John,  Senior Machine Learning Researcher, Secondmind Labs  at the UCL Centre for AI. Recorded on the 4th November 2020. Abstract When companies, whether start-ups or big corporations, talk about "machine learning" they usually mean some kind of neural network model. Not always though: I will talk about why instead we put a lot of our efforts on probabilistic models built using Gaussian processes. When a Machine Learning course briefly covers Gaussian processes, you might go away thinking they're just basis function interpolation, only apply when the noise is Gaussian, and don't scale to larger datasets. Here I will discuss why these are misconceptions and show why Gaussian processes are both interesting and useful in practical applications. Bio Ti is a senior machine learning researcher in the probabilistic modelling team at Secondmind Labs, where they have been working on a broad range of customer and research projects involving Gaussian processes. Ti believes in making research output reusable by integrating it in common toolboxes and is core maintainer of the GPflow open source project for Gaussian process modelling.}
}

@article{universityLearningSpectralKernels,
  title = {Learning with {{Spectral Kernels}}},
  author = {University, Markus Heinonen Aalto},
  pages = {59},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/FSCEGZD5/University - Learning with Spectral Kernels.pdf;/Users/lichengk/Zotero/storage/UFADXG57/University - Learning with Spectral Kernels.pdf}
}

@article{vaitlGradientsShouldStay2022,
  title = {Gradients Should Stay on Path: Better Estimators of the Reverse- and Forward {{KL}} Divergence for Normalizing Flows},
  shorttitle = {Gradients Should Stay on Path},
  author = {Vaitl, Lorenz and Nicoli, Kim A and Nakajima, Shinichi and Kessel, Pan},
  year = {2022},
  month = dec,
  journal = {Machine Learning: Science and Technology},
  volume = {3},
  number = {4},
  pages = {045006},
  issn = {2632-2153},
  doi = {10.1088/2632-2153/ac9455},
  urldate = {2022-12-13},
  abstract = {Abstract             We show how to use the path-wise derivative estimator for both the forward reverse Kullback\textendash Leibler divergence for any practically invertible normalizing flow. The resulting path-gradient estimators are straightforward to implement, have lower variance, and lead not only to faster convergence of training but also to better overall approximation results compared to standard total gradient estimators. We also demonstrate that path-gradient training is less susceptible to mode-collapse. In light of our results, we expect that path-gradient estimators will become the new standard method to train normalizing flows for variational inference.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/CJ2YU33B/Vaitl et al. - 2022 - Gradients should stay on path better estimators o.pdf}
}

@inproceedings{vakiliScalableThompsonSampling2021,
  title = {Scalable {{Thompson Sampling}} Using {{Sparse Gaussian Process Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vakili, Sattar and Moss, Henry and Artemev, Artem and Dutordoir, Vincent and Picheny, Victor},
  year = {2021},
  volume = {34},
  pages = {5631--5643},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-01-31},
  abstract = {Thompson Sampling (TS) from Gaussian Process (GP) models is a powerful tool for the optimization of black-box functions. Although TS enjoys strong theoretical guarantees and convincing empirical performance, it incurs a large computational overhead that scales polynomially with the optimization budget. Recently, scalable TS methods based on sparse GP models have been proposed to increase the scope of TS, enabling its application to problems that are sufficiently multi-modal, noisy or combinatorial to require more than a few hundred evaluations to be solved. However, the approximation error introduced by sparse GPs invalidates all existing regret bounds. In this work, we perform a theoretical and empirical analysis of scalable TS. We provide theoretical guarantees and show that the drastic reduction in computational complexity of scalable TS can be enjoyed without loss in the regret performance over the standard TS. These conceptual claims are validated for practical implementations of scalable TS on synthetic benchmarks and as part of a real-world high-throughput molecular design task.},
  file = {/Users/lichengk/Zotero/storage/GIN6N7VC/Vakili et al. - 2021 - Scalable Thompson Sampling using Sparse Gaussian P.pdf}
}

@article{vanderplasUnderstandingLombScargle2018,
  title = {Understanding the {{Lomb}}\textendash{{Scargle Periodogram}}},
  author = {VanderPlas, Jacob T.},
  year = {2018},
  month = may,
  journal = {The Astrophysical Journal Supplement Series},
  volume = {236},
  number = {1},
  pages = {16},
  publisher = {{IOP Publishing}},
  issn = {0067-0049},
  doi = {10.3847/1538-4365/aab766},
  urldate = {2021-12-07},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/VanderPlas_2018_Understanding the Lomb–Scargle Periodogram.pdf;/Users/lichengk/Zotero/storage/M9I4MD6P/aab766.html}
}

@article{vandervaartInformationRatesNonparametric2011,
  title = {Information Rates of Nonparametric Gaussian Process Methods},
  author = {{van der Vaart}, Aad and {van Zanten}, Harry},
  year = {2011},
  journal = {Journal of Machine Learning Research},
  volume = {12},
  number = {60},
  pages = {2095--2119}
}

@article{vanderwilkFrameworkInterdomainMultioutput2020,
  title = {A {{Framework}} for {{Interdomain}} and {{Multioutput Gaussian Processes}}},
  author = {{van der Wilk}, Mark and Dutordoir, Vincent and John, S. T. and Artemev, Artem and Adam, Vincent and Hensman, James},
  year = {2020},
  month = mar,
  journal = {arXiv:2003.01115 [cs, stat]},
  eprint = {2003.01115},
  primaryclass = {cs, stat},
  urldate = {2022-03-04},
  abstract = {One obstacle to the use of Gaussian processes (GPs) in large-scale problems, and as a component in deep learning system, is the need for bespoke derivations and implementations for small variations in the model or inference. In order to improve the utility of GPs we need a modular system that allows rapid implementation and testing, as seen in the neural network community. We present a mathematical and software framework for scalable approximate inference in GPs, which combines interdomain approximations and multiple outputs. Our framework, implemented in GPflow, provides a unified interface for many existing multioutput models, as well as more recent convolutional structures. This simplifies the creation of deep models with GPs, and we hope that this work will encourage more interest in this approach.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/XIJKK6SX/van der Wilk et al. - 2020 - A Framework for Interdomain and Multioutput Gaussi.pdf;/Users/lichengk/Zotero/storage/PQZUEKD5/2003.html}
}

@article{vanderwilkLearningInvariancesUsing2018,
  title = {Learning {{Invariances}} Using the {{Marginal Likelihood}}},
  author = {{van der Wilk}, Mark and Bauer, Matthias and John, S. T. and Hensman, James},
  year = {2018},
  month = aug,
  journal = {arXiv:1808.05563 [cs, stat]},
  eprint = {1808.05563},
  primaryclass = {cs, stat},
  urldate = {2022-02-25},
  abstract = {Generalising well in supervised learning tasks relies on correctly extrapolating the training data to a large region of the input space. One way to achieve this is to constrain the predictions to be invariant to transformations on the input that are known to be irrelevant (e.g. translation). Commonly, this is done through data augmentation, where the training set is enlarged by applying hand-crafted transformations to the inputs. We argue that invariances should instead be incorporated in the model structure, and learned using the marginal likelihood, which correctly rewards the reduced complexity of invariant models. We demonstrate this for Gaussian process models, due to the ease with which their marginal likelihood can be estimated. Our main contribution is a variational inference scheme for Gaussian processes containing invariances described by a sampling procedure. We learn the sampling procedure by back-propagating through it to maximise the marginal likelihood.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/Zotero/storage/FGAWMVT3/van der Wilk et al. - 2018 - Learning Invariances using the Marginal Likelihood.pdf;/Users/lichengk/Zotero/storage/BVGHVFLF/1808.html}
}

@article{vandeschootBayesianStatisticsModelling2021,
  title = {Bayesian Statistics and Modelling},
  author = {{van de Schoot}, Rens and Depaoli, Sarah and King, Ruth and Kramer, Bianca and M{\"a}rtens, Kaspar and Tadesse, Mahlet G. and Vannucci, Marina and Gelman, Andrew and Veen, Duco and Willemsen, Joukje and Yau, Christopher},
  year = {2021},
  month = dec,
  journal = {Nature Reviews Methods Primers},
  volume = {1},
  number = {1},
  pages = {1},
  issn = {2662-8449},
  doi = {10.1038/s43586-020-00001-2},
  urldate = {2021-08-27},
  abstract = {Bayesian statistics is an approach to data analysis based on Bayes' theorem, where available knowledge about parameters in a statistical model is updated with the information in observed data. The background knowledge is expressed as a prior distribution and combined with observational data in the form of a likelihood function to determine the posterior distribution. The posterior can also be used for making predictions about future events. This Primer describes the stages involved in Bayesian analysis, from specifying the prior and data models to deriving inference, model checking and refinement. We discuss the importance of prior and posterior predictive checking, selecting a proper technique for sampling from a posterior distribution, variational inference and variable selection. Examples of successful applications of Bayesian analysis across various research fields are provided, including in social sciences, ecology, genetics, medicine and more. We propose strategies for reproducibility and reporting standards, outlining an updated WAMBS (when to Worry and how to Avoid the Misuse of Bayesian Statistics) checklist. Finally, we outline the impact of Bayesian analysis on artificial intelligence, a major goal in the next decade.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/4FQP37IH/s43586-020-00001-2.pdf}
}

@inproceedings{vanervenOpenProblemFast2020,
  title = {Open Problem: {{Fast}} and Optimal Online Portfolio Selection},
  booktitle = {Proceedings of Thirty Third Conference on Learning Theory},
  author = {Van Erven, Tim and {Van der Hoeven}, Dirk and Kot{\l}owski, Wojciech and Koolen, Wouter M.},
  editor = {Abernethy, Jacob and Agarwal, Shivani},
  year = {2020},
  month = jul,
  series = {Proceedings of Machine Learning Research},
  volume = {125},
  pages = {3864--3869},
  publisher = {{PMLR}},
  abstract = {Online portfolio selection has received much attention in the COLT community since its introduction by Cover, but all state-of-the-art methods fall short in at least one of the following ways: they are either i) computationally infeasible; or ii) they do not guarantee optimal regret; or iii) they assume the gradients are bounded, which is unnecessary and cannot be guaranteed. We are interested in a natural follow-the-regularized-leader (FTRL) approach based on the log barrier regularizer, which is computationally feasible. The open problem we put before the community is to formally prove whether this approach achieves the optimal regret. Resolving this question will likely lead to new techniques to analyse FTRL algorithms. There are also interesting technical connections to self-concordance, which has previously been used in the context of bandit convex optimization.},
  pdf = {http://proceedings.mlr.press/v125/van-erven20a/van-erven20a.pdf},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Van Erven et al_2020_Open problem.pdf}
}

@article{vanhataloAdvancedBayesianInference,
  title = {Advanced {{Bayesian Inference}}},
  author = {Vanhatalo, Jarno},
  abstract = {These are lecture notes for the course Advanced Bayesian Inference. These notes are not comprehensive list of all coarse content but summarize some of the key issues covered during the course. Other course material is listed in course Moodle page. These notes will be updated during the course. Be also aware that the notes have not been proofread thoroughly so they may contain typos. The update history of the notes is the following: \textbullet{} 14.3.2022 First version released \textbullet{} 22.3.2022 Some typo fixes in Sections 2.4-2.6. \textbullet{} 22.3.2022 Some typo fixes in Sections 2.7-3.3.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/8L6NLJNY/Vanhatalo - Advanced Bayesian Inference.pdf}
}

@article{vapnikOverviewStatisticalLearning1999,
  title = {An Overview of Statistical Learning Theory},
  author = {Vapnik, V.N.},
  year = {Sept./1999},
  journal = {IEEE Transactions on Neural Networks},
  volume = {10},
  number = {5},
  pages = {988--999},
  issn = {10459227},
  doi = {10.1109/72.788640},
  urldate = {2021-05-09},
  abstract = {Statistical learning theory was introduced in the late 1960's. Until the 1990's it was a purely theoretical analysis of the problem of function estimation from a given collection of data. In the middle of the 1990's new types of learning algorithms (called support vector machines) based on the developed theory were proposed. This made statistical learning theory not only a tool for the theoretical analysis but also a tool for creating practical algorithms for estimating multidimensional functions. This article presents a very general overview of statistical learning theory including both theoretical and algorithmic aspects of the theory. The goal of this overview is to demonstrate how the abstract learning theory established conditions for generalization which are more general than those discussed in classical statistical paradigms and how the understanding of these conditions inspired new algorithmic approaches to function estimation problems. A more detailed overview of the theory (without proofs) can be found in Vapnik (1995). In Vapnik (1998) one can find detailed description of the theory (including proofs).},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Vapnik_1999_An overview of statistical learning theory.pdf}
}

@misc{VariationalGaussianProcess,
  title = {The {{Variational Gaussian Process}} | {{Paper}} | {{Microsoft Academic}}},
  urldate = {2021-08-25},
  howpublished = {https://academic.microsoft.com/paper/2979719808/citedby/search?q=The\%20Variational\%20Gaussian\%20Process\&qe=RId\%253D2979719808\&f=\&orderBy=0}
}

@article{vehtariSurveyBayesianPredictive2012,
  title = {A Survey of {{Bayesian}} Predictive Methods for Model Assessment, Selection and Comparison},
  author = {Vehtari, Aki and Ojanen, Janne},
  year = {2012},
  month = jan,
  journal = {Statistics Surveys},
  volume = {6},
  number = {none},
  pages = {142--228},
  publisher = {{Amer. Statist. Assoc., the Bernoulli Soc., the Inst. Math. Statist., and the Statist. Soc. Canada}},
  issn = {1935-7516},
  doi = {10.1214/12-SS102},
  urldate = {2023-06-09},
  abstract = {To date, several methods exist in the statistical literature for model assessment, which purport themselves specifically as Bayesian predictive methods. The decision theoretic assumptions on which these methods are based are not always clearly stated in the original articles, however. The aim of this survey is to provide a unified review of Bayesian predictive model assessment and selection methods, and of methods closely related to them. We review the various assumptions that are made in this context and discuss the connections between different approaches, with an emphasis on how each method approximates the expected utility of using a Bayesian model for the purpose of predicting future data.},
  keywords = {62-02,62C10,Bayesian,cross-validation,decision theory,Expected utility,information criteria,model assessment,Model selection,predictive},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Vehtari_Ojanen_2012_A survey of Bayesian predictive methods for model assessment, selection and.pdf}
}

@misc{velickovicEverythingConnectedGraph2023,
  title = {Everything Is {{Connected}}: {{Graph Neural Networks}}},
  shorttitle = {Everything Is {{Connected}}},
  author = {Veli{\v c}kovi{\'c}, Petar},
  year = {2023},
  month = jan,
  number = {arXiv:2301.08210},
  eprint = {2301.08210},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-20},
  abstract = {In many ways, graphs are the main modality of data we receive from nature. This is due to the fact that most of the patterns we see, both in natural and artificial systems, are elegantly representable using the language of graph structures. Prominent examples include molecules (represented as graphs of atoms and bonds), social networks and transportation networks. This potential has already been seen by key scientific and industrial groups, with already-impacted application areas including traffic forecasting, drug discovery, social network analysis and recommender systems. Further, some of the most successful domains of application for machine learning in previous years -- images, text and speech processing -- can be seen as special cases of graph representation learning, and consequently there has been significant exchange of information between these areas. The main aim of this short survey is to enable the reader to assimilate the key concepts in the area, and position graph representation learning in a proper context with related fields.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Veličković_2023_Everything is Connected.pdf;/Users/lichengk/Zotero/storage/ZMFT2M9M/2301.html}
}

@misc{verineExpressivityBiLipschitzNormalizing2022,
  title = {On the Expressivity of Bi-{{Lipschitz}} Normalizing Flows},
  author = {Verine, Alexandre and Negrevergne, Benjamin and Rossi, Fabrice and Chevaleyre, Yann},
  year = {2022},
  month = feb,
  number = {arXiv:2107.07232},
  eprint = {2107.07232},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-01-18},
  abstract = {An invertible function is bi-Lipschitz if both the function and its inverse have bounded Lipschitz constants. Nowadays, most Normalizing Flows are bi-Lipschitz by design or by training to limit numerical errors (among other things). In this paper, we discuss the expressivity of bi-Lipschitz Normalizing Flows and identify several target distributions that are difficult to approximate using such models. Then, we characterize the expressivity of bi-Lipschitz Normalizing Flows by giving several lower bounds on the Total Variation distance between these particularly unfavorable distributions and their best possible approximation. Finally, we discuss potential remedies which include using more complex latent distributions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Verine et al_2022_On the expressivity of bi-Lipschitz normalizing flows.pdf;/Users/lichengk/Zotero/storage/K2UBNWFI/2107.html}
}

@book{vershyninHighdimensionalProbabilityIntroduction2018,
  title = {High-Dimensional Probability: An Introduction with Applications in Data Science},
  shorttitle = {High-Dimensional Probability},
  author = {Vershynin, Roman},
  year = {2018},
  series = {Cambridge Series in Statistical and Probabilistic Mathematics},
  number = {47},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge ; New York, NY}},
  isbn = {978-1-108-41519-4},
  lccn = {QA273 .V4485 2018},
  keywords = {Probabilities,Random variables,Stochastic processes},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Vershynin_2018_High-dimensional probability.pdf}
}

@book{vetterliFoundationsSignalProcessing2014,
  title = {Foundations of Signal Processing},
  author = {Vetterli, Martin and Kova{\v c}evi{\'c}, Jelena and Goyal, Vivek K.},
  year = {2014},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  isbn = {978-1-107-03860-8},
  langid = {english},
  lccn = {TK5102.9 .V479 2014},
  keywords = {Signal processing},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Vetterli et al_2014_Foundations of signal processing.pdf}
}

@article{wagstaffBatchSelectionParallelisation2018,
  title = {Batch {{Selection}} for {{Parallelisation}} of {{Bayesian Quadrature}}},
  author = {Wagstaff, Ed and Hamid, Saad and Osborne, Michael},
  year = {2018},
  month = dec,
  journal = {arXiv:1812.01553 [cs, stat]},
  eprint = {1812.01553},
  primaryclass = {cs, stat},
  urldate = {2021-05-21},
  abstract = {Integration over non-negative integrands is a central problem in machine learning (e.g. for model averaging, (hyper-)parameter marginalisation, and computing posterior predictive distributions). Bayesian Quadrature is a probabilistic numerical integration technique that performs promisingly when compared to traditional Markov Chain Monte Carlo methods. However, in contrast to easily-parallelised MCMC methods, Bayesian Quadrature methods have, thus far, been essentially serial in nature, selecting a single point to sample at each step of the algorithm. We deliver methods to select batches of points at each step, based upon those recently presented in the Batch Bayesian Optimisation literature. Such parallelisation significantly reduces computation time, especially when the integrand is expensive to sample.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wagstaff et al_2018_Batch Selection for Parallelisation of Bayesian Quadrature.pdf;/Users/lichengk/Zotero/storage/UHHNEXC9/1812.html}
}

@book{wainwrightHighDimensionalStatisticsNonAsymptotic2019,
  title = {High-{{Dimensional Statistics}}: {{A Non-Asymptotic Viewpoint}}},
  shorttitle = {High-{{Dimensional Statistics}}},
  author = {Wainwright, Martin J.},
  year = {2019},
  month = feb,
  edition = {First},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108627771},
  urldate = {2022-08-26},
  isbn = {978-1-108-62777-1 978-1-108-49802-9},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wainwright_2019_High-Dimensional Statistics.pdf}
}

@article{walkerBayesianInferenceMisspecified2013,
  title = {Bayesian Inference with Misspecified Models},
  author = {Walker, Stephen G.},
  year = {2013},
  month = oct,
  journal = {Journal of Statistical Planning and Inference},
  volume = {143},
  number = {10},
  pages = {1621--1633},
  issn = {03783758},
  doi = {10.1016/j.jspi.2013.05.013},
  urldate = {2023-05-22},
  abstract = {This article reviews Bayesian inference from the perspective that the designated model is misspecified. This misspecification has implications in interpretation of objects, such as the prior distribution, which has been the cause of recent questioning of the appropriateness of Bayesian inference in this scenario. The main focus of this article is to establish the suitability of applying the Bayes update to a misspecified model, and relies on representation theorems for sequences of symmetric distributions; the identification of parameter values of interest; and the construction of sequences of distributions which act as the guesses as to where the next observation is coming from. A conclusion is that a clear identification of the fundamental starting point for the Bayesian is described.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Walker_2013_Bayesian inference with misspecified models.pdf}
}

@article{wangAdaptiveGaussianProcess2018,
  title = {Adaptive {{Gaussian}} Process Approximation for {{Bayesian}} Inference with Expensive Likelihood Functions},
  author = {Wang, Hongqiao and Li, Jinglai},
  year = {2018},
  month = mar,
  journal = {arXiv:1703.09930 [stat]},
  eprint = {1703.09930},
  primaryclass = {stat},
  urldate = {2021-09-27},
  abstract = {We consider Bayesian inference problems with computationally intensive likelihood functions. We propose a Gaussian process (GP) based method to approximate the joint distribution of the unknown parameters and the data. In particular, we write the joint density approximately as a product of an approximate posterior density and an exponentiated GP surrogate. We then provide an adaptive algorithm to construct such an approximation, where an active learning method is used to choose the design points. With numerical examples, we illustrate that the proposed method has competitive performance against existing approaches for Bayesian computation.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/N2PMZLW8/Wang and Li - 2018 - Adaptive Gaussian process approximation for Bayesi.pdf;/Users/lichengk/Zotero/storage/4RXPH9YR/1703.html}
}

@article{wangBayesianOptimizationBillion2016,
  title = {Bayesian {{Optimization}} in a {{Billion Dimensions}} via {{Random Embeddings}}},
  author = {Wang, Ziyu and Hutter, Frank and Zoghi, Masrour and Matheson, David and De Feitas, Nando},
  year = {2016},
  month = feb,
  journal = {Journal of Artificial Intelligence Research},
  volume = {55},
  pages = {361--387},
  issn = {1076-9757},
  doi = {10.1613/jair.4806},
  urldate = {2021-05-27},
  abstract = {Bayesian optimization techniques have been successfully applied to robotics, planning, sensor placement, recommendation, advertising, intelligent user interfaces and automatic algorithm configuration. Despite these successes, the approach is restricted to problems of moderate dimension, and several workshops on Bayesian optimization have identified its scaling to high-dimensions as one of the holy grails of the field. In this paper, we introduce a novel random embedding idea to attack this problem. The resulting Random EMbedding Bayesian Optimization (REMBO) algorithm is very simple, has important invariance properties, and applies to domains with both categorical and continuous variables. We present a thorough theoretical analysis of REMBO. Empirical results confirm that REMBO can effectively solve problems with billions of dimensions, provided the intrinsic dimensionality is low. They also show that REMBO achieves state-of-the-art performance in optimizing the 47 discrete parameters of a popular mixed integer linear programming solver.},
  langid = {english},
  keywords = {ObsCite,toread},
  annotation = {186 citations (Semantic Scholar/DOI) [2021-06-03]},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wang et al_2016_Bayesian Optimization in a Billion Dimensions via Random Embeddings.pdf}
}

@article{wangExactGaussianProcesses2019,
  title = {Exact {{Gaussian Processes}} on a {{Million Data Points}}},
  author = {Wang, Ke Alexander and Pleiss, Geoff and Gardner, Jacob R. and Tyree, Stephen and Weinberger, Kilian Q. and Wilson, Andrew Gordon},
  year = {2019},
  month = dec,
  journal = {arXiv:1903.08114 [cs, stat]},
  eprint = {1903.08114},
  primaryclass = {cs, stat},
  urldate = {2022-02-15},
  abstract = {Gaussian processes (GPs) are flexible non-parametric models, with a capacity that grows with the available data. However, computational constraints with standard inference procedures have limited exact GPs to problems with fewer than about ten thousand training points, necessitating approximations for larger datasets. In this paper, we develop a scalable approach for exact GPs that leverages multi-GPU parallelization and methods like linear conjugate gradients, accessing the kernel matrix only through matrix multiplication. By partitioning and distributing kernel matrix multiplies, we demonstrate that an exact GP can be trained on over a million points, a task previously thought to be impossible with current computing hardware, in less than 2 hours. Moreover, our approach is generally applicable, without constraints to grid data or specific kernel classes. Enabled by this scalability, we perform the first-ever comparison of exact GPs against scalable GP approximations on datasets with \$10\^4 \textbackslash!-\textbackslash! 10\^6\$ data points, showing dramatic performance improvements.},
  archiveprefix = {arxiv},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wang et al_2019_Exact Gaussian Processes on a Million Data Points.pdf;/Users/lichengk/Zotero/storage/LWDWHVFD/1903.html}
}

@article{wangGeneralMethodRobust2018,
  title = {A {{General Method}} for {{Robust Bayesian Modeling}}},
  author = {Wang, Chong and Blei, David M.},
  year = {2018},
  month = dec,
  journal = {Bayesian Analysis},
  volume = {13},
  number = {4},
  issn = {1936-0975},
  doi = {10.1214/17-BA1090},
  urldate = {2022-12-15},
  abstract = {Robust Bayesian models are appealing alternatives to standard models, providing protection from data that contains outliers or other departures from the model assumptions. Historically, robust models were mostly developed on a case-by-case basis; examples include robust linear regression, robust mixture models, and bursty topic models. In this paper we develop a general approach to robust Bayesian modeling. We show how to turn an existing Bayesian model into a robust model, and then develop a generic computational strategy for it. We use our method to study robust variants of several models, including linear regression, Poisson regression, logistic regression, and probabilistic topic models. We discuss the connections between our methods and existing approaches, especially empirical Bayes and James\textendash Stein estimation.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wang_Blei_2018_A General Method for Robust Bayesian Modeling.pdf}
}

@article{warrenGeneralizedBayesianQuadrature,
  title = {Generalized {{Bayesian Quadrature}} with {{Spectral Kernels}}},
  author = {Warren, Houston and Oliveira, Rafael and Ramos, Fabio},
  pages = {11},
  abstract = {Bayesian probabilistic integration, or Bayesian quadrature (BQ), has arisen as a popular means of numerical integral estimation with quantified uncertainty for problems where computational cost limits data availability. BQ leverages flexible Gaussian processes (GPs) to model an integrand which can be subsequently analytically integrated through properties of Gaussian distributions. However, BQ is inherently limited by the fact that the method relies on the use of a strict set of kernels for use in the GP model of the integrand, reducing the flexibility of the method in modeling varied integrand types. In this paper, we present spectral Bayesian quadrature, a form of Bayesian quadrature that allows for the use of any shift-invariant kernel in the integrand GP model while still maintaining the analytical tractability of the integral posterior, increasing the flexibility of BQ methods to address varied problem settings. Additionally our method enables integration with respect to a uniform expectation, effectively computing definite integrals of challenging integrands. We derive the theory and error bounds for this model, as well as demonstrate GBQ's improved accuracy, flexibility, and data efficiency, compared to traditional BQ and other numerical integration methods, on a variety of quadrature problems.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/Zotero/storage/2ZPTYLJJ/Warren et al. - Generalized Bayesian Quadrature with Spectral Kern.pdf}
}

@book{wassermanAllStatisticsConcise2010,
  title = {All of Statistics: A Concise Course in Statistical Inference},
  shorttitle = {All of Statistics},
  author = {Wasserman, Larry},
  year = {2010},
  series = {Springer Texts in Statistics},
  edition = {Corrected second printing, 2005},
  publisher = {{Springer}},
  address = {{New York, NY}},
  isbn = {978-1-4419-2322-6 978-0-387-21736-9},
  langid = {english},
  annotation = {OCLC: 837651382},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wasserman_2010_All of statistics.pdf}
}

@unpublished{wassermanNonparametricBayesianMethods2012,
  title = {Nonparametric {{Bayesian Methods}}},
  author = {Wasserman, Larry},
  year = {2012},
  urldate = {2021-08-22},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wasserman_2012_Nonparametric Bayesian Methods.pdf}
}

@article{welandaweRobustAutomatedAccurate2022,
  title = {Robust, {{Automated}}, and {{Accurate Black-box Variational Inference}}},
  author = {Welandawe, Manushi and Andersen, Michael Riis and Vehtari, Aki and Huggins, Jonathan H.},
  year = {2022},
  month = mar,
  journal = {arXiv:2203.15945 [cs, stat]},
  eprint = {2203.15945},
  primaryclass = {cs, stat},
  urldate = {2022-04-06},
  abstract = {Black-box variational inference (BBVI) now sees widespread use in machine learning and statistics as a fast yet flexible alternative to Markov chain Monte Carlo methods for approximate Bayesian inference. However, stochastic optimization methods for BBVI remain unreliable and require substantial expertise and hand-tuning to apply effectively. In this paper, we propose Robust, Automated, and Accurate BBVI (RAABBVI), a framework for reliable BBVI optimization. RAABBVI is based on rigorously justified automation techniques, includes just a small number of intuitive tuning parameters, and detects inaccurate estimates of the optimal variational approximation. RAABBVI adaptively decreases the learning rate by detecting convergence of the fixed--learning-rate iterates, then estimates the symmetrized Kullback--Leiber (KL) divergence between the current variational approximation and the optimal one. It also employs a novel optimization termination criterion that enables the user to balance desired accuracy against computational cost by comparing (i) the predicted relative decrease in the symmetrized KL divergence if a smaller learning were used and (ii) the predicted computation required to converge with the smaller learning rate. We validate the robustness and accuracy of RAABBVI through carefully designed simulation studies and on a diverse set of real-world model and data examples.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Welandawe et al_2022_Robust, Automated, and Accurate Black-box Variational Inference.pdf;/Users/lichengk/Zotero/storage/GUANH8PK/2203.html}
}

@misc{WelcomeBayesianModeling,
  title = {Welcome \textemdash{} {{Bayesian Modeling}} and {{Computation}} in {{Python}}},
  urldate = {2023-04-23},
  howpublished = {https://bayesiancomputationbook.com/welcome.html}
}

@book{wendlandScatteredDataApproximation2004,
  title = {Scattered {{Data Approximation}}},
  author = {Wendland, Holger},
  year = {2004},
  series = {Cambridge {{Monographs}} on {{Applied}} and {{Computational Mathematics}}},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511617539},
  urldate = {2021-09-24},
  abstract = {Many practical applications require the reconstruction of a multivariate function from discrete, unstructured data. This book gives a self-contained, complete introduction into this subject. It concentrates on truly meshless methods such as radial basis functions, moving least squares, and partitions of unity. The book starts with an overview on typical applications of scattered data approximation, coming from surface reconstruction, fluid-structure interaction, and the numerical solution of partial differential equations. It then leads the reader from basic properties to the current state of research, addressing all important issues, such as existence, uniqueness, approximation properties, numerical stability, and efficient implementation. Each chapter ends with a section giving information on the historical background and hints for further reading. Complete proofs are included, making this perfectly suited for graduate courses on multivariate approximation and it can be used to support courses in computer-aided geometric design, and meshless methods for partial differential equations.},
  isbn = {978-0-521-84335-5},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wendland_2004_Scattered Data Approximation.pdf;/Users/lichengk/Zotero/storage/K6AT6VGU/980EEC9DBC4CAA711D089187818135E3.html}
}

@article{wengerReducingVarianceGaussian2021,
  title = {Reducing the {{Variance}} of {{Gaussian Process Hyperparameter Optimization}} with {{Preconditioning}}},
  author = {Wenger, Jonathan and Pleiss, Geoff and Hennig, Philipp and Cunningham, John P. and Gardner, Jacob R.},
  year = {2021},
  month = jul,
  journal = {arXiv:2107.00243 [cs, math]},
  eprint = {2107.00243},
  primaryclass = {cs, math},
  urldate = {2021-10-18},
  abstract = {Gaussian processes remain popular as a flexible and expressive model class, but the computational cost of kernel hyperparameter optimization stands as a major limiting factor to their scaling and broader adoption. Recent work has made great strides combining stochastic estimation with iterative numerical techniques, essentially boiling down GP inference to the cost of (many) matrix-vector multiplies. Preconditioning -- a highly effective step for any iterative method involving matrix-vector multiplication -- can be used to accelerate convergence and thus reduce bias in hyperparameter optimization. Here, we prove that preconditioning has an additional benefit that has been previously unexplored. It not only reduces the bias of the \$\textbackslash log\$-marginal likelihood estimator and its derivatives, but it also simultaneously can reduce variance at essentially negligible cost. We leverage this result to derive sample-efficient algorithms for GP hyperparameter optimization requiring as few as \$\textbackslash mathcal\{O\}(\textbackslash log(\textbackslash varepsilon\^\{-1\}))\$ instead of \$\textbackslash mathcal\{O\}(\textbackslash varepsilon\^\{-2\})\$ samples to achieve error \$\textbackslash varepsilon\$. Our theoretical results enable provably efficient and scalable optimization of kernel hyperparameters, which we validate empirically on a set of large-scale benchmark problems. There, variance reduction via preconditioning results in an order of magnitude speedup in hyperparameter optimization of exact GPs.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis},
  file = {/Users/lichengk/Zotero/storage/IUNFFTQB/Wenger et al. - 2021 - Reducing the Variance of Gaussian Process Hyperpar.pdf;/Users/lichengk/Zotero/storage/TEQKE2I4/2107.html}
}

@article{wilkinsonBayesNewtonMethodsApproximate2021,
  title = {Bayes-{{Newton Methods}} for {{Approximate Bayesian Inference}} with {{PSD Guarantees}}},
  author = {Wilkinson, William J. and S{\"a}rkk{\"a}, Simo and Solin, Arno},
  year = {2021},
  month = nov,
  journal = {arXiv:2111.01721 [cs, stat]},
  eprint = {2111.01721},
  primaryclass = {cs, stat},
  urldate = {2022-02-18},
  abstract = {We formulate natural gradient variational inference (VI), expectation propagation (EP), and posterior linearisation (PL) as extensions of Newton's method for optimising the parameters of a Bayesian posterior distribution. This viewpoint explicitly casts inference algorithms under the framework of numerical optimisation. We show that common approximations to Newton's method from the optimisation literature, namely Gauss-Newton and quasi-Newton methods (e.g., the BFGS algorithm), are still valid under this 'Bayes-Newton' framework. This leads to a suite of novel algorithms which are guaranteed to result in positive semi-definite covariance matrices, unlike standard VI and EP. Our unifying viewpoint provides new insights into the connections between various inference schemes. All the presented methods apply to any model with a Gaussian prior and non-conjugate likelihood, which we demonstrate with (sparse) Gaussian processes and state space models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wilkinson et al_2021_Bayes-Newton Methods for Approximate Bayesian Inference with PSD Guarantees2.pdf;/Users/lichengk/Zotero/storage/QEK4JR2A/2111.html}
}

@inproceedings{williamsComputingInfiniteNetworks1996,
  title = {Computing with {{Infinite Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Williams, Christopher},
  year = {1996},
  volume = {9},
  publisher = {{MIT Press}},
  urldate = {2023-06-05},
  abstract = {For  neural  networks  with  a  wide  class  of weight-priors,  it  can  be  shown  that  in  the  limit  of an  infinite  number of hidden  units  the  prior over functions  tends to a  Gaussian process.  In  this paper an(cid:173) alytic forms are derived for the covariance function of the Gaussian  processes  corresponding  to networks with sigmoidal and Gaussian  hidden  units.  This  allows predictions  to  be  made efficiently  using  networks  with an infinite number of hidden units,  and shows  that,  somewhat paradoxically, it may be  easier  to compute with infinite  networks  than finite  ones.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Williams_1996_Computing with Infinite Networks.pdf}
}

@inproceedings{williamsUsingNystromMethod2001,
  title = {Using the {{Nystr\"om Method}} to {{Speed Up Kernel Machines}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Williams, Christopher and Seeger, Matthias},
  year = {2001},
  volume = {13},
  publisher = {{MIT Press}},
  urldate = {2022-02-15},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Williams_Seeger_2001_Using the Nyström Method to Speed Up Kernel Machines.pdf}
}

@misc{wilsonBayesianDeepLearning2022,
  title = {Bayesian {{Deep Learning}} and a {{Probabilistic Perspective}} of {{Generalization}}},
  author = {Wilson, Andrew Gordon and Izmailov, Pavel},
  year = {2022},
  month = mar,
  number = {arXiv:2002.08791},
  eprint = {2002.08791},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-02-02},
  abstract = {The key distinguishing property of a Bayesian approach is marginalization, rather than using a single setting of weights. Bayesian marginalization can particularly improve the accuracy and calibration of modern deep neural networks, which are typically underspecified by the data, and can represent many compelling but different solutions. We show that deep ensembles provide an effective mechanism for approximate Bayesian marginalization, and propose a related approach that further improves the predictive distribution by marginalizing within basins of attraction, without significant overhead. We also investigate the prior over functions implied by a vague distribution over neural network weights, explaining the generalization properties of such models from a probabilistic perspective. From this perspective, we explain results that have been presented as mysterious and distinct to neural network generalization, such as the ability to fit images with random labels, and show that these results can be reproduced with Gaussian processes. We also show that Bayesian model averaging alleviates double descent, resulting in monotonic performance improvements with increased flexibility. Finally, we provide a Bayesian perspective on tempering for calibrating predictive distributions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/AVFBLBXW/Wilson and Izmailov - 2022 - Bayesian Deep Learning and a Probabilistic Perspec.pdf;/Users/lichengk/Zotero/storage/RU2WATGS/2002.html}
}

@inproceedings{wilsonCopulaProcesses2010,
  title = {Copula {{Processes}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wilson, Andrew G and Ghahramani, Zoubin},
  year = {2010},
  volume = {23},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-12-12},
  abstract = {We define a copula process which describes the dependencies between arbitrarily many random variables independently of their marginal distributions. As an example, we develop a stochastic volatility model, Gaussian Copula Process Volatility (GCPV), to predict the latent standard deviations of a sequence of random variables. To make predictions we use Bayesian inference, with the Laplace approximation, and with Markov chain Monte Carlo as an alternative. We find our model can outperform GARCH on simulated and financial data. And unlike GARCH, GCPV can easily handle missing data, incorporate covariates other than time, and model a rich class of covariance structures.},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wilson_Ghahramani_2010_Copula Processes.pdf}
}

@article{wilsonCorrectionSpectralMixture,
  title = {Correction to {{Spectral Mixture}} ({{SM}}) {{Kernel Derivation}} for {{Multidimensional Inputs}}},
  author = {Wilson, Andrew Gordon},
  pages = {2},
  abstract = {This note corrects a typo in the spectral mixture kernel in Wilson and Adams (2013) for the case of multidimensional inputs.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wilson_Correction to Spectral Mixture (SM) Kernel Derivation for Multidimensional.pdf}
}

@phdthesis{wilsonCovarianceKernelsFast2014,
  title = {Covariance {{Kernels}} for {{Fast Automatic Pattern Discovery}} and {{Extrapolation}} with {{Gaussian Processes}}},
  author = {Wilson, Andrew Gordon},
  year = {2014},
  abstract = {Truly intelligent systems are capable of pattern discovery and extrapolation without human intervention. Bayesian nonparametric models, which can uniquely represent expressive prior information and detailed inductive biases, provide a distinct opportunity to develop intelligent systems, with applications in essentially any learning and prediction task.},
  langid = {english},
  keywords = {toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wilson_2014_Covariance Kernels for Fast Automatic Pattern Discovery and Extrapolation with.pdf}
}

@inproceedings{wilsonEfficientlySamplingFunctions2020,
  title = {Efficiently Sampling Functions from {{Gaussian}} Process Posteriors},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  author = {Wilson, James and Borovitskiy, Viacheslav and Terenin, Alexander and Mostowsky, Peter and Deisenroth, Marc},
  editor = {III, Hal Daum{\'e} and Singh, Aarti},
  year = {2020},
  month = jul,
  series = {Proceedings of Machine Learning Research},
  volume = {119},
  pages = {10292--10302},
  publisher = {{PMLR}},
  abstract = {Gaussian processes are the gold standard for many real-world modeling problems, especially in cases where a model's success hinges upon its ability to faithfully represent predictive uncertainty. These problems typically exist as parts of larger frameworks, wherein quantities of interest are ultimately defined by integrating over posterior distributions. These quantities are frequently intractable, motivating the use of Monte Carlo methods. Despite substantial progress in scaling up Gaussian processes to large training sets, methods for accurately generating draws from their posterior distributions still scale cubically in the number of test locations. We identify a decomposition of Gaussian processes that naturally lends itself to scalable sampling by separating out the prior from the data. Building off of this factorization, we propose an easy-to-use and general-purpose approach for fast posterior sampling, which seamlessly pairs with sparse approximations to afford scalability both during training and at test time. In a series of experiments designed to test competing sampling schemes' statistical properties and practical ramifications, we demonstrate how decoupled sample paths accurately represent Gaussian process posteriors at a fraction of the usual cost.},
  pdf = {http://proceedings.mlr.press/v119/wilson20a/wilson20a.pdf},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wilson et al_2020_Efficiently sampling functions from Gaussian process posteriors.pdf;/Users/lichengk/OneDrive/Zotero/attachments/Wilson et al_2020_Efficiently sampling functions from Gaussian process posteriors2.pdf}
}

@article{wilsonEvaluatingApproximateInference,
  title = {Evaluating {{Approximate Inference}} in {{Bayesian Deep Learning}}},
  author = {Wilson, Andrew Gordon and Izmailov, Pavel and Hoffman, Matthew D and Gal, Yarin and Li, Yingzhen and Pradier, Melanie F and Vikram, Sharad and Foong, Andrew and Lotfi, Sanae and Farquhar, Sebastian},
  pages = {14},
  abstract = {Uncertainty representation is crucial to the safe and reliable deployment of deep learning. Bayesian methods provide a natural mechanism to represent epistemic uncertainty, leading to improved generalization and calibrated predictive distributions. Bayesian methods are particularly promising for deep neural networks, which can represent many different explanations to a given problem corresponding to different settings of parameters. While approximate inference procedures in Bayesian deep learning are improving in scalability and generalization performance, there has been no way of knowing, until now, whether these methods are working as intended, to provide ever more faithful representations of the Bayesian predictive distribution. In this competition we provide the first opportunity to measure the fidelity of approximate inference procedures in deep learning through comparison to Hamiltonian Monte Carlo (HMC). HMC is a highly efficient and well-studied Markov Chain Monte Carlo (MCMC) method that is guaranteed to asymptotically produce samples from the true posterior, but is prohibitively expensive in modern deep learning. To address this computational challenge, we have parallelized the computation over hundreds of tensor processing unit (TPU) devices.},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/Zotero/storage/VE3EV4U2/Wilson et al. - Evaluating Approximate Inference in Bayesian Deep .pdf}
}

@article{wilsonFastKernelLearning,
  title = {Fast {{Kernel Learning}} for {{Multidimensional Pattern Extrapolation}}},
  author = {Wilson, Andrew Gordon and Nehorai, Arye and Gilboa, Elad and Cunningham, John P},
  pages = {18},
  abstract = {The ability to automatically discover patterns and perform extrapolation is an essential quality of intelligent systems. Kernel methods, such as Gaussian processes, have great potential for pattern extrapolation, since the kernel flexibly and interpretably controls the generalisation properties of these methods. However, automatically extrapolating large scale multidimensional patterns is in general difficult, and developing Gaussian process models for this purpose involves several challenges. A vast majority of kernels, and kernel learning methods, currently only succeed in smoothing and interpolation. This difficulty is compounded by the fact that Gaussian processes are typically only tractable for small datasets, and scaling an expressive kernel learning approach poses different challenges than scaling a standard Gaussian process model. One faces additional computational constraints, and the need to retain significant model structure for expressing the rich information available in a large dataset. In this paper, we propose a Gaussian process approach for large scale multidimensional pattern extrapolation. We recover sophisticated out of class kernels, perform texture extrapolation, inpainting, and video extrapolation, and long range forecasting of land surface temperatures, all on large multidimensional datasets, including a problem with 383,400 training points. The proposed method significantly outperforms alternative scalable and flexible Gaussian process methods, in speed and accuracy. Moreover, we show that a distinct combination of expressive kernels, a fully non-parametric representation, and scalable inference which exploits existing model structure, are critical for large scale multidimensional pattern extrapolation.},
  langid = {english},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wilson et al_Fast Kernel Learning for Multidimensional Pattern Extrapolation.pdf}
}

@article{wilsonGaussianProcessKernels,
  title = {Gaussian {{Process Kernels}} for {{Pattern Discovery}} and {{Extrapolation}}},
  author = {Wilson, Andrew Gordon and Adams, Ryan Prescott},
  pages = {9},
  abstract = {Gaussian processes are rich distributions over functions, which provide a Bayesian nonparametric approach to smoothing and interpolation. We introduce simple closed form kernels that can be used with Gaussian processes to discover patterns and enable extrapolation. These kernels are derived by modelling a spectral density \textendash{} the Fourier transform of a kernel \textendash{} with a Gaussian mixture. The proposed kernels support a broad class of stationary covariances, but Gaussian process inference remains simple and analytic. We demonstrate the proposed kernels by discovering patterns and performing long range extrapolation on synthetic examples, as well as atmospheric CO2 trends and airline passenger data. We also show that it is possible to reconstruct several popular standard covariances within our framework.},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wilson_Adams_Gaussian Process Kernels for Pattern Discovery and Extrapolation.pdf}
}

@article{wilsonMaximizingAcquisitionFunctions2018,
  title = {Maximizing Acquisition Functions for {{Bayesian}} Optimization},
  author = {Wilson, James T. and Hutter, Frank and Deisenroth, Marc Peter},
  year = {2018},
  month = dec,
  journal = {arXiv:1805.10196 [cs, stat]},
  eprint = {1805.10196},
  primaryclass = {cs, stat},
  urldate = {2021-10-04},
  abstract = {Bayesian optimization is a sample-efficient approach to global optimization that relies on theoretically motivated value heuristics (acquisition functions) to guide its search process. Fully maximizing acquisition functions produces the Bayes' decision rule, but this ideal is difficult to achieve since these functions are frequently non-trivial to optimize. This statement is especially true when evaluating queries in parallel, where acquisition functions are routinely non-convex, high-dimensional, and intractable. We first show that acquisition functions estimated via Monte Carlo integration are consistently amenable to gradient-based optimization. Subsequently, we identify a common family of acquisition functions, including EI and UCB, whose properties not only facilitate but justify use of greedy approaches for their maximization.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,toread},
  file = {/Users/lichengk/Zotero/storage/LIFZTBTG/Wilson et al. - 2018 - Maximizing acquisition functions for Bayesian opti.pdf;/Users/lichengk/Zotero/storage/T6AYI6IN/1805.html}
}

@inproceedings{wilsonMaximizingAcquisitionFunctions2018a,
  title = {Maximizing Acquisition Functions for {{Bayesian}} Optimization},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wilson, James and Hutter, Frank and Deisenroth, Marc},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-01-18},
  abstract = {Bayesian optimization is a sample-efficient approach to global optimization that relies on theoretically motivated value heuristics (acquisition functions) to guide its search process. Fully maximizing acquisition functions produces the Bayes' decision rule, but this ideal is difficult to achieve since these functions are frequently non-trivial to optimize. This statement is especially true when evaluating queries in parallel, where acquisition functions are routinely non-convex, high-dimensional, and intractable. We first show that acquisition functions estimated via Monte Carlo integration are consistently amenable to gradient-based optimization. Subsequently, we identify a common family of acquisition functions, including EI and UCB, whose characteristics not only facilitate but justify use of greedy approaches for their maximization.},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wilson et al_2018_Maximizing acquisition functions for Bayesian optimization.pdf}
}

@article{wilsonReparameterizationTrickAcquisition2017,
  title = {The Reparameterization Trick for Acquisition Functions},
  author = {Wilson, James T. and Moriconi, Riccardo and Hutter, Frank and Deisenroth, Marc Peter},
  year = {2017},
  month = dec,
  journal = {arXiv:1712.00424 [cs, math, stat]},
  eprint = {1712.00424},
  primaryclass = {cs, math, stat},
  urldate = {2022-02-19},
  abstract = {Bayesian optimization is a sample-efficient approach to solving global optimization problems. Along with a surrogate model, this approach relies on theoretically motivated value heuristics (acquisition functions) to guide the search process. Maximizing acquisition functions yields the best performance; unfortunately, this ideal is difficult to achieve since optimizing acquisition functions per se is frequently non-trivial. This statement is especially true in the parallel setting, where acquisition functions are routinely non-convex, high-dimensional, and intractable. Here, we demonstrate how many popular acquisition functions can be formulated as Gaussian integrals amenable to the reparameterization trick and, ensuingly, gradient-based optimization. Further, we use this reparameterized representation to derive an efficient Monte Carlo estimator for the upper confidence bound acquisition function in the context of parallel selection.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wilson et al_2017_The reparameterization trick for acquisition functions.pdf;/Users/lichengk/Zotero/storage/5AM5K8RW/1712.html}
}

@article{wilsonTenSimpleRules2019,
  title = {Ten Simple Rules for the Computational Modeling of Behavioral Data},
  author = {Wilson, Robert C and Collins, Anne GE},
  editor = {Behrens, Timothy E},
  year = {2019},
  month = nov,
  journal = {eLife},
  volume = {8},
  pages = {e49547},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.49547},
  urldate = {2022-06-02},
  abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
  keywords = {computational modeling,model fitting,reproducibility,validation},
  file = {/Users/lichengk/Zotero/storage/FNEFPPNA/Wilson and Collins - 2019 - Ten simple rules for the computational modeling of.pdf}
}

@article{winklerNumericalRecipesArt1993,
  title = {Numerical Recipes in {{C}}: {{The}} Art of Scientific Computing, Second Edition},
  shorttitle = {Numerical Recipes in {{C}}},
  author = {Winkler, Joab R},
  year = {1993},
  month = jan,
  journal = {Endeavour},
  volume = {17},
  number = {4},
  pages = {201},
  issn = {01609327},
  doi = {10.1016/0160-9327(93)90069-F},
  urldate = {2022-08-08},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Winkler_1993_Numerical recipes in C.pdf}
}

@misc{wongFlowMCNormalizingflowEnhanced2022,
  title = {{{flowMC}}: {{Normalizing-flow}} Enhanced Sampling Package for Probabilistic Inference in {{Jax}}},
  shorttitle = {{{flowMC}}},
  author = {Wong, Kaze W. K. and Gabri{\'e}, Marylou and {Foreman-Mackey}, Daniel},
  year = {2022},
  month = nov,
  number = {arXiv:2211.06397},
  eprint = {2211.06397},
  primaryclass = {astro-ph},
  publisher = {{arXiv}},
  urldate = {2022-11-22},
  abstract = {flowMC is a Python library for accelerated Markov Chain Monte Carlo (MCMC) leveraging deep generative modeling. It is built on top of the machine learning libraries JAX and Flax. At its core, flowMC uses a local sampler and a learnable global sampler in tandem to efficiently sample posterior distributions. While multiple chains of the local sampler generate samples over the region of interest in the target parameter space, the package uses these samples to train a normalizing flow model, then uses it to propose global jumps across the parameter space. The flowMC sampler can handle non-trivial geometry, such as multimodal distributions and distributions with local correlations. The key features of flowMC are summarized in the following list: * Since flowMC is built on top of JAX, it supports gradient-based samplers through automatic differentiation such as MALA and Hamiltonian Monte Carlo (HMC). * flowMC uses state-of-the-art normalizing flow models such as Rational-Quadratic Splines to power its global sampler. These models are very efficient in capturing important features within a relatively short training time. * Use of accelerators such as GPUs and TPUs are natively supported. The code also supports the use of multiple accelerators with SIMD parallelism. * By default, Just-in-time (JIT) compilations are used to further speed up the sampling process. * We provide a simple black box interface for the users who want to use flowMC by its default parameters, yet provide at the same time an extensive guide explaining trade-offs while tuning the sampler parameters. The tight integration of all the above features makes flowMC a highly performant yet simple- to-use package for statistical inference.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
  file = {/Users/lichengk/Zotero/storage/UFVMKG8K/Wong et al. - 2022 - flowMC Normalizing-flow enhanced sampling package.pdf;/Users/lichengk/Zotero/storage/EJCKFDJJ/2211.html}
}

@inproceedings{wuBayesianOptimizationGradients2017,
  title = {Bayesian Optimization with Gradients},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Wu, Jian and Poloczek, Matthias and Wilson, Andrew G and Frazier, Peter},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  keywords = {ObsCite,toread},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wu et al_2017_Bayesian optimization with gradients.pdf}
}

@inproceedings{wuethrichRegretBoundsGaussianProcess2021,
  title = {Regret {{Bounds}} for {{Gaussian-Process Optimization}} in {{Large Domains}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wuethrich, Manuel and Sch{\"o}lkopf, Bernhard and Krause, Andreas},
  year = {2021},
  volume = {34},
  pages = {7385--7396},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-08-09},
  abstract = {The goal of this paper is to characterize Gaussian-Process optimization in the setting where the function domain is large relative to the number of admissible function evaluations, i.e., where it is impossible to find the global optimum. We provide upper bounds on the suboptimality (Bayesian simple regret) of the solution found by optimization strategies that are closely related to the widely used expected improvement (EI) and upper confidence bound (UCB) algorithms. These regret bounds illuminate the relationship between the number of evaluations, the domain size (i.e. cardinality of finite domains / Lipschitz constant of the covariance function in continuous domains), and the optimality of the retrieved function value.In particular, we show that even when the number of evaluations is far too small to find the global optimum, we can find nontrivial function values (e.g. values that achieve a certain ratio with the optimal value).},
  file = {/Users/lichengk/Zotero/storage/CDMLIYNI/Wuethrich et al. - 2021 - Regret Bounds for Gaussian-Process Optimization in.pdf}
}

@article{wuExploitingGradientsHessians2018,
  title = {Exploiting Gradients and {{Hessians}} in {{Bayesian}} Optimization and {{Bayesian}} Quadrature},
  author = {Wu, Anqi and Aoi, Mikio C. and Pillow, Jonathan W.},
  year = {2018},
  month = mar,
  journal = {arXiv:1704.00060 [stat]},
  eprint = {1704.00060},
  primaryclass = {stat},
  urldate = {2022-03-09},
  abstract = {An exciting branch of machine learning research focuses on methods for learning, optimizing, and integrating unknown functions that are difficult or costly to evaluate. A popular Bayesian approach to this problem uses a Gaussian process (GP) to construct a posterior distribution over the function of interest given a set of observed measurements, and selects new points to evaluate using the statistics of this posterior. Here we extend these methods to exploit derivative information from the unknown function. We describe methods for Bayesian optimization (BO) and Bayesian quadrature (BQ) in settings where first and second derivatives may be evaluated along with the function itself. We perform sampling-based inference in order to incorporate uncertainty over hyperparameters, and show that both hyperparameter and function uncertainty decrease much more rapidly when using derivative information. Moreover, we introduce techniques for overcoming ill-conditioning issues that have plagued earlier methods for gradient-enhanced Gaussian processes and kriging. We illustrate the efficacy of these methods using applications to real and simulated Bayesian optimization and quadrature problems, and show that exploting derivatives can provide substantial gains over standard methods.},
  archiveprefix = {arxiv},
  keywords = {ObsCite,Statistics - Machine Learning,相关性高},
  file = {/Users/lichengk/Zotero/storage/Y72IWCZE/Wu et al. - 2018 - Exploiting gradients and Hessians in Bayesian opti.pdf;/Users/lichengk/Zotero/storage/L5YCH6MF/1704.html}
}

@misc{wuFoundationPosteriorsApproximate2022,
  title = {Foundation {{Posteriors}} for {{Approximate Probabilistic Inference}}},
  author = {Wu, Mike and Goodman, Noah},
  year = {2022},
  month = may,
  number = {arXiv:2205.09735},
  eprint = {2205.09735},
  primaryclass = {cs, stat},
  institution = {{arXiv}},
  urldate = {2022-05-26},
  abstract = {Probabilistic programs provide an expressive representation language for generative models. Given a probabilistic program, we are interested in the task of posterior inference: estimating a latent variable given a set of observed variables. Existing techniques for inference in probabilistic programs often require choosing many hyper-parameters, are computationally expensive, and/or only work for restricted classes of programs. Here we formulate inference as masked language modeling: given a program, we generate a supervised dataset of variables and assignments, and randomly mask a subset of the assignments. We then train a neural network to unmask the random values, defining an approximate posterior distribution. By optimizing a single neural network across a range of programs we amortize the cost of training, yielding a ``foundation'' posterior able to do zero-shot inference for new programs. The foundation posterior can also be fine-tuned for a particular program and dataset by optimizing a variational inference objective. We show the efficacy of the approach, zero-shot and fine-tuned, on a benchmark of STAN programs.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/SFG3XHY5/Wu and Goodman - 2022 - Foundation Posteriors for Approximate Probabilisti.pdf;/Users/lichengk/Zotero/storage/SQCU739M/2205.html}
}

@article{wuINVARIANTPROBABILITYDISTRIBUTIONS,
  title = {{{INVARIANT PROBABILITY DISTRIBUTIONS}}},
  author = {Wu, Botao},
  pages = {8},
  abstract = {In this paper, we attempt to answer the three questions about the invariant probability distribution for stochastic matrices: (1) does every stochastic matrix have an invariant probability distribution?; (2) is the invariant probability distribution unique?; and (3) when can we conclude that the power of a stochastic matrix converges? To answer these questions, we present the Perron-Frobenius Theorem about matrices with positive entries.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/XKWLGSR8/Wu - INVARIANT PROBABILITY DISTRIBUTIONS.pdf}
}

@article{wuLectureNotesInformationtheoretic,
  title = {Lecture Notes on: {{Information-theoretic}} Methods for High-Dimensional Statistics},
  author = {Wu, Yihong},
  pages = {162},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wu_Lecture notes on.pdf}
}

@misc{wuStochasticNormalizingFlows2020,
  title = {Stochastic {{Normalizing Flows}}},
  author = {Wu, Hao and K{\"o}hler, Jonas and No{\'e}, Frank},
  year = {2020},
  month = oct,
  number = {arXiv:2002.06707},
  eprint = {2002.06707},
  primaryclass = {physics, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2002.06707},
  urldate = {2022-12-07},
  abstract = {The sampling of probability distributions specified up to a normalization constant is an important problem in both machine learning and statistical mechanics. While classical stochastic sampling methods such as Markov Chain Monte Carlo (MCMC) or Langevin Dynamics (LD) can suffer from slow mixing times there is a growing interest in using normalizing flows in order to learn the transformation of a simple prior distribution to the given target distribution. Here we propose a generalized and combined approach to sample target densities: Stochastic Normalizing Flows (SNF) -- an arbitrary sequence of deterministic invertible functions and stochastic sampling blocks. We show that stochasticity overcomes expressivity limitations of normalizing flows resulting from the invertibility constraint, whereas trainable transformations between sampling steps improve efficiency of pure MCMC/LD along the flow. By invoking ideas from non-equilibrium statistical mechanics we derive an efficient training procedure by which both the sampler's and the flow's parameters can be optimized end-to-end, and by which we can compute exact importance weights without having to marginalize out the randomness of the stochastic blocks. We illustrate the representational power, sampling efficiency and asymptotic correctness of SNFs on several benchmarks including applications to sampling molecular systems in equilibrium.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Physics - Chemical Physics,{Physics - Data Analysis, Statistics and Probability},Statistics - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Wu et al_2020_Stochastic Normalizing Flows.pdf;/Users/lichengk/Zotero/storage/C44WQ3NI/2002.html}
}

@article{yadavFasterKernelInterpolation2021,
  title = {Faster {{Kernel Interpolation}} for {{Gaussian Processes}}},
  author = {Yadav, Mohit and Sheldon, Daniel and Musco, Cameron},
  year = {2021},
  month = aug,
  journal = {arXiv:2101.11751 [cs]},
  eprint = {2101.11751},
  primaryclass = {cs},
  urldate = {2021-09-15},
  abstract = {A key challenge in scaling Gaussian Process (GP) regression to massive datasets is that exact inference requires computation with a dense n x n kernel matrix, where n is the number of data points. Significant work focuses on approximating the kernel matrix via interpolation using a smaller set of m inducing points. Structured kernel interpolation (SKI) is among the most scalable methods: by placing inducing points on a dense grid and using structured matrix algebra, SKI achieves per-iteration time of O(n + m log m) for approximate inference. This linear scaling in n enables inference for very large data sets; however the cost is per-iteration, which remains a limitation for extremely large n. We show that the SKI per-iteration time can be reduced to O(m log m) after a single O(n) time precomputation step by reframing SKI as solving a natural Bayesian linear regression problem with a fixed set of m compact basis functions. With per-iteration complexity independent of the dataset size n for a fixed grid, our method scales to truly massive data sets. We demonstrate speedups in practice for a wide range of m and n and apply the method to GP inference on a three-dimensional weather radar dataset with over 100 million points.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Yadav et al_2021_Faster Kernel Interpolation for Gaussian Processes.pdf;/Users/lichengk/Zotero/storage/7WGP3697/2101.html}
}

@article{yangIlldefinedProblemMaximum,
  title = {The {{Ill-defined Problem}} of {{Maximum Likelihood Estimation}}},
  author = {Yang, Yibo},
  langid = {english},
  keywords = {ObsCite},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Yang_The Ill-defined Problem of Maximum Likelihood Estimation.pdf}
}

@misc{YangSongGenerative,
  title = {Yang {{Song}} | {{Generative Modeling}} by {{Estimating Gradients}} of the {{Data Distribution}}},
  urldate = {2022-06-15},
  howpublished = {https://yang-song.github.io/blog/2021/score/}
}

@article{yaoDeepLearningFunctional2021,
  title = {Deep {{Learning}} for {{Functional Data Analysis}} with {{Adaptive Basis Layers}}},
  author = {Yao, Junwen and Mueller, Jonas and Wang, Jane-Ling},
  year = {2021},
  journal = {arXiv preprint arXiv:2106.10414},
  eprint = {2106.10414},
  archiveprefix = {arxiv},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Yao et al_2021_Deep Learning for Functional Data Analysis with Adaptive Basis Layers.pdf;/Users/lichengk/Zotero/storage/9NRRS2SD/2106.html}
}

@article{yaoYesDidIt2018,
  title = {Yes, but {{Did It Work}}?: {{Evaluating Variational Inference}}},
  shorttitle = {Yes, but {{Did It Work}}?},
  author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
  year = {2018},
  month = jul,
  journal = {arXiv:1802.02538 [stat]},
  eprint = {1802.02538},
  primaryclass = {stat},
  urldate = {2022-03-23},
  abstract = {While it's always possible to compute a variational approximation to a posterior distribution, it can be difficult to discover problems with this approximation. We propose two diagnostic algorithms to alleviate this problem. The Paretosmoothed importance sampling (PSIS) diagnostic gives a goodness of fit measurement for joint distributions, while simultaneously improving the error in the estimate. The variational simulationbased calibration (VSBC) assesses the average performance of point estimates.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/QW5AHIZ8/Yao et al. - 2018 - Yes, but Did It Work Evaluating Variational Infe.pdf}
}

@misc{yiSparseVariationalGaussian2021,
  title = {Sparse and {{Variational Gaussian Process}} \textemdash{} {{What To Do When Data}} Is {{Large}}},
  author = {Yi, Wei},
  year = {2021},
  month = aug,
  journal = {Medium},
  urldate = {2021-08-24},
  abstract = {Learn how the Sparse and Variational Gaussian Process model uses inducing variables to scale to large datasets.},
  howpublished = {https://towardsdatascience.com/sparse-and-variational-gaussian-process-what-to-do-when-data-is-large-2d3959f430e7},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/9AJSE3EI/sparse-and-variational-gaussian-process-what-to-do-when-data-is-large-2d3959f430e7.html}
}

@misc{yiVariationalGaussianProcess2021,
  title = {Variational {{Gaussian Process}} \textemdash{} {{What To Do When Things Are Not Gaussian}}},
  author = {Yi, Wei},
  year = {2021},
  month = jun,
  journal = {Medium},
  urldate = {2021-08-23},
  abstract = {Learn to use non-Gaussian distributions in Gaussian Process models, and variational inference with Gaussian quadrature to compute\ldots},
  howpublished = {https://towardsdatascience.com/variational-gaussian-process-what-to-do-when-things-are-not-gaussian-41197039f3d4},
  langid = {english},
  keywords = {*5{$\medwhitestar\medwhitestar\medwhitestar\medwhitestar\medwhitestar$}},
  file = {/Users/lichengk/Zotero/storage/ADJLASVA/variational-gaussian-process-what-to-do-when-things-are-not-gaussian-41197039f3d4.html}
}

@book{zacconePythonParallelProgramming2015,
  title = {Python Parallel Programming Cookbook: Master Efficient Parallel Programming to Build Powerful Applications Using {{Python}}},
  shorttitle = {Python Parallel Programming Cookbook},
  author = {Zaccone, Giancarlo},
  year = {2015},
  series = {Quick Answers to Common Problems},
  edition = {1. publ},
  publisher = {{Packt Publ}},
  address = {{Birmingham Mumbai}},
  isbn = {978-1-78528-958-3},
  langid = {english},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Zaccone_2015_Python parallel programming cookbook.pdf}
}

@inproceedings{zanettiNovelGaussianMixture2018,
  title = {A {{Novel Gaussian Mixture Approximation}} for {{Nonlinear Estimation}}},
  booktitle = {2018 21st {{International Conference}} on {{Information Fusion}} ({{FUSION}})},
  author = {Zanetti, Renato and Tuggle, Kirsten},
  year = {2018},
  month = jul,
  pages = {1100--1106},
  doi = {10.23919/ICIF.2018.8455485},
  abstract = {A novel adaptive nonlinear estimator is presented to accurately incorporate nonlinear/non-Gaussian measurement in a Bayesian framework. The underlying algorithm relies on a Gaussian Mixture Model (GMM) to approximate the probability density function (pdf) of the state conditioned on all current and past measurement. Automatic mixture components refining is performed to ensure that the posterior GMM approximation of the pdf accurately represents the true distribution.},
  keywords = {Approximation algorithms,Bayes methods,Covariance matrices,Current measurement,Gaussian distribution,Kalman filters,Probability density function},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Zanetti_Tuggle_2018_A Novel Gaussian Mixture Approximation for Nonlinear Estimation.pdf;/Users/lichengk/Zotero/storage/2W88VSCZ/8455485.html}
}

@article{zhangAdvancesVariationalInference2019,
  title = {Advances in {{Variational Inference}}},
  author = {Zhang, Cheng and B{\"u}tepage, Judith and Kjellstr{\"o}m, Hedvig and Mandt, Stephan},
  year = {2019},
  month = aug,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {41},
  number = {8},
  pages = {2008--2026},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2018.2889774},
  abstract = {Many modern unsupervised or semi-supervised machine learning algorithms rely on Bayesian probabilistic models. These models are usually intractable and thus require approximate inference. Variational inference (VI) lets us approximate a high-dimensional Bayesian posterior with a simpler variational distribution by solving an optimization problem. This approach has been successfully applied to various models and large-scale applications. In this review, we give an overview of recent trends in variational inference. We first introduce standard mean field variational inference, then review recent advances focusing on the following aspects: (a) scalable VI, which includes stochastic approximations, (b) generic VI, which extends the applicability of VI to a large class of otherwise intractable models, such as non-conjugate models, (c) accurate VI, which includes variational models beyond the mean field approximation or with atypical divergences, and (d) amortized VI, which implements the inference over local latent variables with inference networks. Finally, we provide a summary of promising future research directions.},
  keywords = {approximate Bayesian inference,Bayes methods,Computational modeling,Hidden Markov models,inference networks,Market research,Optimization,Probabilistic logic,reparameterization gradients,scalable inference,Stochastic processes,structured variational approximations,Variational inference},
  file = {/Users/lichengk/Zotero/storage/SLRZXURT/Zhang et al. - 2019 - Advances in Variational Inference.pdf;/Users/lichengk/Zotero/storage/2GNEKQK5/stamp.html}
}

@misc{zhangSequentialGaussianProcesses2019,
  title = {Sequential {{Gaussian Processes}} for {{Online Learning}} of {{Nonstationary Functions}}},
  author = {Zhang, Michael Minyi and Dumitrascu, Bianca and Williamson, Sinead A. and Engelhardt, Barbara E.},
  year = {2019},
  month = oct,
  number = {arXiv:1905.10003},
  eprint = {1905.10003},
  primaryclass = {cs, stat},
  institution = {{arXiv}},
  urldate = {2022-05-31},
  abstract = {Many machine learning problems can be framed in the context of estimating functions, and often these are time-dependent functions that are estimated in real-time as observations arrive. Gaussian processes (GPs) are an attractive choice for modeling real-valued nonlinear functions due to their flexibility and uncertainty quantification. However, the typical GP regression model suffers from several drawbacks: i) Conventional GP inference scales \$O(N\^\{3\})\$ with respect to the number of observations; ii) updating a GP model sequentially is not trivial; and iii) covariance kernels often enforce stationarity constraints on the function, while GPs with non-stationary covariance kernels are often intractable to use in practice. To overcome these issues, we propose an online sequential Monte Carlo algorithm to fit mixtures of GPs that capture non-stationary behavior while allowing for fast, distributed inference. By formulating hyperparameter optimization as a multi-armed bandit problem, we accelerate mixing for real time inference. Our approach empirically improves performance over state-of-the-art methods for online GP estimation in the context of prediction for simulated non-stationary data and hospital time series data.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {/Users/lichengk/Zotero/storage/HTIRB7DV/Zhang et al. - 2019 - Sequential Gaussian Processes for Online Learning .pdf;/Users/lichengk/Zotero/storage/NT9RDV7Q/1905.html}
}

@article{zhangUnderstandingDeepLearning2021,
  title = {Understanding Deep Learning (Still) Requires Rethinking Generalization},
  author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  year = {2021},
  month = mar,
  journal = {Communications of the ACM},
  volume = {64},
  number = {3},
  pages = {107--115},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3446776},
  urldate = {2022-12-05},
  abstract = {Despite their massive size, successful deep artificial \-neural networks can exhibit a remarkably small gap between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family or to the regularization techniques used during training.},
  langid = {english},
  file = {/Users/lichengk/Zotero/storage/W959UCI3/Zhang et al. - 2021 - Understanding deep learning (still) requires rethi.pdf}
}

@inproceedings{zhaoAcceleratingInterferencebasedQoS2021,
  title = {Accelerating {{Interference-based QoS Analysis}} of {{Vehicular Ad Hoc Networks}} for {{BSM Safety Applications}}: {{Parallel Numerical Solutions}} and {{Simulations}}.},
  shorttitle = {Accelerating {{Interference-based QoS Analysis}} of {{Vehicular Ad Hoc Networks}} for {{BSM Safety Applications}}},
  booktitle = {{{VEHITS}}},
  author = {Zhao, Jing and Zhou, Hao and Wang, Yanbin and Lu, Hualin and Li, Zhijuan and Ma, Xiaomin},
  year = {2021},
  pages = {600--610},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Zhao et al_2021_Accelerating Interference-based QoS Analysis of Vehicular Ad Hoc Networks for.pdf}
}

@article{zhouAdaptiveBayesianQuadrature2020,
  title = {Adaptive {{Bayesian}} Quadrature Based Statistical Moments Estimation for Structural Reliability Analysis},
  author = {Zhou, Tong and Peng, Yongbo},
  year = {2020},
  journal = {Reliability Engineering \& System Safety},
  volume = {198},
  pages = {106902},
  publisher = {{Elsevier}},
  file = {/Users/lichengk/Zotero/storage/Q3IBJLUB/S0951832019307306.html}
}

@article{zhuBayesianProbabilisticNumerical2020,
  title = {Bayesian {{Probabilistic Numerical Integration}} with {{Tree-Based Models}}},
  author = {Zhu, Harrison and Liu, Xing and Kang, Ruya and Shen, Zhichao and Flaxman, Seth and Briol, Fran{\c c}ois-Xavier},
  year = {2020},
  journal = {arXiv preprint arXiv:2006.05371},
  eprint = {2006.05371},
  archiveprefix = {arxiv},
  file = {/Users/lichengk/OneDrive/Zotero/attachments/Zhu et al_2020_Bayesian Probabilistic Numerical Integration with Tree-Based Models.pdf;/Users/lichengk/Zotero/storage/FAMTU3A5/2006.html}
}

@article{zhuPhysicsconstrainedDeepLearning2019,
  title = {Physics-Constrained Deep Learning for High-Dimensional Surrogate Modeling and Uncertainty Quantification without Labeled Data},
  author = {Zhu, Yinhao and Zabaras, Nicholas and Koutsourelakis, Phaedon-Stelios and Perdikaris, Paris},
  year = {2019},
  month = oct,
  journal = {Journal of Computational Physics},
  volume = {394},
  pages = {56--81},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2019.05.024},
  urldate = {2022-02-02},
  abstract = {Surrogate modeling and uncertainty quantification tasks for PDE systems are most often considered as supervised learning problems where input and output data pairs are used for training. The construction of such emulators is by definition a small data problem which poses challenges to deep learning approaches that have been developed to operate in the big data regime. Even in cases where such models have been shown to have good predictive capability in high dimensions, they fail to address constraints in the data implied by the PDE model. This paper provides a methodology that incorporates the governing equations of the physical model in the loss/likelihood functions. The resulting physics-constrained, deep learning models are trained without any labeled data (e.g. employing only input data) and provide comparable predictive responses with data-driven models while obeying the constraints of the problem at hand. This work employs a convolutional encoder-decoder neural network approach as well as a conditional flow-based generative model for the solution of PDEs, surrogate model construction, and uncertainty quantification tasks. The methodology is posed as a minimization problem of the reverse Kullback-Leibler (KL) divergence between the model predictive density and the reference conditional density, where the later is defined as the Boltzmann-Gibbs distribution at a given inverse temperature with the underlying potential relating to the PDE system of interest. The generalization capability of these models to out-of-distribution input is considered. Quantification and interpretation of the predictive uncertainty is provided for a number of problems.},
  langid = {english},
  keywords = {Conditional generative model,Normalizing flow,ObsCite,Physics-constrained,Reverse KL divergence,Surrogate modeling,Uncertainty quantification},
  file = {/Users/lichengk/Zotero/storage/HYL5D5X8/Zhu et al. - 2019 - Physics-constrained deep learning for high-dimensi.pdf;/Users/lichengk/Zotero/storage/WS9ZU263/S0021999119303559.html}
}
